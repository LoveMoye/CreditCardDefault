{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Module\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features of data\n",
    "\n",
    "- ID: ID of each client\n",
    "- LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit)\n",
    "- SEX: Gender (1=male, 2=female)\n",
    "- EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n",
    "- MARRIAGE: Marital status (1=married, 2=single, 3=others)\n",
    "- AGE: Age in years\n",
    "- PAY_0: Repayment status in September, 2005 (-2 = no usage, -1=pay duly, 1=payment delay for one month, 2=payment delay for two months, … 8=payment - delay for eight months, 9=payment delay for nine months and above)\n",
    "- PAY_2: Repayment status in August, 2005 (scale same as above)\n",
    "- PAY_3: Repayment status in July, 2005 (scale same as above)\n",
    "- PAY_4: Repayment status in June, 2005 (scale same as above)\n",
    "- PAY_5: Repayment status in May, 2005 (scale same as above)\n",
    "- PAY_6: Repayment status in April, 2005 (scale same as above)\n",
    "- BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n",
    "- BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n",
    "- BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n",
    "- BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n",
    "- BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n",
    "- BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n",
    "- PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n",
    "- PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n",
    "- PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n",
    "- PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n",
    "- PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n",
    "- PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n",
    "- default.payment.next.month: Default payment (1=yes(failure to make a payment on a dept), 0=no(succeed)) ** To default is to fail to make a payment on a debt by the due date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Variable\n",
    "\n",
    "random_state = 475\n",
    "\n",
    "info = [\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\"]\n",
    "delay_n = [\"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\"]\n",
    "bill_n = [\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\"]\n",
    "pay_n = [\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C:/Users/chowonjae/Desktop/내부 프로젝트/uci_creditcard-train-0.0-0.0 (1).csv\")\n",
    "test = pd.read_csv(\"C:/Users/chowonjae/Desktop/내부 프로젝트/uci_creditcard-test-0.0-0.0 (1).csv\")\n",
    "\n",
    "length = len(train)\n",
    "\n",
    "#Change the column name \"default payment next month\" -> \"default\"\n",
    "train = train.rename(columns = {\"default payment next month\":\"default\"})\n",
    "test = test.rename(columns = {\"default payment next month\":\"default\"})\n",
    "\n",
    "train = train.drop([\"ID\",\"sep_idx\"], axis = 1)\n",
    "train_drop_info = train.drop(info, axis = 1)\n",
    "\n",
    "test = test.drop([\"ID\",\"sep_idx\"], axis = 1)\n",
    "\n",
    "# Change Type\n",
    "\n",
    "train[\"SEX\"] = train[\"SEX\"].astype(np.int)\n",
    "train[\"EDUCATION\"] = train[\"EDUCATION\"].astype(np.int)\n",
    "train[\"MARRIAGE\"] = train[\"MARRIAGE\"].astype(np.int)\n",
    "train[\"AGE\"] = train[\"AGE\"].astype(np.int)\n",
    "train[\"default\"] = train[\"default\"].astype(np.int)\n",
    "train[delay_n] = train[delay_n].astype(np.int)\n",
    "\n",
    "test[\"SEX\"] = test[\"SEX\"].astype(np.int)\n",
    "test[\"EDUCATION\"] = test[\"EDUCATION\"].astype(np.int)\n",
    "test[\"MARRIAGE\"] = test[\"MARRIAGE\"].astype(np.int)\n",
    "test[\"AGE\"] = test[\"AGE\"].astype(np.int)\n",
    "test[\"default\"] = test[\"default\"].astype(np.int)\n",
    "test[delay_n] = test[delay_n].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(\"default\", axis = 1)\n",
    "y_train = train[\"default\"]\n",
    "\n",
    "X_test = test.drop(\"default\", axis = 1)\n",
    "y_test = test[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18640\n",
       "1     5356\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.776796\n",
       "1    0.223204\n",
       "Name: default, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts() / y_train.value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split_train, split_val = train_test_split(train, test_size = 0.2, random_state = random_state, stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train = split_train.reset_index(drop = True)\n",
    "split_val = split_val.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "apr = [\"PAY_6\", \"BILL_AMT6\", \"PAY_AMT6\"]\n",
    "may = [\"PAY_5\", \"BILL_AMT5\", \"PAY_AMT5\"]\n",
    "jun = [\"PAY_4\", \"BILL_AMT4\", \"PAY_AMT4\"]\n",
    "jul = [\"PAY_3\", \"BILL_AMT3\", \"PAY_AMT3\"]\n",
    "aug = [\"PAY_2\", \"BILL_AMT2\", \"PAY_AMT2\"]\n",
    "sep = [\"PAY_0\", \"BILL_AMT1\", \"PAY_AMT1\"]\n",
    "month_list = [apr, may, jun, jul, aug, sep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Input(df):\n",
    "    \n",
    "    total = len(df) * 6 * 3 # 숫자 총 갯수\n",
    "    df_preprocessing = np.array([.0] * total).reshape(-1, 6 ,3) # 처리한 데이터 저장할 array\n",
    "    df_unit = np.array([.0] * (18)).reshape(6, 3)\n",
    "    for i in range(len(df)):\n",
    "        X_df_i = df.loc[i]\n",
    "        for j in range(6):\n",
    "            df_unit[j] = df.loc[i][month_list[j]].values\n",
    "        df_preprocessing[i] = df_unit\n",
    "    \n",
    "    return df_preprocessing\n",
    "\n",
    "def preprocessing(df, test = False):\n",
    "    \n",
    "    if not test:\n",
    "        y = df[\"default\"]\n",
    "\n",
    "        one_hot = np.unique([0, 1]).shape[0]\n",
    "        y_preprocessing = np.eye(one_hot)[y.to_numpy()].reshape(-1, 2)\n",
    "\n",
    "    ##MinMaxScaling\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    mms = MinMaxScaler()\n",
    "    mms.fit(df[[\"LIMIT_BAL\"] + bill_n + pay_n])\n",
    "\n",
    "    X_scaling = mms.transform(df[[\"LIMIT_BAL\"] + bill_n + pay_n])\n",
    "\n",
    "    X_scaling_df = pd.DataFrame(X_scaling, columns = [\"LIMIT_BAL\"] + bill_n + pay_n)\n",
    "\n",
    "    for delay in delay_n:    \n",
    "        X_scaling_df[delay] = df[delay].reset_index(drop = True)\n",
    "\n",
    "    X_add_feature = df[info]\n",
    "    X_add_feature.loc[:,\"LIMIT_BAL\"] = X_scaling_df[\"LIMIT_BAL\"].copy()\n",
    "\n",
    "    X_preprocessing = LSTM_Input(X_scaling_df)\n",
    "    \n",
    "    if test:\n",
    "        return X_preprocessing, X_add_feature\n",
    "    \n",
    "    y = df[\"default\"]\n",
    "\n",
    "    one_hot = np.unique([0, 1]).shape[0]\n",
    "    y_preprocessing = np.eye(one_hot)[y.to_numpy()].reshape(-1, 2)\n",
    "        \n",
    "    return X_preprocessing, X_add_feature, y, y_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "X_val_preprocessing, X_val_add_feature, y_val, y_val_preprocessing = preprocessing(split_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "X_test_preprocessing, X_test_add_feature = preprocessing(X_test, test = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling \n",
    "\n",
    "- 과표본화 기반 앙상블 논문을 기반으로 데이터 구성\n",
    "- [출처] http://lambdafield.com/page/imbalanced-data-%EC%B2%98%EB%A6%AC%ED%95%98%EA%B8%B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sampling(train, proportion, size = None, return_default = False):\n",
    "    \n",
    "    if return_default:\n",
    "        return train\n",
    "    \n",
    "    if isinstance(size, int) or isinstance(size, str):\n",
    "        \n",
    "        if size == \"same\":\n",
    "            size = train[train['default'] == 0].shape[0]\n",
    "        \n",
    "        succeed_sample = train[train['default'] == 0].shape[0]\n",
    "        succeed = train[train['default'] == 0].reset_index(drop = True)\n",
    "\n",
    "        default_sample = train[train['default'] == 1].shape[0]\n",
    "        idx = np.random.randint(0, default_sample, size)\n",
    "        default = train[train['default'] == 1].reset_index(drop = True).iloc[idx]\n",
    "        \n",
    "        df = pd.concat([succeed, default])\n",
    "        \n",
    "        return df.reset_index(drop = True)\n",
    "    \n",
    "    \n",
    "    succeed_sample = train[train['default'] == 0].shape[0]\n",
    "    succeed = train[train['default'] == 0].reset_index(drop = True)\n",
    "\n",
    "    default_sample = train[train['default'] == 1].shape[0]\n",
    "    idx = np.random.randint(0, default_sample, int(len(split_train) * proportion))\n",
    "    default = train[train['default'] == 1].reset_index(drop = True).iloc[idx]\n",
    "\n",
    "    df = pd.concat([succeed, default])\n",
    "    \n",
    "    return df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "sample_size =[0, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "sampling_list = []\n",
    "\n",
    "for (i, size) in enumerate(sample_size):\n",
    "    if i == 0:    \n",
    "        df = load_sampling(split_train, size, return_default = True)\n",
    "    else:\n",
    "        df = load_sampling(split_train, size)\n",
    "    \n",
    "    X_train_preprocessing, X_train_add_feature, y_train_before, y_train_preprocessing = preprocessing(df)\n",
    "    \n",
    "    sampling_list.append([X_train_preprocessing, X_train_add_feature, y_train_before, y_train_preprocessing])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##한번만 실행할 것.\n",
    "\n",
    "metric = tf.keras.metrics.AUC(num_thresholds=300, curve='ROC', summation_method='interpolation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (6,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNN Model\n",
    "\n",
    "def RNN_Model(learning_rate):\n",
    "    \n",
    "    # Input layer\n",
    "    input_layer = layers.Input(shape = X_train_preprocessing.shape[1:])\n",
    "    add_feature = layers.Input(shape = (5))\n",
    "    \n",
    "    # RNN\n",
    "    lstm = layers.LSTM(3)(input_layer)\n",
    "    \n",
    "    # Add features\n",
    "    add = layers.Concatenate()([lstm, add_feature])\n",
    "    \n",
    "    # output layer\n",
    "    fc1 = layers.Dense(256, activation = \"relu\")(add)\n",
    "    bn1 = layers.BatchNormalization()(fc1)\n",
    "    fc2 = layers.Dense(256, activation = \"relu\")(bn1)\n",
    "    bn2 = layers.BatchNormalization()(fc2)\n",
    "    output = layers.Dense(2, activation = 'sigmoid')(bn2)\n",
    "    \n",
    "    model = keras.Model(inputs = [input_layer, add_feature], outputs = output)\n",
    "    \n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr = learning_rate),\n",
    "                  metrics = [metric, \"accuracy\"],\n",
    "                 loss = 'categorical_crossentropy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val,epochs, batch_size = None, patience = 5, monitor = 'val_loss'):\n",
    "    \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=patience, restore_best_weights = True, mode = \"max\")\n",
    "    \n",
    "    history = model.fit(x = X_train, y = y_train, epochs = epochs, batch_size = batch_size, callbacks = [callback],\n",
    "                       shuffle = True, validation_data = (X_val, y_val))\n",
    "     \n",
    "    epochs = history.epoch\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    \n",
    "    return epochs, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 6, 3)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 3)            84          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8)            0           lstm[0][0]                       \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          2304        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256)          1024        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            514         batch_normalization_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 70,742\n",
      "Trainable params: 69,718\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.00001\n",
    "\n",
    "my_model = RNN_Model(learning_rate)\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (19196, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 0th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.6500 - auc: 0.5884 - accuracy: 0.5716 - val_loss: 0.6211 - val_auc: 0.5344 - val_accuracy: 0.5796\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.5980 - auc: 0.5508 - accuracy: 0.6182 - val_loss: 0.5908 - val_auc: 0.5522 - val_accuracy: 0.6112\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.5861 - auc: 0.5572 - accuracy: 0.6297 - val_loss: 0.5822 - val_auc: 0.5610 - val_accuracy: 0.6265\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5800 - auc: 0.5651 - accuracy: 0.6349 - val_loss: 0.5788 - val_auc: 0.5691 - val_accuracy: 0.6296\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5745 - auc: 0.5767 - accuracy: 0.6410 - val_loss: 0.5747 - val_auc: 0.5808 - val_accuracy: 0.6348\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5704 - auc: 0.5875 - accuracy: 0.6485 - val_loss: 0.5717 - val_auc: 0.5968 - val_accuracy: 0.6385\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5665 - auc: 0.6005 - accuracy: 0.6549 - val_loss: 0.5661 - val_auc: 0.6097 - val_accuracy: 0.6554\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5651 - auc: 0.6073 - accuracy: 0.6609 - val_loss: 0.5640 - val_auc: 0.6182 - val_accuracy: 0.6579\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5617 - auc: 0.6170 - accuracy: 0.6651 - val_loss: 0.5613 - val_auc: 0.6210 - val_accuracy: 0.6658\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5596 - auc: 0.6232 - accuracy: 0.6717 - val_loss: 0.5596 - val_auc: 0.6299 - val_accuracy: 0.6612\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5576 - auc: 0.6298 - accuracy: 0.6756 - val_loss: 0.5543 - val_auc: 0.6405 - val_accuracy: 0.6733\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5539 - auc: 0.6376 - accuracy: 0.6796 - val_loss: 0.5538 - val_auc: 0.6438 - val_accuracy: 0.6719\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5532 - auc: 0.6420 - accuracy: 0.6852 - val_loss: 0.5509 - val_auc: 0.6470 - val_accuracy: 0.6771\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5483 - auc: 0.6497 - accuracy: 0.6900 - val_loss: 0.5469 - val_auc: 0.6568 - val_accuracy: 0.6831\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5468 - auc: 0.6552 - accuracy: 0.6919 - val_loss: 0.5443 - val_auc: 0.6620 - val_accuracy: 0.6954\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5434 - auc: 0.6600 - accuracy: 0.7020 - val_loss: 0.5416 - val_auc: 0.6696 - val_accuracy: 0.7015\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 9s 14ms/step - loss: 0.5397 - auc: 0.6645 - accuracy: 0.7019 - val_loss: 0.5427 - val_auc: 0.6659 - val_accuracy: 0.6994\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5392 - auc: 0.6707 - accuracy: 0.7073 - val_loss: 0.5383 - val_auc: 0.6743 - val_accuracy: 0.7077\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5362 - auc: 0.6741 - accuracy: 0.7105 - val_loss: 0.5350 - val_auc: 0.6802 - val_accuracy: 0.7171\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5350 - auc: 0.6807 - accuracy: 0.7207 - val_loss: 0.5315 - val_auc: 0.6873 - val_accuracy: 0.7248\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5321 - auc: 0.6852 - accuracy: 0.7248 - val_loss: 0.5307 - val_auc: 0.6888 - val_accuracy: 0.7275\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5301 - auc: 0.6916 - accuracy: 0.7273 - val_loss: 0.5240 - val_auc: 0.7034 - val_accuracy: 0.7390\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5273 - auc: 0.6997 - accuracy: 0.7305 - val_loss: 0.5214 - val_auc: 0.7081 - val_accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5262 - auc: 0.7054 - accuracy: 0.7361 - val_loss: 0.5180 - val_auc: 0.7180 - val_accuracy: 0.7533\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5236 - auc: 0.7132 - accuracy: 0.7406 - val_loss: 0.5163 - val_auc: 0.7237 - val_accuracy: 0.7546\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.5202 - auc: 0.7194 - accuracy: 0.7451 - val_loss: 0.5156 - val_auc: 0.7248 - val_accuracy: 0.7540\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.5188 - auc: 0.7275 - accuracy: 0.7520 - val_loss: 0.5090 - val_auc: 0.7425 - val_accuracy: 0.7648\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5159 - auc: 0.7351 - accuracy: 0.7535 - val_loss: 0.5053 - val_auc: 0.7535 - val_accuracy: 0.7744\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5147 - auc: 0.7444 - accuracy: 0.7592 - val_loss: 0.5058 - val_auc: 0.7573 - val_accuracy: 0.7727\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5101 - auc: 0.7517 - accuracy: 0.7616 - val_loss: 0.4968 - val_auc: 0.7737 - val_accuracy: 0.7815\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5083 - auc: 0.7631 - accuracy: 0.7696 - val_loss: 0.4923 - val_auc: 0.7888 - val_accuracy: 0.7815\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5073 - auc: 0.7735 - accuracy: 0.7756 - val_loss: 0.4964 - val_auc: 0.7906 - val_accuracy: 0.7873\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.5039 - auc: 0.7858 - accuracy: 0.7804 - val_loss: 0.4862 - val_auc: 0.8086 - val_accuracy: 0.7890\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4978 - auc: 0.7996 - accuracy: 0.7864 - val_loss: 0.4880 - val_auc: 0.8146 - val_accuracy: 0.8002\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4963 - auc: 0.8103 - accuracy: 0.7880 - val_loss: 0.4815 - val_auc: 0.8252 - val_accuracy: 0.7975\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4932 - auc: 0.8157 - accuracy: 0.7893 - val_loss: 0.4803 - val_auc: 0.8260 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4914 - auc: 0.8181 - accuracy: 0.7884 - val_loss: 0.4784 - val_auc: 0.8290 - val_accuracy: 0.7985\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4900 - auc: 0.8201 - accuracy: 0.7892 - val_loss: 0.4762 - val_auc: 0.8320 - val_accuracy: 0.8004\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4904 - auc: 0.8205 - accuracy: 0.7913 - val_loss: 0.4768 - val_auc: 0.8325 - val_accuracy: 0.7987\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4882 - auc: 0.8231 - accuracy: 0.7897 - val_loss: 0.4757 - val_auc: 0.8330 - val_accuracy: 0.8008\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4878 - auc: 0.8229 - accuracy: 0.7899 - val_loss: 0.4771 - val_auc: 0.8325 - val_accuracy: 0.7998\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4884 - auc: 0.8234 - accuracy: 0.7907 - val_loss: 0.4745 - val_auc: 0.8355 - val_accuracy: 0.8021\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4861 - auc: 0.8262 - accuracy: 0.7924 - val_loss: 0.4739 - val_auc: 0.8343 - val_accuracy: 0.8012\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4864 - auc: 0.8243 - accuracy: 0.7903 - val_loss: 0.4735 - val_auc: 0.8352 - val_accuracy: 0.8025\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4864 - auc: 0.8262 - accuracy: 0.7922 - val_loss: 0.4745 - val_auc: 0.8375 - val_accuracy: 0.8012\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4863 - auc: 0.8267 - accuracy: 0.7907 - val_loss: 0.4738 - val_auc: 0.8368 - val_accuracy: 0.8027\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4859 - auc: 0.8257 - accuracy: 0.7923 - val_loss: 0.4723 - val_auc: 0.8384 - val_accuracy: 0.8015\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4862 - auc: 0.8261 - accuracy: 0.7926 - val_loss: 0.4728 - val_auc: 0.8363 - val_accuracy: 0.8027\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4870 - auc: 0.8267 - accuracy: 0.7919 - val_loss: 0.4737 - val_auc: 0.8375 - val_accuracy: 0.8035\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 9s 14ms/step - loss: 0.4864 - auc: 0.8267 - accuracy: 0.7912 - val_loss: 0.4726 - val_auc: 0.8371 - val_accuracy: 0.8027\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4839 - auc: 0.8286 - accuracy: 0.7927 - val_loss: 0.4740 - val_auc: 0.8369 - val_accuracy: 0.8029\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.4859 - auc: 0.8261 - accuracy: 0.7935 - val_loss: 0.4725 - val_auc: 0.8361 - val_accuracy: 0.8021\n",
      "\n",
      "\n",
      "Train data shape: (19710, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 1th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "616/616 [==============================] - 10s 17ms/step - loss: 0.6397 - auc: 0.6100 - accuracy: 0.5884 - val_loss: 0.5970 - val_auc: 0.5744 - val_accuracy: 0.6221\n",
      "Epoch 2/100\n",
      "616/616 [==============================] - 9s 15ms/step - loss: 0.6001 - auc: 0.5719 - accuracy: 0.6282 - val_loss: 0.5758 - val_auc: 0.5817 - val_accuracy: 0.6556\n",
      "Epoch 3/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.5870 - auc: 0.5775 - accuracy: 0.6396 - val_loss: 0.5717 - val_auc: 0.5846 - val_accuracy: 0.6538\n",
      "Epoch 4/100\n",
      "616/616 [==============================] - 9s 15ms/step - loss: 0.5803 - auc: 0.5894 - accuracy: 0.6475 - val_loss: 0.5601 - val_auc: 0.6015 - val_accuracy: 0.6696\n",
      "Epoch 5/100\n",
      "616/616 [==============================] - 9s 15ms/step - loss: 0.5740 - auc: 0.6024 - accuracy: 0.6561 - val_loss: 0.5540 - val_auc: 0.6164 - val_accuracy: 0.6733\n",
      "Epoch 6/100\n",
      "616/616 [==============================] - 9s 15ms/step - loss: 0.5683 - auc: 0.6139 - accuracy: 0.6621 - val_loss: 0.5483 - val_auc: 0.6302 - val_accuracy: 0.6802\n",
      "Epoch 7/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5634 - auc: 0.6254 - accuracy: 0.6733 - val_loss: 0.5442 - val_auc: 0.6443 - val_accuracy: 0.6850\n",
      "Epoch 8/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5602 - auc: 0.6345 - accuracy: 0.6792 - val_loss: 0.5445 - val_auc: 0.6492 - val_accuracy: 0.6971\n",
      "Epoch 9/100\n",
      "616/616 [==============================] - 9s 15ms/step - loss: 0.5570 - auc: 0.6412 - accuracy: 0.6843 - val_loss: 0.5398 - val_auc: 0.6560 - val_accuracy: 0.6994\n",
      "Epoch 10/100\n",
      "616/616 [==============================] - 9s 15ms/step - loss: 0.5542 - auc: 0.6503 - accuracy: 0.6927 - val_loss: 0.5322 - val_auc: 0.6696 - val_accuracy: 0.7073\n",
      "Epoch 11/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5528 - auc: 0.6551 - accuracy: 0.7006 - val_loss: 0.5343 - val_auc: 0.6667 - val_accuracy: 0.7104\n",
      "Epoch 12/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5492 - auc: 0.6610 - accuracy: 0.7038 - val_loss: 0.5303 - val_auc: 0.6732 - val_accuracy: 0.7227\n",
      "Epoch 13/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5455 - auc: 0.6677 - accuracy: 0.7152 - val_loss: 0.5273 - val_auc: 0.6814 - val_accuracy: 0.7265\n",
      "Epoch 14/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5446 - auc: 0.6735 - accuracy: 0.7184 - val_loss: 0.5233 - val_auc: 0.6933 - val_accuracy: 0.7465\n",
      "Epoch 15/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5428 - auc: 0.6819 - accuracy: 0.7245 - val_loss: 0.5211 - val_auc: 0.7002 - val_accuracy: 0.7475\n",
      "Epoch 16/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5389 - auc: 0.6874 - accuracy: 0.7284 - val_loss: 0.5177 - val_auc: 0.7068 - val_accuracy: 0.7565\n",
      "Epoch 17/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5350 - auc: 0.6966 - accuracy: 0.7364 - val_loss: 0.5103 - val_auc: 0.7199 - val_accuracy: 0.7602\n",
      "Epoch 18/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5351 - auc: 0.7011 - accuracy: 0.7386 - val_loss: 0.5161 - val_auc: 0.7209 - val_accuracy: 0.7602\n",
      "Epoch 19/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5306 - auc: 0.7109 - accuracy: 0.7460 - val_loss: 0.5053 - val_auc: 0.7394 - val_accuracy: 0.7713\n",
      "Epoch 20/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5280 - auc: 0.7224 - accuracy: 0.7531 - val_loss: 0.5024 - val_auc: 0.7498 - val_accuracy: 0.7794\n",
      "Epoch 21/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5251 - auc: 0.7313 - accuracy: 0.7573 - val_loss: 0.4997 - val_auc: 0.7613 - val_accuracy: 0.7856\n",
      "Epoch 22/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5220 - auc: 0.7419 - accuracy: 0.7637 - val_loss: 0.4975 - val_auc: 0.7700 - val_accuracy: 0.7904\n",
      "Epoch 23/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5189 - auc: 0.7525 - accuracy: 0.7674 - val_loss: 0.4964 - val_auc: 0.7785 - val_accuracy: 0.7898\n",
      "Epoch 24/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5147 - auc: 0.7674 - accuracy: 0.7745 - val_loss: 0.4875 - val_auc: 0.8021 - val_accuracy: 0.7998\n",
      "Epoch 25/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5141 - auc: 0.7784 - accuracy: 0.7758 - val_loss: 0.4860 - val_auc: 0.8090 - val_accuracy: 0.8008\n",
      "Epoch 26/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5112 - auc: 0.7878 - accuracy: 0.7785 - val_loss: 0.4846 - val_auc: 0.8129 - val_accuracy: 0.8017\n",
      "Epoch 27/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5089 - auc: 0.7930 - accuracy: 0.7781 - val_loss: 0.4851 - val_auc: 0.8152 - val_accuracy: 0.8002\n",
      "Epoch 28/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5073 - auc: 0.7970 - accuracy: 0.7772 - val_loss: 0.4973 - val_auc: 0.8032 - val_accuracy: 0.7942\n",
      "Epoch 29/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5052 - auc: 0.8005 - accuracy: 0.7813 - val_loss: 0.4829 - val_auc: 0.8188 - val_accuracy: 0.7998\n",
      "Epoch 30/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5051 - auc: 0.8026 - accuracy: 0.7797 - val_loss: 0.4823 - val_auc: 0.8209 - val_accuracy: 0.7994\n",
      "Epoch 31/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5042 - auc: 0.8028 - accuracy: 0.7792 - val_loss: 0.4783 - val_auc: 0.8228 - val_accuracy: 0.8008\n",
      "Epoch 32/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5052 - auc: 0.8004 - accuracy: 0.7794 - val_loss: 0.4782 - val_auc: 0.8223 - val_accuracy: 0.8004\n",
      "Epoch 33/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5058 - auc: 0.8024 - accuracy: 0.7786 - val_loss: 0.4792 - val_auc: 0.8223 - val_accuracy: 0.8008\n",
      "Epoch 34/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5028 - auc: 0.8051 - accuracy: 0.7808 - val_loss: 0.4790 - val_auc: 0.8220 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5046 - auc: 0.8024 - accuracy: 0.7766 - val_loss: 0.4810 - val_auc: 0.8211 - val_accuracy: 0.8012\n",
      "Epoch 36/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5034 - auc: 0.8037 - accuracy: 0.7803 - val_loss: 0.4769 - val_auc: 0.8246 - val_accuracy: 0.8002\n",
      "Epoch 37/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5025 - auc: 0.8051 - accuracy: 0.7800 - val_loss: 0.4766 - val_auc: 0.8245 - val_accuracy: 0.7998\n",
      "Epoch 38/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5026 - auc: 0.8051 - accuracy: 0.7800 - val_loss: 0.4765 - val_auc: 0.8247 - val_accuracy: 0.7994\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5023 - auc: 0.8052 - accuracy: 0.7789 - val_loss: 0.4774 - val_auc: 0.8246 - val_accuracy: 0.7987\n",
      "Epoch 40/100\n",
      "616/616 [==============================] - 9s 15ms/step - loss: 0.5005 - auc: 0.8076 - accuracy: 0.7808 - val_loss: 0.4783 - val_auc: 0.8240 - val_accuracy: 0.8006\n",
      "Epoch 41/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5028 - auc: 0.8057 - accuracy: 0.7797 - val_loss: 0.4772 - val_auc: 0.8250 - val_accuracy: 0.8004\n",
      "Epoch 42/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5006 - auc: 0.8080 - accuracy: 0.7798 - val_loss: 0.4772 - val_auc: 0.8261 - val_accuracy: 0.8006\n",
      "Epoch 43/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5022 - auc: 0.8073 - accuracy: 0.7795 - val_loss: 0.4795 - val_auc: 0.8242 - val_accuracy: 0.7994\n",
      "Epoch 44/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5001 - auc: 0.8091 - accuracy: 0.7816 - val_loss: 0.4786 - val_auc: 0.8268 - val_accuracy: 0.7990\n",
      "Epoch 45/100\n",
      "616/616 [==============================] - 9s 15ms/step - loss: 0.4996 - auc: 0.8098 - accuracy: 0.7808 - val_loss: 0.4806 - val_auc: 0.8253 - val_accuracy: 0.7985\n",
      "Epoch 46/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5002 - auc: 0.8099 - accuracy: 0.7796 - val_loss: 0.4762 - val_auc: 0.8279 - val_accuracy: 0.7998\n",
      "Epoch 47/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.4994 - auc: 0.8105 - accuracy: 0.7816 - val_loss: 0.4775 - val_auc: 0.8267 - val_accuracy: 0.8006\n",
      "Epoch 48/100\n",
      "616/616 [==============================] - 9s 15ms/step - loss: 0.4996 - auc: 0.8091 - accuracy: 0.7799 - val_loss: 0.4783 - val_auc: 0.8262 - val_accuracy: 0.7998\n",
      "Epoch 49/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.4985 - auc: 0.8118 - accuracy: 0.7810 - val_loss: 0.4757 - val_auc: 0.8268 - val_accuracy: 0.8000\n",
      "Epoch 50/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.4986 - auc: 0.8104 - accuracy: 0.7814 - val_loss: 0.4773 - val_auc: 0.8268 - val_accuracy: 0.7987\n",
      "Epoch 51/100\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.5000 - auc: 0.8093 - accuracy: 0.7816 - val_loss: 0.4761 - val_auc: 0.8266 - val_accuracy: 0.7996\n",
      "\n",
      "\n",
      "Train data shape: (20669, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 2th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.6615 - auc: 0.5709 - accuracy: 0.5532 - val_loss: 0.6258 - val_auc: 0.5118 - val_accuracy: 0.5754\n",
      "Epoch 2/100\n",
      "646/646 [==============================] - 10s 15ms/step - loss: 0.6221 - auc: 0.5353 - accuracy: 0.6103 - val_loss: 0.6022 - val_auc: 0.5360 - val_accuracy: 0.6140\n",
      "Epoch 3/100\n",
      "646/646 [==============================] - 10s 15ms/step - loss: 0.6121 - auc: 0.5457 - accuracy: 0.6196 - val_loss: 0.5848 - val_auc: 0.5559 - val_accuracy: 0.6396\n",
      "Epoch 4/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.6036 - auc: 0.5578 - accuracy: 0.6309 - val_loss: 0.5823 - val_auc: 0.5659 - val_accuracy: 0.6479\n",
      "Epoch 5/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5977 - auc: 0.5697 - accuracy: 0.6409 - val_loss: 0.5670 - val_auc: 0.5879 - val_accuracy: 0.6529\n",
      "Epoch 6/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5945 - auc: 0.5796 - accuracy: 0.6465 - val_loss: 0.5676 - val_auc: 0.5956 - val_accuracy: 0.6604\n",
      "Epoch 7/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5924 - auc: 0.5875 - accuracy: 0.6508 - val_loss: 0.5650 - val_auc: 0.6046 - val_accuracy: 0.6662\n",
      "Epoch 8/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5879 - auc: 0.5995 - accuracy: 0.6572 - val_loss: 0.5616 - val_auc: 0.6158 - val_accuracy: 0.6827\n",
      "Epoch 9/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5866 - auc: 0.6072 - accuracy: 0.6648 - val_loss: 0.5525 - val_auc: 0.6341 - val_accuracy: 0.6931\n",
      "Epoch 10/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5825 - auc: 0.6149 - accuracy: 0.6712 - val_loss: 0.5550 - val_auc: 0.6336 - val_accuracy: 0.6900\n",
      "Epoch 11/100\n",
      "646/646 [==============================] - 9s 15ms/step - loss: 0.5791 - auc: 0.6226 - accuracy: 0.6756 - val_loss: 0.5548 - val_auc: 0.6411 - val_accuracy: 0.6835\n",
      "Epoch 12/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5793 - auc: 0.6268 - accuracy: 0.6785 - val_loss: 0.5428 - val_auc: 0.6587 - val_accuracy: 0.7056\n",
      "Epoch 13/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5780 - auc: 0.6332 - accuracy: 0.6848 - val_loss: 0.5420 - val_auc: 0.6658 - val_accuracy: 0.7248\n",
      "Epoch 14/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5746 - auc: 0.6409 - accuracy: 0.6923 - val_loss: 0.5389 - val_auc: 0.6702 - val_accuracy: 0.7362\n",
      "Epoch 15/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5723 - auc: 0.6465 - accuracy: 0.6957 - val_loss: 0.5341 - val_auc: 0.6783 - val_accuracy: 0.7319\n",
      "Epoch 16/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5715 - auc: 0.6528 - accuracy: 0.7017 - val_loss: 0.5349 - val_auc: 0.6873 - val_accuracy: 0.7319\n",
      "Epoch 17/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5696 - auc: 0.6605 - accuracy: 0.7045 - val_loss: 0.5241 - val_auc: 0.7010 - val_accuracy: 0.7581\n",
      "Epoch 18/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5674 - auc: 0.6675 - accuracy: 0.7105 - val_loss: 0.5304 - val_auc: 0.7074 - val_accuracy: 0.7531\n",
      "Epoch 19/100\n",
      "646/646 [==============================] - 10s 15ms/step - loss: 0.5660 - auc: 0.6755 - accuracy: 0.7149 - val_loss: 0.5283 - val_auc: 0.7131 - val_accuracy: 0.7633\n",
      "Epoch 20/100\n",
      "646/646 [==============================] - 10s 15ms/step - loss: 0.5611 - auc: 0.6873 - accuracy: 0.7243 - val_loss: 0.5239 - val_auc: 0.7239 - val_accuracy: 0.7654\n",
      "Epoch 21/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5601 - auc: 0.6954 - accuracy: 0.7294 - val_loss: 0.5148 - val_auc: 0.7439 - val_accuracy: 0.7812\n",
      "Epoch 22/100\n",
      "646/646 [==============================] - 10s 15ms/step - loss: 0.5558 - auc: 0.7079 - accuracy: 0.7356 - val_loss: 0.5158 - val_auc: 0.7618 - val_accuracy: 0.7827\n",
      "Epoch 23/100\n",
      "646/646 [==============================] - 9s 15ms/step - loss: 0.5534 - auc: 0.7261 - accuracy: 0.7423 - val_loss: 0.5108 - val_auc: 0.7763 - val_accuracy: 0.7883\n",
      "Epoch 24/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5510 - auc: 0.7401 - accuracy: 0.7470 - val_loss: 0.5067 - val_auc: 0.7899 - val_accuracy: 0.8004\n",
      "Epoch 25/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5470 - auc: 0.7535 - accuracy: 0.7533 - val_loss: 0.5035 - val_auc: 0.8074 - val_accuracy: 0.8012\n",
      "Epoch 26/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5471 - auc: 0.7607 - accuracy: 0.7525 - val_loss: 0.4976 - val_auc: 0.8100 - val_accuracy: 0.8023\n",
      "Epoch 27/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5436 - auc: 0.7680 - accuracy: 0.7535 - val_loss: 0.4996 - val_auc: 0.8100 - val_accuracy: 0.8017\n",
      "Epoch 28/100\n",
      "646/646 [==============================] - 11s 17ms/step - loss: 0.5409 - auc: 0.7729 - accuracy: 0.7538 - val_loss: 0.4907 - val_auc: 0.8229 - val_accuracy: 0.8010\n",
      "Epoch 29/100\n",
      "646/646 [==============================] - 11s 17ms/step - loss: 0.5415 - auc: 0.7738 - accuracy: 0.7543 - val_loss: 0.4901 - val_auc: 0.8239 - val_accuracy: 0.8006\n",
      "Epoch 30/100\n",
      "646/646 [==============================] - 10s 15ms/step - loss: 0.5404 - auc: 0.7744 - accuracy: 0.7551 - val_loss: 0.4886 - val_auc: 0.8249 - val_accuracy: 0.8015\n",
      "Epoch 31/100\n",
      "646/646 [==============================] - 10s 15ms/step - loss: 0.5405 - auc: 0.7753 - accuracy: 0.7556 - val_loss: 0.4869 - val_auc: 0.8235 - val_accuracy: 0.8021\n",
      "Epoch 32/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5389 - auc: 0.7770 - accuracy: 0.7571 - val_loss: 0.4908 - val_auc: 0.8207 - val_accuracy: 0.8021\n",
      "Epoch 33/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5379 - auc: 0.7795 - accuracy: 0.7546 - val_loss: 0.4884 - val_auc: 0.8248 - val_accuracy: 0.8017\n",
      "Epoch 34/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5369 - auc: 0.7809 - accuracy: 0.7551 - val_loss: 0.4837 - val_auc: 0.8285 - val_accuracy: 0.8027\n",
      "Epoch 35/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5388 - auc: 0.7782 - accuracy: 0.7549 - val_loss: 0.4830 - val_auc: 0.8283 - val_accuracy: 0.8040\n",
      "Epoch 36/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5384 - auc: 0.7789 - accuracy: 0.7530 - val_loss: 0.4839 - val_auc: 0.8295 - val_accuracy: 0.8027\n",
      "Epoch 37/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5380 - auc: 0.7787 - accuracy: 0.7536 - val_loss: 0.4827 - val_auc: 0.8287 - val_accuracy: 0.8033\n",
      "Epoch 38/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5363 - auc: 0.7804 - accuracy: 0.7549 - val_loss: 0.4918 - val_auc: 0.8230 - val_accuracy: 0.8008\n",
      "Epoch 39/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5355 - auc: 0.7803 - accuracy: 0.7560 - val_loss: 0.4878 - val_auc: 0.8238 - val_accuracy: 0.8025\n",
      "Epoch 40/100\n",
      "646/646 [==============================] - 9s 15ms/step - loss: 0.5354 - auc: 0.7813 - accuracy: 0.7570 - val_loss: 0.4825 - val_auc: 0.8284 - val_accuracy: 0.8023\n",
      "Epoch 41/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5368 - auc: 0.7802 - accuracy: 0.7552 - val_loss: 0.4791 - val_auc: 0.8306 - val_accuracy: 0.8029\n",
      "Epoch 42/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5354 - auc: 0.7823 - accuracy: 0.7570 - val_loss: 0.4859 - val_auc: 0.8283 - val_accuracy: 0.8023\n",
      "Epoch 43/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5368 - auc: 0.7814 - accuracy: 0.7558 - val_loss: 0.4840 - val_auc: 0.8294 - val_accuracy: 0.8029\n",
      "Epoch 44/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5357 - auc: 0.7818 - accuracy: 0.7545 - val_loss: 0.4793 - val_auc: 0.8307 - val_accuracy: 0.8040\n",
      "Epoch 45/100\n",
      "646/646 [==============================] - 10s 15ms/step - loss: 0.5353 - auc: 0.7810 - accuracy: 0.7561 - val_loss: 0.4821 - val_auc: 0.8277 - val_accuracy: 0.8037\n",
      "Epoch 46/100\n",
      "646/646 [==============================] - 10s 15ms/step - loss: 0.5349 - auc: 0.7814 - accuracy: 0.7559 - val_loss: 0.4798 - val_auc: 0.8299 - val_accuracy: 0.8029\n",
      "Epoch 47/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5341 - auc: 0.7814 - accuracy: 0.7564 - val_loss: 0.4789 - val_auc: 0.8284 - val_accuracy: 0.8033\n",
      "Epoch 48/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5329 - auc: 0.7829 - accuracy: 0.7588 - val_loss: 0.4832 - val_auc: 0.8280 - val_accuracy: 0.8033\n",
      "Epoch 49/100\n",
      "646/646 [==============================] - 9s 14ms/step - loss: 0.5344 - auc: 0.7815 - accuracy: 0.7556 - val_loss: 0.4799 - val_auc: 0.8277 - val_accuracy: 0.8027\n",
      "\n",
      "\n",
      "Train data shape: (21629, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 3th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "676/676 [==============================] - 12s 18ms/step - loss: 0.6793 - auc: 0.5661 - accuracy: 0.5414 - val_loss: 0.6319 - val_auc: 0.5243 - val_accuracy: 0.5931\n",
      "Epoch 2/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.6460 - auc: 0.5321 - accuracy: 0.5873 - val_loss: 0.6024 - val_auc: 0.5562 - val_accuracy: 0.6285\n",
      "Epoch 3/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.6340 - auc: 0.5470 - accuracy: 0.6040 - val_loss: 0.5964 - val_auc: 0.5719 - val_accuracy: 0.6454\n",
      "Epoch 4/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.6265 - auc: 0.5628 - accuracy: 0.6211 - val_loss: 0.5842 - val_auc: 0.5921 - val_accuracy: 0.6696\n",
      "Epoch 5/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.6200 - auc: 0.5738 - accuracy: 0.6355 - val_loss: 0.5797 - val_auc: 0.6065 - val_accuracy: 0.6931\n",
      "Epoch 6/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.6141 - auc: 0.5853 - accuracy: 0.6495 - val_loss: 0.5644 - val_auc: 0.6279 - val_accuracy: 0.6998\n",
      "Epoch 7/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.6085 - auc: 0.5971 - accuracy: 0.6589 - val_loss: 0.5657 - val_auc: 0.6324 - val_accuracy: 0.7013\n",
      "Epoch 8/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.6045 - auc: 0.6050 - accuracy: 0.6685 - val_loss: 0.5598 - val_auc: 0.6461 - val_accuracy: 0.7208\n",
      "Epoch 9/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5998 - auc: 0.6180 - accuracy: 0.6801 - val_loss: 0.5522 - val_auc: 0.6620 - val_accuracy: 0.7373\n",
      "Epoch 10/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5949 - auc: 0.6318 - accuracy: 0.6902 - val_loss: 0.5437 - val_auc: 0.6817 - val_accuracy: 0.7462\n",
      "Epoch 11/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5898 - auc: 0.6480 - accuracy: 0.7004 - val_loss: 0.5392 - val_auc: 0.7059 - val_accuracy: 0.7550\n",
      "Epoch 12/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5840 - auc: 0.6655 - accuracy: 0.7063 - val_loss: 0.5290 - val_auc: 0.7354 - val_accuracy: 0.7750\n",
      "Epoch 13/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5806 - auc: 0.6872 - accuracy: 0.7210 - val_loss: 0.5225 - val_auc: 0.7554 - val_accuracy: 0.7767\n",
      "Epoch 14/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5758 - auc: 0.7128 - accuracy: 0.7270 - val_loss: 0.5333 - val_auc: 0.7668 - val_accuracy: 0.7906\n",
      "Epoch 15/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5719 - auc: 0.7313 - accuracy: 0.7287 - val_loss: 0.5109 - val_auc: 0.8037 - val_accuracy: 0.7983\n",
      "Epoch 16/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5690 - auc: 0.7430 - accuracy: 0.7323 - val_loss: 0.5041 - val_auc: 0.8049 - val_accuracy: 0.7977\n",
      "Epoch 17/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5674 - auc: 0.7484 - accuracy: 0.7298 - val_loss: 0.5082 - val_auc: 0.8063 - val_accuracy: 0.7973\n",
      "Epoch 18/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5649 - auc: 0.7514 - accuracy: 0.7311 - val_loss: 0.5031 - val_auc: 0.8111 - val_accuracy: 0.7973\n",
      "Epoch 19/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5637 - auc: 0.7565 - accuracy: 0.7324 - val_loss: 0.4974 - val_auc: 0.8214 - val_accuracy: 0.7996\n",
      "Epoch 20/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5618 - auc: 0.7608 - accuracy: 0.7352 - val_loss: 0.4953 - val_auc: 0.8224 - val_accuracy: 0.8002\n",
      "Epoch 21/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5619 - auc: 0.7581 - accuracy: 0.7329 - val_loss: 0.5023 - val_auc: 0.8187 - val_accuracy: 0.7994\n",
      "Epoch 22/100\n",
      "676/676 [==============================] - 10s 16ms/step - loss: 0.5623 - auc: 0.7611 - accuracy: 0.7326 - val_loss: 0.4962 - val_auc: 0.8240 - val_accuracy: 0.7987\n",
      "Epoch 23/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5622 - auc: 0.7613 - accuracy: 0.7321 - val_loss: 0.4983 - val_auc: 0.8233 - val_accuracy: 0.7996\n",
      "Epoch 24/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5617 - auc: 0.7618 - accuracy: 0.7333 - val_loss: 0.4886 - val_auc: 0.8293 - val_accuracy: 0.8012\n",
      "Epoch 25/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5615 - auc: 0.7619 - accuracy: 0.7331 - val_loss: 0.4897 - val_auc: 0.8275 - val_accuracy: 0.8015\n",
      "Epoch 26/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5609 - auc: 0.7626 - accuracy: 0.7347 - val_loss: 0.4936 - val_auc: 0.8239 - val_accuracy: 0.8012\n",
      "Epoch 27/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5589 - auc: 0.7652 - accuracy: 0.7341 - val_loss: 0.4984 - val_auc: 0.8257 - val_accuracy: 0.7985\n",
      "Epoch 28/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5620 - auc: 0.7624 - accuracy: 0.7340 - val_loss: 0.4985 - val_auc: 0.8243 - val_accuracy: 0.7973\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5599 - auc: 0.7657 - accuracy: 0.7330 - val_loss: 0.4994 - val_auc: 0.8199 - val_accuracy: 0.7973\n",
      "\n",
      "\n",
      "Train data shape: (22589, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 4th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6801 - auc: 0.5965 - accuracy: 0.5645 - val_loss: 0.6589 - val_auc: 0.5246 - val_accuracy: 0.5581\n",
      "Epoch 2/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.6437 - auc: 0.5492 - accuracy: 0.6067 - val_loss: 0.6157 - val_auc: 0.5588 - val_accuracy: 0.6200\n",
      "Epoch 3/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.6291 - auc: 0.5596 - accuracy: 0.6281 - val_loss: 0.5868 - val_auc: 0.5866 - val_accuracy: 0.6821\n",
      "Epoch 4/100\n",
      "706/706 [==============================] - 12s 16ms/step - loss: 0.6231 - auc: 0.5688 - accuracy: 0.6421 - val_loss: 0.5787 - val_auc: 0.5975 - val_accuracy: 0.6804\n",
      "Epoch 5/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.6170 - auc: 0.5828 - accuracy: 0.6535 - val_loss: 0.5660 - val_auc: 0.6229 - val_accuracy: 0.6860\n",
      "Epoch 6/100\n",
      "706/706 [==============================] - 12s 16ms/step - loss: 0.6145 - auc: 0.5940 - accuracy: 0.6607 - val_loss: 0.5612 - val_auc: 0.6467 - val_accuracy: 0.7350\n",
      "Epoch 7/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.6102 - auc: 0.6114 - accuracy: 0.6728 - val_loss: 0.5584 - val_auc: 0.6599 - val_accuracy: 0.7240\n",
      "Epoch 8/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.6057 - auc: 0.6261 - accuracy: 0.6788 - val_loss: 0.5499 - val_auc: 0.6820 - val_accuracy: 0.7423\n",
      "Epoch 9/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.6024 - auc: 0.6404 - accuracy: 0.6889 - val_loss: 0.5482 - val_auc: 0.7004 - val_accuracy: 0.7444\n",
      "Epoch 10/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.6002 - auc: 0.6568 - accuracy: 0.6941 - val_loss: 0.5456 - val_auc: 0.7176 - val_accuracy: 0.7567\n",
      "Epoch 11/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5961 - auc: 0.6724 - accuracy: 0.7011 - val_loss: 0.5294 - val_auc: 0.7446 - val_accuracy: 0.7904\n",
      "Epoch 12/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5917 - auc: 0.6868 - accuracy: 0.7077 - val_loss: 0.5267 - val_auc: 0.7589 - val_accuracy: 0.7898\n",
      "Epoch 13/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5893 - auc: 0.7014 - accuracy: 0.7103 - val_loss: 0.5282 - val_auc: 0.7693 - val_accuracy: 0.7917\n",
      "Epoch 14/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5871 - auc: 0.7119 - accuracy: 0.7131 - val_loss: 0.5155 - val_auc: 0.7891 - val_accuracy: 0.8015\n",
      "Epoch 15/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5869 - auc: 0.7181 - accuracy: 0.7142 - val_loss: 0.5081 - val_auc: 0.8059 - val_accuracy: 0.8023\n",
      "Epoch 16/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5834 - auc: 0.7274 - accuracy: 0.7185 - val_loss: 0.5242 - val_auc: 0.7924 - val_accuracy: 0.7960\n",
      "Epoch 17/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5822 - auc: 0.7310 - accuracy: 0.7183 - val_loss: 0.5166 - val_auc: 0.8035 - val_accuracy: 0.7954\n",
      "Epoch 18/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5810 - auc: 0.7350 - accuracy: 0.7172 - val_loss: 0.5024 - val_auc: 0.8161 - val_accuracy: 0.8044\n",
      "Epoch 19/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5812 - auc: 0.7335 - accuracy: 0.7185 - val_loss: 0.5020 - val_auc: 0.8174 - val_accuracy: 0.8035\n",
      "Epoch 20/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5788 - auc: 0.7396 - accuracy: 0.7207 - val_loss: 0.5012 - val_auc: 0.8194 - val_accuracy: 0.8012\n",
      "Epoch 21/100\n",
      "706/706 [==============================] - 12s 16ms/step - loss: 0.5795 - auc: 0.7406 - accuracy: 0.7191 - val_loss: 0.5016 - val_auc: 0.8195 - val_accuracy: 0.8033\n",
      "Epoch 22/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5775 - auc: 0.7420 - accuracy: 0.7207 - val_loss: 0.4952 - val_auc: 0.8219 - val_accuracy: 0.8031\n",
      "Epoch 23/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5783 - auc: 0.7426 - accuracy: 0.7204 - val_loss: 0.4993 - val_auc: 0.8209 - val_accuracy: 0.8040\n",
      "Epoch 24/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5783 - auc: 0.7415 - accuracy: 0.7201 - val_loss: 0.5018 - val_auc: 0.8190 - val_accuracy: 0.8050\n",
      "Epoch 25/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5764 - auc: 0.7427 - accuracy: 0.7189 - val_loss: 0.4932 - val_auc: 0.8206 - val_accuracy: 0.8033\n",
      "Epoch 26/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5765 - auc: 0.7424 - accuracy: 0.7204 - val_loss: 0.4957 - val_auc: 0.8220 - val_accuracy: 0.8046\n",
      "Epoch 27/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5759 - auc: 0.7441 - accuracy: 0.7211 - val_loss: 0.4977 - val_auc: 0.8210 - val_accuracy: 0.8035\n",
      "Epoch 28/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5756 - auc: 0.7458 - accuracy: 0.7199 - val_loss: 0.5088 - val_auc: 0.8154 - val_accuracy: 0.8033\n",
      "Epoch 29/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5748 - auc: 0.7454 - accuracy: 0.7207 - val_loss: 0.5004 - val_auc: 0.8212 - val_accuracy: 0.8033\n",
      "Epoch 30/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5773 - auc: 0.7443 - accuracy: 0.7200 - val_loss: 0.5019 - val_auc: 0.8195 - val_accuracy: 0.8035\n",
      "Epoch 31/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5745 - auc: 0.7468 - accuracy: 0.7213 - val_loss: 0.4929 - val_auc: 0.8237 - val_accuracy: 0.8050\n",
      "Epoch 32/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5742 - auc: 0.7474 - accuracy: 0.7210 - val_loss: 0.4961 - val_auc: 0.8250 - val_accuracy: 0.8044\n",
      "Epoch 33/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5748 - auc: 0.7474 - accuracy: 0.7199 - val_loss: 0.4999 - val_auc: 0.8215 - val_accuracy: 0.8050\n",
      "Epoch 34/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5724 - auc: 0.7486 - accuracy: 0.7217 - val_loss: 0.5025 - val_auc: 0.8206 - val_accuracy: 0.8033\n",
      "Epoch 35/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.5735 - auc: 0.7470 - accuracy: 0.7200 - val_loss: 0.4938 - val_auc: 0.8235 - val_accuracy: 0.8035\n",
      "Epoch 36/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5735 - auc: 0.7486 - accuracy: 0.7229 - val_loss: 0.4940 - val_auc: 0.8250 - val_accuracy: 0.8040oss: 0.5731 - auc: 0.7485 - accuracy: 0.72 - ETA: 5s - loss: 0.5726 - auc: 0.7490 - accura - E - ETA: 0s - loss: 0.5721 - \n",
      "Epoch 37/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5731 - auc: 0.7479 - accuracy: 0.7210 - val_loss: 0.4984 - val_auc: 0.8217 - val_accuracy: 0.8037\n",
      "Epoch 38/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5720 - auc: 0.7493 - accuracy: 0.7220 - val_loss: 0.4895 - val_auc: 0.8275 - val_accuracy: 0.8056\n",
      "Epoch 39/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5727 - auc: 0.7502 - accuracy: 0.7211 - val_loss: 0.4906 - val_auc: 0.8270 - val_accuracy: 0.8048.7500 - accuracy: \n",
      "Epoch 40/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5721 - auc: 0.7495 - accuracy: 0.7219 - val_loss: 0.4917 - val_auc: 0.8274 - val_accuracy: 0.8054\n",
      "Epoch 41/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5727 - auc: 0.7497 - accuracy: 0.7219 - val_loss: 0.4953 - val_auc: 0.8223 - val_accuracy: 0.8031\n",
      "Epoch 42/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5697 - auc: 0.7501 - accuracy: 0.7238 - val_loss: 0.4922 - val_auc: 0.8229 - val_accuracy: 0.8065\n",
      "Epoch 43/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5706 - auc: 0.7491 - accuracy: 0.7222 - val_loss: 0.4937 - val_auc: 0.8231 - val_accuracy: 0.8054\n",
      "\n",
      "\n",
      "Train data shape: (23549, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 5th sample\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "736/736 [==============================] - 16s 22ms/step - loss: 0.6779 - auc: 0.5669 - accuracy: 0.5585 - val_loss: 0.6159 - val_auc: 0.5479 - val_accuracy: 0.6250 0.5675 - accuracy\n",
      "Epoch 2/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.6570 - auc: 0.5342 - accuracy: 0.5879 - val_loss: 0.6075 - val_auc: 0.5513 - val_accuracy: 0.6473\n",
      "Epoch 3/100\n",
      "736/736 [==============================] - 13s 18ms/step - loss: 0.6523 - auc: 0.5392 - accuracy: 0.5980 - val_loss: 0.6046 - val_auc: 0.5582 - val_accuracy: 0.6504\n",
      "Epoch 4/100\n",
      "736/736 [==============================] - 13s 18ms/step - loss: 0.6457 - auc: 0.5474 - accuracy: 0.6099 - val_loss: 0.6057 - val_auc: 0.5695 - val_accuracy: 0.6477\n",
      "Epoch 5/100\n",
      "736/736 [==============================] - 13s 18ms/step - loss: 0.6421 - auc: 0.5560 - accuracy: 0.6194 - val_loss: 0.5966 - val_auc: 0.5847 - val_accuracy: 0.6810\n",
      "Epoch 6/100\n",
      "736/736 [==============================] - 14s 19ms/step - loss: 0.6389 - auc: 0.5632 - accuracy: 0.6263 - val_loss: 0.5892 - val_auc: 0.5947 - val_accuracy: 0.6744\n",
      "Epoch 7/100\n",
      "736/736 [==============================] - 13s 18ms/step - loss: 0.6344 - auc: 0.5735 - accuracy: 0.6358 - val_loss: 0.5811 - val_auc: 0.6124 - val_accuracy: 0.6819\n",
      "Epoch 8/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.6325 - auc: 0.5827 - accuracy: 0.6432 - val_loss: 0.5836 - val_auc: 0.6283 - val_accuracy: 0.6950\n",
      "Epoch 9/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.6298 - auc: 0.5935 - accuracy: 0.6472 - val_loss: 0.5741 - val_auc: 0.6457 - val_accuracy: 0.7113\n",
      "Epoch 10/100\n",
      "736/736 [==============================] - 13s 18ms/step - loss: 0.6272 - auc: 0.6029 - accuracy: 0.6536 - val_loss: 0.5754 - val_auc: 0.6548 - val_accuracy: 0.7192\n",
      "Epoch 11/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.6237 - auc: 0.6163 - accuracy: 0.6580 - val_loss: 0.5655 - val_auc: 0.6754 - val_accuracy: 0.7310\n",
      "Epoch 12/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.6206 - auc: 0.6277 - accuracy: 0.6650 - val_loss: 0.5643 - val_auc: 0.6935 - val_accuracy: 0.7392\n",
      "Epoch 13/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.6176 - auc: 0.6404 - accuracy: 0.6718 - val_loss: 0.5607 - val_auc: 0.7177 - val_accuracy: 0.7350\n",
      "Epoch 14/100\n",
      "736/736 [==============================] - 13s 18ms/step - loss: 0.6164 - auc: 0.6536 - accuracy: 0.6729 - val_loss: 0.5544 - val_auc: 0.7266 - val_accuracy: 0.7585\n",
      "Epoch 15/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.6120 - auc: 0.6665 - accuracy: 0.6767 - val_loss: 0.5498 - val_auc: 0.7330 - val_accuracy: 0.7615\n",
      "Epoch 16/100\n",
      "736/736 [==============================] - 13s 18ms/step - loss: 0.6115 - auc: 0.6770 - accuracy: 0.6810 - val_loss: 0.5470 - val_auc: 0.7507 - val_accuracy: 0.7629\n",
      "Epoch 17/100\n",
      "736/736 [==============================] - 15s 20ms/step - loss: 0.6079 - auc: 0.6832 - accuracy: 0.6819 - val_loss: 0.5548 - val_auc: 0.7552 - val_accuracy: 0.7494\n",
      "Epoch 18/100\n",
      "736/736 [==============================] - 13s 18ms/step - loss: 0.6067 - auc: 0.6914 - accuracy: 0.6855 - val_loss: 0.5458 - val_auc: 0.7586 - val_accuracy: 0.7629\n",
      "Epoch 19/100\n",
      "736/736 [==============================] - 15s 20ms/step - loss: 0.6077 - auc: 0.6944 - accuracy: 0.6884 - val_loss: 0.5379 - val_auc: 0.7774 - val_accuracy: 0.7806\n",
      "Epoch 20/100\n",
      "736/736 [==============================] - 16s 21ms/step - loss: 0.6042 - auc: 0.6997 - accuracy: 0.6926 - val_loss: 0.5366 - val_auc: 0.7851 - val_accuracy: 0.7887\n",
      "Epoch 21/100\n",
      "736/736 [==============================] - 15s 20ms/step - loss: 0.6034 - auc: 0.7052 - accuracy: 0.6923 - val_loss: 0.5345 - val_auc: 0.7911 - val_accuracy: 0.7840\n",
      "Epoch 22/100\n",
      "736/736 [==============================] - 14s 18ms/step - loss: 0.6027 - auc: 0.7074 - accuracy: 0.6921 - val_loss: 0.5298 - val_auc: 0.8004 - val_accuracy: 0.7944\n",
      "Epoch 23/100\n",
      "736/736 [==============================] - 13s 18ms/step - loss: 0.6014 - auc: 0.7098 - accuracy: 0.6944 - val_loss: 0.5310 - val_auc: 0.8007 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.6015 - auc: 0.7137 - accuracy: 0.6973 - val_loss: 0.5199 - val_auc: 0.8075 - val_accuracy: 0.7971\n",
      "Epoch 25/100\n",
      "736/736 [==============================] - 13s 18ms/step - loss: 0.6003 - auc: 0.7170 - accuracy: 0.6960 - val_loss: 0.5266 - val_auc: 0.8077 - val_accuracy: 0.7969\n",
      "Epoch 26/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.6015 - auc: 0.7161 - accuracy: 0.6942 - val_loss: 0.5233 - val_auc: 0.8102 - val_accuracy: 0.7962\n",
      "Epoch 27/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.5992 - auc: 0.7172 - accuracy: 0.6956 - val_loss: 0.5215 - val_auc: 0.8075 - val_accuracy: 0.7981\n",
      "Epoch 28/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.5994 - auc: 0.7190 - accuracy: 0.6953 - val_loss: 0.5254 - val_auc: 0.8035 - val_accuracy: 0.7956\n",
      "Epoch 29/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.6000 - auc: 0.7168 - accuracy: 0.6961 - val_loss: 0.5204 - val_auc: 0.8128 - val_accuracy: 0.7919 l\n",
      "Epoch 30/100\n",
      "736/736 [==============================] - 12s 17ms/step - loss: 0.5991 - auc: 0.7205 - accuracy: 0.6996 - val_loss: 0.5247 - val_auc: 0.8114 - val_accuracy: 0.7958\n",
      "Epoch 31/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.5968 - auc: 0.7230 - accuracy: 0.6991 - val_loss: 0.5136 - val_auc: 0.8174 - val_accuracy: 0.7994\n",
      "Epoch 32/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.5960 - auc: 0.7237 - accuracy: 0.6990 - val_loss: 0.5229 - val_auc: 0.8135 - val_accuracy: 0.7952\n",
      "Epoch 33/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.5944 - auc: 0.7268 - accuracy: 0.6999 - val_loss: 0.5142 - val_auc: 0.8157 - val_accuracy: 0.7973\n",
      "Epoch 34/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.5977 - auc: 0.7225 - accuracy: 0.6964 - val_loss: 0.5204 - val_auc: 0.8132 - val_accuracy: 0.7940.5989 - auc: 0.7211 - accu - ETA: 0s - loss: 0.5989 - auc:\n",
      "Epoch 35/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.5978 - auc: 0.7219 - accuracy: 0.6995 - val_loss: 0.5254 - val_auc: 0.7962 - val_accuracy: 0.7929\n",
      "Epoch 36/100\n",
      "736/736 [==============================] - 12s 17ms/step - loss: 0.5959 - auc: 0.7239 - accuracy: 0.7005 - val_loss: 0.5107 - val_auc: 0.8202 - val_accuracy: 0.8006\n",
      "Epoch 37/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.5964 - auc: 0.7230 - accuracy: 0.6987 - val_loss: 0.5174 - val_auc: 0.8165 - val_accuracy: 0.8010\n",
      "Epoch 38/100\n",
      "736/736 [==============================] - 13s 18ms/step - loss: 0.5952 - auc: 0.7235 - accuracy: 0.6988 - val_loss: 0.5231 - val_auc: 0.8023 - val_accuracy: 0.7952\n",
      "Epoch 39/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.5972 - auc: 0.7213 - accuracy: 0.6994 - val_loss: 0.5176 - val_auc: 0.8117 - val_accuracy: 0.7973\n",
      "Epoch 40/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.5966 - auc: 0.7220 - accuracy: 0.6964 - val_loss: 0.5084 - val_auc: 0.8215 - val_accuracy: 0.8010\n",
      "Epoch 41/100\n",
      "736/736 [==============================] - 12s 17ms/step - loss: 0.5953 - auc: 0.7237 - accuracy: 0.7004 - val_loss: 0.5081 - val_auc: 0.8192 - val_accuracy: 0.7992\n",
      "Epoch 42/100\n",
      "736/736 [==============================] - 13s 18ms/step - loss: 0.5936 - auc: 0.7262 - accuracy: 0.7030 - val_loss: 0.5208 - val_auc: 0.8106 - val_accuracy: 0.7960\n",
      "Epoch 43/100\n",
      "736/736 [==============================] - 12s 17ms/step - loss: 0.5955 - auc: 0.7230 - accuracy: 0.7005 - val_loss: 0.5097 - val_auc: 0.8202 - val_accuracy: 0.8010\n",
      "Epoch 44/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.5929 - auc: 0.7244 - accuracy: 0.7002 - val_loss: 0.5050 - val_auc: 0.8217 - val_accuracy: 0.8025\n",
      "Epoch 45/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.5931 - auc: 0.7257 - accuracy: 0.7021 - val_loss: 0.5086 - val_auc: 0.8220 - val_accuracy: 0.8031\n",
      "Epoch 46/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.5924 - auc: 0.7253 - accuracy: 0.7009 - val_loss: 0.5105 - val_auc: 0.8195 - val_accuracy: 0.7996\n",
      "Epoch 47/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.5925 - auc: 0.7257 - accuracy: 0.7015 - val_loss: 0.5173 - val_auc: 0.8129 - val_accuracy: 0.7987\n",
      "Epoch 48/100\n",
      "736/736 [==============================] - 13s 18ms/step - loss: 0.5938 - auc: 0.7243 - accuracy: 0.7006 - val_loss: 0.5187 - val_auc: 0.8102 - val_accuracy: 0.7985\n",
      "Epoch 49/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.5922 - auc: 0.7255 - accuracy: 0.7017 - val_loss: 0.5143 - val_auc: 0.8177 - val_accuracy: 0.7994\n",
      "Epoch 50/100\n",
      "736/736 [==============================] - 12s 17ms/step - loss: 0.5926 - auc: 0.7251 - accuracy: 0.7025 - val_loss: 0.5152 - val_auc: 0.8141 - val_accuracy: 0.7967\n",
      "\n",
      "\n",
      "Train data shape: (24509, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 6th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 15s 20ms/step - loss: 0.6915 - auc: 0.5675 - accuracy: 0.5571 - val_loss: 0.6522 - val_auc: 0.5317 - val_accuracy: 0.5908\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.6677 - auc: 0.5281 - accuracy: 0.5757 - val_loss: 0.6292 - val_auc: 0.5467 - val_accuracy: 0.6217\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.6614 - auc: 0.5363 - accuracy: 0.5875 - val_loss: 0.6385 - val_auc: 0.5497 - val_accuracy: 0.6029\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.6556 - auc: 0.5442 - accuracy: 0.6011 - val_loss: 0.6168 - val_auc: 0.5721 - val_accuracy: 0.6498\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.6498 - auc: 0.5568 - accuracy: 0.6107 - val_loss: 0.6065 - val_auc: 0.5937 - val_accuracy: 0.6575\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6451 - auc: 0.5658 - accuracy: 0.6254 - val_loss: 0.5983 - val_auc: 0.6123 - val_accuracy: 0.6794\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.6399 - auc: 0.5783 - accuracy: 0.6360 - val_loss: 0.5968 - val_auc: 0.6364 - val_accuracy: 0.6954\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6346 - auc: 0.5979 - accuracy: 0.6447 - val_loss: 0.5846 - val_auc: 0.6649 - val_accuracy: 0.7144\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6302 - auc: 0.6143 - accuracy: 0.6577 - val_loss: 0.5787 - val_auc: 0.6912 - val_accuracy: 0.7248\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.6252 - auc: 0.6352 - accuracy: 0.6653 - val_loss: 0.5650 - val_auc: 0.7194 - val_accuracy: 0.7588\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6224 - auc: 0.6512 - accuracy: 0.6723 - val_loss: 0.5645 - val_auc: 0.7339 - val_accuracy: 0.7510\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.6181 - auc: 0.6700 - accuracy: 0.6753 - val_loss: 0.5515 - val_auc: 0.7704 - val_accuracy: 0.7785\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6147 - auc: 0.6843 - accuracy: 0.6820 - val_loss: 0.5430 - val_auc: 0.7925 - val_accuracy: 0.7952\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6132 - auc: 0.6936 - accuracy: 0.6835 - val_loss: 0.5508 - val_auc: 0.7892 - val_accuracy: 0.7900\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.6117 - auc: 0.7017 - accuracy: 0.6857 - val_loss: 0.5412 - val_auc: 0.8059 - val_accuracy: 0.7967\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6090 - auc: 0.7082 - accuracy: 0.6906 - val_loss: 0.5444 - val_auc: 0.8049 - val_accuracy: 0.7950\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6100 - auc: 0.7099 - accuracy: 0.6878 - val_loss: 0.5382 - val_auc: 0.8134 - val_accuracy: 0.7969\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 16s 20ms/step - loss: 0.6065 - auc: 0.7164 - accuracy: 0.6921 - val_loss: 0.5461 - val_auc: 0.8072 - val_accuracy: 0.7908\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.6056 - auc: 0.7180 - accuracy: 0.6933 - val_loss: 0.5436 - val_auc: 0.8097 - val_accuracy: 0.7933\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6056 - auc: 0.7192 - accuracy: 0.6917 - val_loss: 0.5432 - val_auc: 0.8080 - val_accuracy: 0.7894\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.6066 - auc: 0.7181 - accuracy: 0.6928 - val_loss: 0.5209 - val_auc: 0.8240 - val_accuracy: 0.8004\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.6058 - auc: 0.7180 - accuracy: 0.6924 - val_loss: 0.5293 - val_auc: 0.8182 - val_accuracy: 0.7983\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6034 - auc: 0.7206 - accuracy: 0.6933 - val_loss: 0.5290 - val_auc: 0.8196 - val_accuracy: 0.7994\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6023 - auc: 0.7228 - accuracy: 0.6934 - val_loss: 0.5243 - val_auc: 0.8214 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6019 - auc: 0.7246 - accuracy: 0.6940 - val_loss: 0.5226 - val_auc: 0.8199 - val_accuracy: 0.7971\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6009 - auc: 0.7251 - accuracy: 0.6968 - val_loss: 0.5306 - val_auc: 0.8178 - val_accuracy: 0.7975\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "plot_list = []\n",
    "model_list = []\n",
    "learning_rate = 0.00001\n",
    "model = RNN_Model(learning_rate)\n",
    "list_index = 0\n",
    "\n",
    "for (j, sample) in enumerate(sampling_list):\n",
    "    \n",
    "    X_train_preprocessing = sample[0]\n",
    "    X_train_add_feature = sample[1]\n",
    "    y_train_preprocessing = sample[3]\n",
    "    \n",
    "    length = len(X_train_preprocessing)\n",
    "    \n",
    "    print(\"Train data shape: {} Val data shape: {}\".format(X_train_preprocessing.shape, X_val_preprocessing.shape))\n",
    "    print(\"Training the model with {}th sample\".format(j))\n",
    "    print(\"-----------------------------------------------\")\n",
    "    \n",
    "    model = RNN_Model(learning_rate)\n",
    "    epoch, hist = train_model(model, [X_train_preprocessing, X_train_add_feature], y_train_preprocessing, \n",
    "                              [X_val_preprocessing, X_val_add_feature], y_val_preprocessing, epochs = epochs, batch_size = 32)\n",
    "    model_list.append(model)\n",
    "    plot_list.append([epoch, hist])\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    \n",
    "    true_positive_mask = np.logical_and((y_true == 1), (y_pred == 1))\n",
    "    true_negative_mask = np.logical_and((y_true == 0), (y_pred == 0))\n",
    "    condition_positive = (y_true == 1)\n",
    "    predicted_positive = (y_pred == 1)\n",
    "    \n",
    "    precision = np.sum(true_positive_mask) / np.sum(predicted_positive)\n",
    "    recall = np.sum(true_positive_mask) / np.sum(condition_positive)\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    acc = (np.sum(true_positive_mask) + np.sum(true_negative_mask)) / len(y_true)\n",
    "    \n",
    "    return precision, recall, f1, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the 0th model\n",
      "0th model's \u001b[35m Precision \u001b[30m: 67.35 \u001b[35m Recall \u001b[30m: 21.38 \u001b[35m F1-score \u001b[30m: 0.32 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n",
      "Predicting the 1th model\n",
      "1th model's \u001b[35m Precision \u001b[30m: 61.46 \u001b[35m Recall \u001b[30m: 27.54 \u001b[35m F1-score \u001b[30m: 0.38 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n",
      "Predicting the 2th model\n",
      "2th model's \u001b[35m Precision \u001b[30m: 63.83 \u001b[35m Recall \u001b[30m: 28.01 \u001b[35m F1-score \u001b[30m: 0.39 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n",
      "Predicting the 3th model\n",
      "3th model's \u001b[35m Precision \u001b[30m: 60.10 \u001b[35m Recall \u001b[30m: 32.49 \u001b[35m F1-score \u001b[30m: 0.42 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n",
      "Predicting the 4th model\n",
      "4th model's \u001b[35m Precision \u001b[30m: 61.02 \u001b[35m Recall \u001b[30m: 35.67 \u001b[35m F1-score \u001b[30m: 0.45 \u001b[35m Accuracy\u001b[30m: 0.81 \n",
      "\n",
      "Predicting the 5th model\n",
      "5th model's \u001b[35m Precision \u001b[30m: 60.10 \u001b[35m Recall \u001b[30m: 35.01 \u001b[35m F1-score \u001b[30m: 0.44 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n",
      "Predicting the 6th model\n",
      "6th model's \u001b[35m Precision \u001b[30m: 58.79 \u001b[35m Recall \u001b[30m: 35.29 \u001b[35m F1-score \u001b[30m: 0.44 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# f1-score\n",
    "for (i, sample) in enumerate(sampling_list):\n",
    "    \n",
    "    print(\"Predicting the {}th model\".format(i))\n",
    "    \n",
    "    model = model_list[i]\n",
    "    y_proba = model.predict([X_val_preprocessing, X_val_add_feature])\n",
    "    y_pred = np.argmax(y_proba, axis = 1)\n",
    "    \n",
    "    precision, recall, f1, accuracy = f1_score(y_val, y_pred)\n",
    "    print(\"{}th model's \\033[35m Precision \\033[30m: {:.2f} \\033[35m Recall \\033[30m: {:.2f} \\033[35m F1-score \\033[30m: {:.2f} \\033[35m Accuracy\\033[30m: {:.2f} \\n\".format(i, precision * 100, recall * 100, f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_list = np.array([.0] * (len(X_test) * 2)).reshape(-1, 2)\n",
    "\n",
    "for (i, model) in enumerate(model_list):\n",
    "    \n",
    "    y_proba = model.predict([X_test_preprocessing, X_test_add_feature])\n",
    "    proba_list += y_proba\n",
    "    \n",
    "y_pred = np.argmax((proba_list / len(model_list)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1, accuracy = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mPrecision\u001b[30m: 0.62, \u001b[35mRecall\u001b[30m: 0.30, \u001b[35mF1-Score\u001b[30m: 0.41, \u001b[35mAccuracy\u001b[30m: 0.81\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[35mPrecision\\033[30m: {:.2f}, \\033[35mRecall\\033[30m: {:.2f}, \\033[35mF1-Score\\033[30m: {:.2f}, \\033[35mAccuracy\\033[30m: {:.2f}\".format(precision, recall, f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (19196, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 0th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.6062 - auc: 0.5635 - accuracy: 0.5956 - val_loss: 0.5833 - val_auc: 0.5443 - val_accuracy: 0.6133\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.5599 - auc: 0.5644 - accuracy: 0.6467 - val_loss: 0.5507 - val_auc: 0.5833 - val_accuracy: 0.6625\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.5479 - auc: 0.5832 - accuracy: 0.6605 - val_loss: 0.5442 - val_auc: 0.5922 - val_accuracy: 0.6633\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.5437 - auc: 0.5974 - accuracy: 0.6716 - val_loss: 0.5348 - val_auc: 0.6115 - val_accuracy: 0.6837\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.5362 - auc: 0.6112 - accuracy: 0.6794 - val_loss: 0.5313 - val_auc: 0.6244 - val_accuracy: 0.6858\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.5311 - auc: 0.6223 - accuracy: 0.6842 - val_loss: 0.5274 - val_auc: 0.6348 - val_accuracy: 0.6919\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.5284 - auc: 0.6291 - accuracy: 0.6920 - val_loss: 0.5208 - val_auc: 0.6476 - val_accuracy: 0.6998\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.5229 - auc: 0.6393 - accuracy: 0.7021 - val_loss: 0.5170 - val_auc: 0.6556 - val_accuracy: 0.7152\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.5198 - auc: 0.6488 - accuracy: 0.7129 - val_loss: 0.5177 - val_auc: 0.6564 - val_accuracy: 0.7077\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.5151 - auc: 0.6535 - accuracy: 0.7183 - val_loss: 0.5050 - val_auc: 0.6763 - val_accuracy: 0.7496\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.5091 - auc: 0.6629 - accuracy: 0.7349 - val_loss: 0.5062 - val_auc: 0.6720 - val_accuracy: 0.7394\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.5034 - auc: 0.6720 - accuracy: 0.7476 - val_loss: 0.4918 - val_auc: 0.7008 - val_accuracy: 0.7715\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4972 - auc: 0.6904 - accuracy: 0.7603 - val_loss: 0.4902 - val_auc: 0.7096 - val_accuracy: 0.7677\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4893 - auc: 0.7092 - accuracy: 0.7742 - val_loss: 0.4714 - val_auc: 0.7556 - val_accuracy: 0.8029\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4803 - auc: 0.7349 - accuracy: 0.7915 - val_loss: 0.4646 - val_auc: 0.7692 - val_accuracy: 0.8031\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4744 - auc: 0.7560 - accuracy: 0.8008 - val_loss: 0.4602 - val_auc: 0.7805 - val_accuracy: 0.8067\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4675 - auc: 0.7672 - accuracy: 0.8002 - val_loss: 0.4575 - val_auc: 0.7845 - val_accuracy: 0.8069\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4664 - auc: 0.7732 - accuracy: 0.8049 - val_loss: 0.4568 - val_auc: 0.7900 - val_accuracy: 0.8079\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4622 - auc: 0.7785 - accuracy: 0.8046 - val_loss: 0.4514 - val_auc: 0.7952 - val_accuracy: 0.8123\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4595 - auc: 0.7811 - accuracy: 0.8051 - val_loss: 0.4494 - val_auc: 0.7980 - val_accuracy: 0.8117\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.4579 - auc: 0.7845 - accuracy: 0.8051 - val_loss: 0.4508 - val_auc: 0.7934 - val_accuracy: 0.8121\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4574 - auc: 0.7852 - accuracy: 0.8051 - val_loss: 0.4485 - val_auc: 0.7976 - val_accuracy: 0.8119\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4560 - auc: 0.7855 - accuracy: 0.8058 - val_loss: 0.4483 - val_auc: 0.7988 - val_accuracy: 0.8117\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4556 - auc: 0.7878 - accuracy: 0.8053 - val_loss: 0.4468 - val_auc: 0.8010 - val_accuracy: 0.8127\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.4560 - auc: 0.7877 - accuracy: 0.8061 - val_loss: 0.4481 - val_auc: 0.8017 - val_accuracy: 0.8112\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4551 - auc: 0.7875 - accuracy: 0.8070 - val_loss: 0.4469 - val_auc: 0.8043 - val_accuracy: 0.8127\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4547 - auc: 0.7915 - accuracy: 0.8063 - val_loss: 0.4475 - val_auc: 0.8054 - val_accuracy: 0.8110\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4534 - auc: 0.7924 - accuracy: 0.8065 - val_loss: 0.4489 - val_auc: 0.8044 - val_accuracy: 0.8115\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4532 - auc: 0.7945 - accuracy: 0.8076 - val_loss: 0.4470 - val_auc: 0.8072 - val_accuracy: 0.8115\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4515 - auc: 0.7921 - accuracy: 0.8051 - val_loss: 0.4507 - val_auc: 0.8097 - val_accuracy: 0.8106\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4530 - auc: 0.7933 - accuracy: 0.8077 - val_loss: 0.4474 - val_auc: 0.8075 - val_accuracy: 0.8115\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4531 - auc: 0.7930 - accuracy: 0.8070 - val_loss: 0.4468 - val_auc: 0.8061 - val_accuracy: 0.8115\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4521 - auc: 0.7941 - accuracy: 0.8067 - val_loss: 0.4456 - val_auc: 0.8073 - val_accuracy: 0.8110\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4514 - auc: 0.7965 - accuracy: 0.8065 - val_loss: 0.4490 - val_auc: 0.8071 - val_accuracy: 0.8119\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4528 - auc: 0.7938 - accuracy: 0.8063 - val_loss: 0.4465 - val_auc: 0.8054 - val_accuracy: 0.8119\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4520 - auc: 0.7939 - accuracy: 0.8058 - val_loss: 0.4494 - val_auc: 0.8063 - val_accuracy: 0.8123\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4522 - auc: 0.7973 - accuracy: 0.8070 - val_loss: 0.4463 - val_auc: 0.8042 - val_accuracy: 0.8121\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4510 - auc: 0.7954 - accuracy: 0.8067 - val_loss: 0.4485 - val_auc: 0.8128 - val_accuracy: 0.8129\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4525 - auc: 0.7966 - accuracy: 0.8058 - val_loss: 0.4484 - val_auc: 0.8085 - val_accuracy: 0.8129\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4506 - auc: 0.7992 - accuracy: 0.8073 - val_loss: 0.4471 - val_auc: 0.8122 - val_accuracy: 0.8125\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4511 - auc: 0.7989 - accuracy: 0.8076 - val_loss: 0.4474 - val_auc: 0.8134 - val_accuracy: 0.8133\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4503 - auc: 0.7993 - accuracy: 0.8071 - val_loss: 0.4468 - val_auc: 0.8126 - val_accuracy: 0.8125\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4503 - auc: 0.8009 - accuracy: 0.8088 - val_loss: 0.4472 - val_auc: 0.8128 - val_accuracy: 0.8135\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4492 - auc: 0.8007 - accuracy: 0.8053 - val_loss: 0.4471 - val_auc: 0.8170 - val_accuracy: 0.8131\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4493 - auc: 0.8025 - accuracy: 0.8070 - val_loss: 0.4472 - val_auc: 0.8142 - val_accuracy: 0.8125\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4504 - auc: 0.7997 - accuracy: 0.8069 - val_loss: 0.4453 - val_auc: 0.8108 - val_accuracy: 0.8131\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 9s 16ms/step - loss: 0.4516 - auc: 0.7997 - accuracy: 0.8069 - val_loss: 0.4461 - val_auc: 0.8103 - val_accuracy: 0.8140\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4493 - auc: 0.8014 - accuracy: 0.8073 - val_loss: 0.4462 - val_auc: 0.8146 - val_accuracy: 0.8135\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4500 - auc: 0.8025 - accuracy: 0.8071 - val_loss: 0.4460 - val_auc: 0.8152 - val_accuracy: 0.8133\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 9s 16ms/step - loss: 0.4495 - auc: 0.8018 - accuracy: 0.8081 - val_loss: 0.4453 - val_auc: 0.8155 - val_accuracy: 0.8129\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4488 - auc: 0.8032 - accuracy: 0.8075 - val_loss: 0.4449 - val_auc: 0.8152 - val_accuracy: 0.8127\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4491 - auc: 0.8038 - accuracy: 0.8080 - val_loss: 0.4465 - val_auc: 0.8158 - val_accuracy: 0.8144\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4492 - auc: 0.8038 - accuracy: 0.8071 - val_loss: 0.4447 - val_auc: 0.8128 - val_accuracy: 0.8148\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4497 - auc: 0.8031 - accuracy: 0.8068 - val_loss: 0.4454 - val_auc: 0.8180 - val_accuracy: 0.8135\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 9s 16ms/step - loss: 0.4494 - auc: 0.8038 - accuracy: 0.8062 - val_loss: 0.4461 - val_auc: 0.8161 - val_accuracy: 0.8125\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4492 - auc: 0.8049 - accuracy: 0.8071 - val_loss: 0.4481 - val_auc: 0.8148 - val_accuracy: 0.8148 loss: - ETA\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4477 - auc: 0.8049 - accuracy: 0.8078 - val_loss: 0.4458 - val_auc: 0.8164 - val_accuracy: 0.8144\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4490 - auc: 0.8058 - accuracy: 0.8075 - val_loss: 0.4470 - val_auc: 0.8182 - val_accuracy: 0.8135os\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4485 - auc: 0.8058 - accuracy: 0.8074 - val_loss: 0.4458 - val_auc: 0.8198 - val_accuracy: 0.8142\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4488 - auc: 0.8051 - accuracy: 0.8066 - val_loss: 0.4463 - val_auc: 0.8189 - val_accuracy: 0.8144\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 9s 16ms/step - loss: 0.4469 - auc: 0.8084 - accuracy: 0.8074 - val_loss: 0.4453 - val_auc: 0.8142 - val_accuracy: 0.8142\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4491 - auc: 0.8035 - accuracy: 0.8068 - val_loss: 0.4453 - val_auc: 0.8152 - val_accuracy: 0.8133\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4477 - auc: 0.8067 - accuracy: 0.8102 - val_loss: 0.4450 - val_auc: 0.8162 - val_accuracy: 0.8135\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4469 - auc: 0.8073 - accuracy: 0.8080 - val_loss: 0.4449 - val_auc: 0.8174 - val_accuracy: 0.8144\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4468 - auc: 0.8079 - accuracy: 0.8082 - val_loss: 0.4458 - val_auc: 0.8169 - val_accuracy: 0.8135\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4476 - auc: 0.8087 - accuracy: 0.8077 - val_loss: 0.4449 - val_auc: 0.8202 - val_accuracy: 0.8140\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4479 - auc: 0.8096 - accuracy: 0.8081 - val_loss: 0.4439 - val_auc: 0.8200 - val_accuracy: 0.8150\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4469 - auc: 0.8091 - accuracy: 0.8077 - val_loss: 0.4467 - val_auc: 0.8191 - val_accuracy: 0.8138\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4474 - auc: 0.8102 - accuracy: 0.8088 - val_loss: 0.4452 - val_auc: 0.8200 - val_accuracy: 0.8127\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4468 - auc: 0.8106 - accuracy: 0.8075 - val_loss: 0.4461 - val_auc: 0.8226 - val_accuracy: 0.8129\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4455 - auc: 0.8117 - accuracy: 0.8091 - val_loss: 0.4452 - val_auc: 0.8200 - val_accuracy: 0.8125\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4459 - auc: 0.8131 - accuracy: 0.8090 - val_loss: 0.4451 - val_auc: 0.8211 - val_accuracy: 0.8129\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4473 - auc: 0.8109 - accuracy: 0.8085 - val_loss: 0.4440 - val_auc: 0.8221 - val_accuracy: 0.8138\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4452 - auc: 0.8124 - accuracy: 0.8093 - val_loss: 0.4456 - val_auc: 0.8223 - val_accuracy: 0.8144\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4471 - auc: 0.8126 - accuracy: 0.8090 - val_loss: 0.4437 - val_auc: 0.8201 - val_accuracy: 0.8140\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4455 - auc: 0.8109 - accuracy: 0.8094 - val_loss: 0.4450 - val_auc: 0.8225 - val_accuracy: 0.8150\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4456 - auc: 0.8130 - accuracy: 0.8100 - val_loss: 0.4462 - val_auc: 0.8221 - val_accuracy: 0.8131\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4467 - auc: 0.8107 - accuracy: 0.8076 - val_loss: 0.4456 - val_auc: 0.8230 - val_accuracy: 0.8144\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4459 - auc: 0.8137 - accuracy: 0.8092 - val_loss: 0.4458 - val_auc: 0.8261 - val_accuracy: 0.8140\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.4449 - auc: 0.8144 - accuracy: 0.8096 - val_loss: 0.4458 - val_auc: 0.8230 - val_accuracy: 0.8138\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.4460 - auc: 0.8120 - accuracy: 0.8078 - val_loss: 0.4435 - val_auc: 0.8235 - val_accuracy: 0.8135\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4450 - auc: 0.8140 - accuracy: 0.8096 - val_loss: 0.4454 - val_auc: 0.8241 - val_accuracy: 0.8148\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4461 - auc: 0.8149 - accuracy: 0.8095 - val_loss: 0.4426 - val_auc: 0.8209 - val_accuracy: 0.8138\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4455 - auc: 0.8157 - accuracy: 0.8080 - val_loss: 0.4442 - val_auc: 0.8299 - val_accuracy: 0.8156\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4463 - auc: 0.8160 - accuracy: 0.8094 - val_loss: 0.4439 - val_auc: 0.8235 - val_accuracy: 0.8140\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4449 - auc: 0.8170 - accuracy: 0.8101 - val_loss: 0.4451 - val_auc: 0.8273 - val_accuracy: 0.8148\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4457 - auc: 0.8164 - accuracy: 0.8091 - val_loss: 0.4429 - val_auc: 0.8266 - val_accuracy: 0.8154\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4447 - auc: 0.8165 - accuracy: 0.8073 - val_loss: 0.4436 - val_auc: 0.8264 - val_accuracy: 0.8144\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4451 - auc: 0.8165 - accuracy: 0.8107 - val_loss: 0.4433 - val_auc: 0.8241 - val_accuracy: 0.8146\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4456 - auc: 0.8167 - accuracy: 0.8093 - val_loss: 0.4443 - val_auc: 0.8294 - val_accuracy: 0.8144\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4449 - auc: 0.8202 - accuracy: 0.8099 - val_loss: 0.4435 - val_auc: 0.8274 - val_accuracy: 0.8131\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4451 - auc: 0.8193 - accuracy: 0.8097 - val_loss: 0.4444 - val_auc: 0.8277 - val_accuracy: 0.8156\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4445 - auc: 0.8192 - accuracy: 0.8103 - val_loss: 0.4452 - val_auc: 0.8318 - val_accuracy: 0.8167\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 9s 16ms/step - loss: 0.4459 - auc: 0.8206 - accuracy: 0.8079 - val_loss: 0.4435 - val_auc: 0.8272 - val_accuracy: 0.8173\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4445 - auc: 0.8199 - accuracy: 0.8095 - val_loss: 0.4441 - val_auc: 0.8310 - val_accuracy: 0.8152\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4445 - auc: 0.8215 - accuracy: 0.8102 - val_loss: 0.4438 - val_auc: 0.8313 - val_accuracy: 0.8144\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4449 - auc: 0.8213 - accuracy: 0.8078 - val_loss: 0.4431 - val_auc: 0.8309 - val_accuracy: 0.8148\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4446 - auc: 0.8196 - accuracy: 0.8095 - val_loss: 0.4439 - val_auc: 0.8292 - val_accuracy: 0.8158\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4447 - auc: 0.8213 - accuracy: 0.8107 - val_loss: 0.4439 - val_auc: 0.8283 - val_accuracy: 0.8158\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4445 - auc: 0.8207 - accuracy: 0.8092 - val_loss: 0.4440 - val_auc: 0.8288 - val_accuracy: 0.8154\n",
      "\n",
      "\n",
      "Train data shape: (19710, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 1th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4619 - auc: 0.8166 - accuracy: 0.7980 - val_loss: 0.4422 - val_auc: 0.8352 - val_accuracy: 0.8150\n",
      "Epoch 2/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4614 - auc: 0.8205 - accuracy: 0.7975 - val_loss: 0.4437 - val_auc: 0.8376 - val_accuracy: 0.8148\n",
      "Epoch 3/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4616 - auc: 0.8194 - accuracy: 0.7992 - val_loss: 0.4437 - val_auc: 0.8389 - val_accuracy: 0.8150\n",
      "Epoch 4/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4611 - auc: 0.8208 - accuracy: 0.7986 - val_loss: 0.4490 - val_auc: 0.8321 - val_accuracy: 0.8142\n",
      "Epoch 5/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4607 - auc: 0.8200 - accuracy: 0.8003 - val_loss: 0.4450 - val_auc: 0.8362 - val_accuracy: 0.8154\n",
      "Epoch 6/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4610 - auc: 0.8190 - accuracy: 0.7981 - val_loss: 0.4436 - val_auc: 0.8388 - val_accuracy: 0.8148\n",
      "Epoch 7/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4594 - auc: 0.8200 - accuracy: 0.8004 - val_loss: 0.4435 - val_auc: 0.8366 - val_accuracy: 0.8148\n",
      "Epoch 8/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4610 - auc: 0.8193 - accuracy: 0.7995 - val_loss: 0.4428 - val_auc: 0.8387 - val_accuracy: 0.8158\n",
      "Epoch 9/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4602 - auc: 0.8196 - accuracy: 0.8005 - val_loss: 0.4424 - val_auc: 0.8358 - val_accuracy: 0.8160\n",
      "Epoch 10/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4606 - auc: 0.8184 - accuracy: 0.7991 - val_loss: 0.4421 - val_auc: 0.8381 - val_accuracy: 0.8158\n",
      "Epoch 11/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4599 - auc: 0.8198 - accuracy: 0.7995 - val_loss: 0.4426 - val_auc: 0.8372 - val_accuracy: 0.8154\n",
      "Epoch 12/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4596 - auc: 0.8200 - accuracy: 0.8018 - val_loss: 0.4422 - val_auc: 0.8397 - val_accuracy: 0.8160\n",
      "Epoch 13/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4601 - auc: 0.8192 - accuracy: 0.7994 - val_loss: 0.4441 - val_auc: 0.8347 - val_accuracy: 0.8158611 - au\n",
      "Epoch 14/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4586 - auc: 0.8196 - accuracy: 0.8017 - val_loss: 0.4428 - val_auc: 0.8369 - val_accuracy: 0.8160\n",
      "Epoch 15/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4604 - auc: 0.8185 - accuracy: 0.7999 - val_loss: 0.4424 - val_auc: 0.8390 - val_accuracy: 0.8146\n",
      "Epoch 16/100\n",
      "616/616 [==============================] - 12s 20ms/step - loss: 0.4592 - auc: 0.8191 - accuracy: 0.8004 - val_loss: 0.4430 - val_auc: 0.8395 - val_accuracy: 0.8156\n",
      "Epoch 17/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4584 - auc: 0.8194 - accuracy: 0.8009 - val_loss: 0.4441 - val_auc: 0.8345 - val_accuracy: 0.8158\n",
      "Epoch 18/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4590 - auc: 0.8176 - accuracy: 0.8012 - val_loss: 0.4429 - val_auc: 0.8367 - val_accuracy: 0.8167c: 0.8159 - accuracy: 0. - ETA: 1s\n",
      "Epoch 19/100\n",
      "616/616 [==============================] - 12s 19ms/step - loss: 0.4590 - auc: 0.8177 - accuracy: 0.7992 - val_loss: 0.4432 - val_auc: 0.8341 - val_accuracy: 0.8165\n",
      "Epoch 20/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4589 - auc: 0.8181 - accuracy: 0.8008 - val_loss: 0.4438 - val_auc: 0.8342 - val_accuracy: 0.8165\n",
      "Epoch 21/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4583 - auc: 0.8196 - accuracy: 0.8001 - val_loss: 0.4435 - val_auc: 0.8347 - val_accuracy: 0.8167\n",
      "Epoch 22/100\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.4590 - auc: 0.8197 - accuracy: 0.8007 - val_loss: 0.4436 - val_auc: 0.8347 - val_accuracy: 0.8160\n",
      "\n",
      "\n",
      "Train data shape: (20669, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 2th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "646/646 [==============================] - 11s 16ms/step - loss: 0.4933 - auc: 0.8035 - accuracy: 0.7774 - val_loss: 0.4456 - val_auc: 0.8432 - val_accuracy: 0.8152\n",
      "Epoch 2/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.4908 - auc: 0.8080 - accuracy: 0.7803 - val_loss: 0.4459 - val_auc: 0.8465 - val_accuracy: 0.8140\n",
      "Epoch 3/100\n",
      "646/646 [==============================] - 11s 16ms/step - loss: 0.4914 - auc: 0.8089 - accuracy: 0.7823 - val_loss: 0.4440 - val_auc: 0.8473 - val_accuracy: 0.8138\n",
      "Epoch 4/100\n",
      "646/646 [==============================] - 11s 16ms/step - loss: 0.4902 - auc: 0.8086 - accuracy: 0.7803 - val_loss: 0.4464 - val_auc: 0.8463 - val_accuracy: 0.8135\n",
      "Epoch 5/100\n",
      "646/646 [==============================] - 11s 16ms/step - loss: 0.4900 - auc: 0.8096 - accuracy: 0.7808 - val_loss: 0.4474 - val_auc: 0.8437 - val_accuracy: 0.8125s: 0.4903 - auc: 0.8095 - accuracy: \n",
      "Epoch 6/100\n",
      "646/646 [==============================] - 11s 17ms/step - loss: 0.4881 - auc: 0.8102 - accuracy: 0.7812 - val_loss: 0.4471 - val_auc: 0.8465 - val_accuracy: 0.8138\n",
      "Epoch 7/100\n",
      "646/646 [==============================] - 11s 16ms/step - loss: 0.4900 - auc: 0.8085 - accuracy: 0.7811 - val_loss: 0.4487 - val_auc: 0.8436 - val_accuracy: 0.8131\n",
      "Epoch 8/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.4873 - auc: 0.8096 - accuracy: 0.7829 - val_loss: 0.4470 - val_auc: 0.8451 - val_accuracy: 0.8138\n",
      "Epoch 9/100\n",
      "646/646 [==============================] - 11s 17ms/step - loss: 0.4895 - auc: 0.8078 - accuracy: 0.7809 - val_loss: 0.4455 - val_auc: 0.8452 - val_accuracy: 0.8121\n",
      "Epoch 10/100\n",
      "646/646 [==============================] - 11s 17ms/step - loss: 0.4881 - auc: 0.8066 - accuracy: 0.7829 - val_loss: 0.4452 - val_auc: 0.8457 - val_accuracy: 0.8135\n",
      "Epoch 11/100\n",
      "646/646 [==============================] - 11s 17ms/step - loss: 0.4878 - auc: 0.8082 - accuracy: 0.7835 - val_loss: 0.4493 - val_auc: 0.8434 - val_accuracy: 0.8119\n",
      "Epoch 12/100\n",
      "646/646 [==============================] - 11s 16ms/step - loss: 0.4868 - auc: 0.8079 - accuracy: 0.7824 - val_loss: 0.4481 - val_auc: 0.8440 - val_accuracy: 0.8123\n",
      "Epoch 13/100\n",
      "646/646 [==============================] - 11s 16ms/step - loss: 0.4882 - auc: 0.8057 - accuracy: 0.7831 - val_loss: 0.4508 - val_auc: 0.8388 - val_accuracy: 0.8102\n",
      "\n",
      "\n",
      "Train data shape: (21629, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 3th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5192 - auc: 0.7920 - accuracy: 0.7620 - val_loss: 0.4463 - val_auc: 0.8509 - val_accuracy: 0.8148\n",
      "Epoch 2/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5162 - auc: 0.7911 - accuracy: 0.7646 - val_loss: 0.4473 - val_auc: 0.8472 - val_accuracy: 0.8148\n",
      "Epoch 3/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5155 - auc: 0.7911 - accuracy: 0.7664 - val_loss: 0.4475 - val_auc: 0.8502 - val_accuracy: 0.8131\n",
      "Epoch 4/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5142 - auc: 0.7923 - accuracy: 0.7660 - val_loss: 0.4565 - val_auc: 0.8451 - val_accuracy: 0.8121\n",
      "Epoch 5/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5144 - auc: 0.7909 - accuracy: 0.7652 - val_loss: 0.4500 - val_auc: 0.8487 - val_accuracy: 0.8125\n",
      "Epoch 6/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5136 - auc: 0.7921 - accuracy: 0.7663 - val_loss: 0.4517 - val_auc: 0.8480 - val_accuracy: 0.8121\n",
      "Epoch 7/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5130 - auc: 0.7924 - accuracy: 0.7672 - val_loss: 0.4583 - val_auc: 0.8434 - val_accuracy: 0.8110\n",
      "Epoch 8/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5143 - auc: 0.7907 - accuracy: 0.7654 - val_loss: 0.4498 - val_auc: 0.8470 - val_accuracy: 0.8121\n",
      "Epoch 9/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5125 - auc: 0.7925 - accuracy: 0.7674 - val_loss: 0.4558 - val_auc: 0.8447 - val_accuracy: 0.8106\n",
      "Epoch 10/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5139 - auc: 0.7910 - accuracy: 0.7661 - val_loss: 0.4588 - val_auc: 0.8445 - val_accuracy: 0.8119\n",
      "Epoch 11/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5115 - auc: 0.7929 - accuracy: 0.7679 - val_loss: 0.4533 - val_auc: 0.8460 - val_accuracy: 0.8115\n",
      "\n",
      "\n",
      "Train data shape: (22589, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 4th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5390 - auc: 0.7735 - accuracy: 0.7481 - val_loss: 0.4508 - val_auc: 0.8452 - val_accuracy: 0.8119\n",
      "Epoch 2/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5363 - auc: 0.7703 - accuracy: 0.7519 - val_loss: 0.4586 - val_auc: 0.8387 - val_accuracy: 0.8104\n",
      "Epoch 3/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5348 - auc: 0.7693 - accuracy: 0.7505 - val_loss: 0.4595 - val_auc: 0.8429 - val_accuracy: 0.8106\n",
      "Epoch 4/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5327 - auc: 0.7702 - accuracy: 0.7547 - val_loss: 0.4611 - val_auc: 0.8386 - val_accuracy: 0.8096\n",
      "Epoch 5/100\n",
      "706/706 [==============================] - 12s 18ms/step - loss: 0.5347 - auc: 0.7701 - accuracy: 0.7526 - val_loss: 0.4541 - val_auc: 0.8395 - val_accuracy: 0.8121\n",
      "Epoch 6/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5311 - auc: 0.7731 - accuracy: 0.7547 - val_loss: 0.4586 - val_auc: 0.8377 - val_accuracy: 0.8096\n",
      "Epoch 7/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5324 - auc: 0.7729 - accuracy: 0.7535 - val_loss: 0.4704 - val_auc: 0.8351 - val_accuracy: 0.8058\n",
      "Epoch 8/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5311 - auc: 0.7752 - accuracy: 0.7551 - val_loss: 0.4621 - val_auc: 0.8415 - val_accuracy: 0.8075\n",
      "Epoch 9/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5305 - auc: 0.7769 - accuracy: 0.7555 - val_loss: 0.4656 - val_auc: 0.8405 - val_accuracy: 0.8054\n",
      "Epoch 10/100\n",
      "706/706 [==============================] - 12s 16ms/step - loss: 0.5295 - auc: 0.7784 - accuracy: 0.7559 - val_loss: 0.4671 - val_auc: 0.8390 - val_accuracy: 0.8050\n",
      "Epoch 11/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5294 - auc: 0.7774 - accuracy: 0.7562 - val_loss: 0.4662 - val_auc: 0.8393 - val_accuracy: 0.8060\n",
      "\n",
      "\n",
      "Train data shape: (23549, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 5th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5545 - auc: 0.7521 - accuracy: 0.7360 - val_loss: 0.4590 - val_auc: 0.8251 - val_accuracy: 0.8121\n",
      "Epoch 2/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5498 - auc: 0.7448 - accuracy: 0.7413 - val_loss: 0.4783 - val_auc: 0.8183 - val_accuracy: 0.8048\n",
      "Epoch 3/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5489 - auc: 0.7438 - accuracy: 0.7407 - val_loss: 0.4744 - val_auc: 0.8271 - val_accuracy: 0.8071\n",
      "Epoch 4/100\n",
      "736/736 [==============================] - 12s 17ms/step - loss: 0.5477 - auc: 0.7478 - accuracy: 0.7418 - val_loss: 0.4676 - val_auc: 0.8282 - val_accuracy: 0.8085\n",
      "Epoch 5/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5463 - auc: 0.7516 - accuracy: 0.7423 - val_loss: 0.4653 - val_auc: 0.8324 - val_accuracy: 0.8092\n",
      "Epoch 6/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5455 - auc: 0.7504 - accuracy: 0.7419 - val_loss: 0.4706 - val_auc: 0.8308 - val_accuracy: 0.8073\n",
      "Epoch 7/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5460 - auc: 0.7529 - accuracy: 0.7417 - val_loss: 0.4722 - val_auc: 0.8357 - val_accuracy: 0.8081\n",
      "Epoch 8/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5455 - auc: 0.7538 - accuracy: 0.7432 - val_loss: 0.4730 - val_auc: 0.8299 - val_accuracy: 0.8046\n",
      "Epoch 9/100\n",
      "736/736 [==============================] - 12s 17ms/step - loss: 0.5440 - auc: 0.7558 - accuracy: 0.7438 - val_loss: 0.4687 - val_auc: 0.8376 - val_accuracy: 0.8087\n",
      "Epoch 10/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5444 - auc: 0.7556 - accuracy: 0.7434 - val_loss: 0.4759 - val_auc: 0.8345 - val_accuracy: 0.8060\n",
      "Epoch 11/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5435 - auc: 0.7575 - accuracy: 0.7433 - val_loss: 0.4772 - val_auc: 0.8300 - val_accuracy: 0.8027\n",
      "Epoch 12/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5436 - auc: 0.7570 - accuracy: 0.7421 - val_loss: 0.4783 - val_auc: 0.8324 - val_accuracy: 0.8025\n",
      "Epoch 13/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5429 - auc: 0.7573 - accuracy: 0.7438 - val_loss: 0.4790 - val_auc: 0.8315 - val_accuracy: 0.8033\n",
      "Epoch 14/100\n",
      "736/736 [==============================] - 12s 17ms/step - loss: 0.5436 - auc: 0.7583 - accuracy: 0.7426 - val_loss: 0.4702 - val_auc: 0.8365 - val_accuracy: 0.8073\n",
      "Epoch 15/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5425 - auc: 0.7586 - accuracy: 0.7444 - val_loss: 0.4784 - val_auc: 0.8284 - val_accuracy: 0.8019\n",
      "Epoch 16/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5419 - auc: 0.7602 - accuracy: 0.7448 - val_loss: 0.4693 - val_auc: 0.8404 - val_accuracy: 0.8056\n",
      "Epoch 17/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5422 - auc: 0.7589 - accuracy: 0.7456 - val_loss: 0.4737 - val_auc: 0.8361 - val_accuracy: 0.8042\n",
      "Epoch 18/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5423 - auc: 0.7614 - accuracy: 0.7454 - val_loss: 0.4750 - val_auc: 0.8341 - val_accuracy: 0.8027\n",
      "Epoch 19/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5417 - auc: 0.7611 - accuracy: 0.7456 - val_loss: 0.4780 - val_auc: 0.8334 - val_accuracy: 0.8035\n",
      "Epoch 20/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5426 - auc: 0.7597 - accuracy: 0.7450 - val_loss: 0.4708 - val_auc: 0.8349 - val_accuracy: 0.8048\n",
      "Epoch 21/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5413 - auc: 0.7601 - accuracy: 0.7439 - val_loss: 0.4857 - val_auc: 0.8257 - val_accuracy: 0.7969\n",
      "Epoch 22/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5424 - auc: 0.7605 - accuracy: 0.7446 - val_loss: 0.4730 - val_auc: 0.8353 - val_accuracy: 0.8054\n",
      "Epoch 23/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5400 - auc: 0.7627 - accuracy: 0.7443 - val_loss: 0.4694 - val_auc: 0.8406 - val_accuracy: 0.8065\n",
      "Epoch 24/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5414 - auc: 0.7628 - accuracy: 0.7440 - val_loss: 0.4728 - val_auc: 0.8314 - val_accuracy: 0.8023\n",
      "Epoch 25/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5412 - auc: 0.7621 - accuracy: 0.7442 - val_loss: 0.4764 - val_auc: 0.8340 - val_accuracy: 0.8021\n",
      "Epoch 26/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5407 - auc: 0.7633 - accuracy: 0.7450 - val_loss: 0.4767 - val_auc: 0.8361 - val_accuracy: 0.8035\n",
      "Epoch 27/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5413 - auc: 0.7628 - accuracy: 0.7459 - val_loss: 0.4740 - val_auc: 0.8337 - val_accuracy: 0.8031\n",
      "Epoch 28/100\n",
      "736/736 [==============================] - 11s 16ms/step - loss: 0.5415 - auc: 0.7612 - accuracy: 0.7447 - val_loss: 0.4702 - val_auc: 0.8397 - val_accuracy: 0.8077\n",
      "Epoch 29/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5417 - auc: 0.7622 - accuracy: 0.7447 - val_loss: 0.4666 - val_auc: 0.8423 - val_accuracy: 0.8069\n",
      "Epoch 30/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5415 - auc: 0.7611 - accuracy: 0.7443 - val_loss: 0.4703 - val_auc: 0.8332 - val_accuracy: 0.8060\n",
      "Epoch 31/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5408 - auc: 0.7618 - accuracy: 0.7445 - val_loss: 0.4811 - val_auc: 0.8289 - val_accuracy: 0.8002\n",
      "Epoch 32/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5412 - auc: 0.7606 - accuracy: 0.7446 - val_loss: 0.4785 - val_auc: 0.8266 - val_accuracy: 0.8019\n",
      "Epoch 33/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5402 - auc: 0.7617 - accuracy: 0.7453 - val_loss: 0.4710 - val_auc: 0.8378 - val_accuracy: 0.8054\n",
      "Epoch 34/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5394 - auc: 0.7636 - accuracy: 0.7455 - val_loss: 0.4776 - val_auc: 0.8330 - val_accuracy: 0.8008\n",
      "Epoch 35/100\n",
      "736/736 [==============================] - 12s 17ms/step - loss: 0.5405 - auc: 0.7626 - accuracy: 0.7431 - val_loss: 0.4684 - val_auc: 0.8374 - val_accuracy: 0.8062\n",
      "Epoch 36/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5406 - auc: 0.7627 - accuracy: 0.7452 - val_loss: 0.4735 - val_auc: 0.8358 - val_accuracy: 0.8029\n",
      "Epoch 37/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5401 - auc: 0.7636 - accuracy: 0.7450 - val_loss: 0.4755 - val_auc: 0.8351 - val_accuracy: 0.8025\n",
      "Epoch 38/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5407 - auc: 0.7632 - accuracy: 0.7449 - val_loss: 0.4659 - val_auc: 0.8360 - val_accuracy: 0.8037\n",
      "Epoch 39/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5403 - auc: 0.7640 - accuracy: 0.7434 - val_loss: 0.4725 - val_auc: 0.8365 - val_accuracy: 0.8031\n",
      "\n",
      "\n",
      "Train data shape: (24509, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 6th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5568 - auc: 0.7458 - accuracy: 0.7315 - val_loss: 0.4746 - val_auc: 0.8321 - val_accuracy: 0.8031\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5555 - auc: 0.7427 - accuracy: 0.7318 - val_loss: 0.4818 - val_auc: 0.8245 - val_accuracy: 0.8021\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5547 - auc: 0.7437 - accuracy: 0.7329 - val_loss: 0.4868 - val_auc: 0.8207 - val_accuracy: 0.7971\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5541 - auc: 0.7412 - accuracy: 0.7314 - val_loss: 0.4800 - val_auc: 0.8292 - val_accuracy: 0.8012\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5538 - auc: 0.7419 - accuracy: 0.7327 - val_loss: 0.4872 - val_auc: 0.8181 - val_accuracy: 0.7960\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5522 - auc: 0.7426 - accuracy: 0.7333 - val_loss: 0.4824 - val_auc: 0.8257 - val_accuracy: 0.7996\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5529 - auc: 0.7432 - accuracy: 0.7343 - val_loss: 0.4868 - val_auc: 0.8238 - val_accuracy: 0.7985\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5527 - auc: 0.7447 - accuracy: 0.7334 - val_loss: 0.4792 - val_auc: 0.8328 - val_accuracy: 0.8017\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5533 - auc: 0.7450 - accuracy: 0.7345 - val_loss: 0.4745 - val_auc: 0.8286 - val_accuracy: 0.8042\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5537 - auc: 0.7436 - accuracy: 0.7333 - val_loss: 0.4791 - val_auc: 0.8278 - val_accuracy: 0.7996\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5523 - auc: 0.7451 - accuracy: 0.7339 - val_loss: 0.4839 - val_auc: 0.8303 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5532 - auc: 0.7437 - accuracy: 0.7334 - val_loss: 0.4937 - val_auc: 0.8219 - val_accuracy: 0.7977\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5531 - auc: 0.7445 - accuracy: 0.7336 - val_loss: 0.4826 - val_auc: 0.8269 - val_accuracy: 0.7987\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5530 - auc: 0.7457 - accuracy: 0.7335 - val_loss: 0.4888 - val_auc: 0.8254 - val_accuracy: 0.7979\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5516 - auc: 0.7462 - accuracy: 0.7343 - val_loss: 0.4807 - val_auc: 0.8325 - val_accuracy: 0.8033\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5513 - auc: 0.7470 - accuracy: 0.7343 - val_loss: 0.4854 - val_auc: 0.8214 - val_accuracy: 0.7979\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5523 - auc: 0.7451 - accuracy: 0.7334 - val_loss: 0.4811 - val_auc: 0.8282 - val_accuracy: 0.7983\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5516 - auc: 0.7470 - accuracy: 0.7340 - val_loss: 0.4835 - val_auc: 0.8277 - val_accuracy: 0.7990\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 단일 모델로 여러개의 표본 학습\n",
    "\n",
    "epochs = 100\n",
    "plot_list = []\n",
    "model_list = []\n",
    "learning_rate = 0.00001\n",
    "model = RNN_Model(learning_rate)\n",
    "list_index = 0\n",
    "\n",
    "for (j, sample) in enumerate(sampling_list):\n",
    "    \n",
    "    X_train_preprocessing = sample[0]\n",
    "    X_train_add_feature = sample[1]\n",
    "    y_train_preprocessing = sample[3]\n",
    "    \n",
    "    length = len(X_train_preprocessing)\n",
    "    \n",
    "    print(\"Train data shape: {} Val data shape: {}\".format(X_train_preprocessing.shape, X_val_preprocessing.shape))\n",
    "    print(\"Training the model with {}th sample\".format(j))\n",
    "    print(\"-----------------------------------------------\")\n",
    "    \n",
    "    epoch, hist = train_model(model, [X_train_preprocessing, X_train_add_feature], y_train_preprocessing, \n",
    "                              [X_val_preprocessing, X_val_add_feature], y_val_preprocessing, epochs = epochs, batch_size = 32, patience = 10)\n",
    "    model_list.append(model)\n",
    "    plot_list.append([epoch, hist])\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "The model's \u001b[35m Precision \u001b[30m: 0.56 \u001b[35m Recall \u001b[30m: 0.49 \u001b[35m F1-score \u001b[30m: 0.52 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting...\")\n",
    "\n",
    "y_proba = model.predict([X_val_preprocessing, X_val_add_feature])\n",
    "y_pred = np.argmax(y_proba, axis = 1)\n",
    "\n",
    "precision, recall, f1, accuracy = f1_score(y_val, y_pred)\n",
    "print(\"The model's \\033[35m Precision \\033[30m: {:.2f} \\033[35m Recall \\033[30m: {:.2f} \\033[35m F1-score \\033[30m: {:.2f} \\033[35m Accuracy\\033[30m: {:.2f} \\n\".format(precision, recall, f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = model.predict([X_test_preprocessing, X_test_add_feature])\n",
    "y_pred = np.argmax(y_proba, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mPrecision\u001b[30m: 0.58, \u001b[35mRecall\u001b[30m: 0.53, \u001b[35mF1-Score\u001b[30m: 0.55, \u001b[35mAccuracy\u001b[30m: 0.82\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1,accuracy = f1_score(y_test, y_pred)\n",
    "print(\"\\033[35mPrecision\\033[30m: {:.2f}, \\033[35mRecall\\033[30m: {:.2f}, \\033[35mF1-Score\\033[30m: {:.2f}, \\033[35mAccuracy\\033[30m: {:.2f}\".format(precision, recall, f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (19196, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 0th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.6243 - auc: 0.6329 - accuracy: 0.6234 - val_loss: 0.5855 - val_auc: 0.5744 - val_accuracy: 0.6567\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.5663 - auc: 0.5936 - accuracy: 0.6647 - val_loss: 0.5519 - val_auc: 0.6057 - val_accuracy: 0.6802\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.5497 - auc: 0.6156 - accuracy: 0.6865 - val_loss: 0.5357 - val_auc: 0.6348 - val_accuracy: 0.6992\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.5364 - auc: 0.6310 - accuracy: 0.7064 - val_loss: 0.5200 - val_auc: 0.6557 - val_accuracy: 0.7304\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.5268 - auc: 0.6479 - accuracy: 0.7203 - val_loss: 0.5077 - val_auc: 0.6716 - val_accuracy: 0.7544\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.5151 - auc: 0.6678 - accuracy: 0.7416 - val_loss: 0.5014 - val_auc: 0.6900 - val_accuracy: 0.7652\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.5067 - auc: 0.6873 - accuracy: 0.7547 - val_loss: 0.4914 - val_auc: 0.7126 - val_accuracy: 0.7763\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4960 - auc: 0.7074 - accuracy: 0.7651 - val_loss: 0.4937 - val_auc: 0.7249 - val_accuracy: 0.7783\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4889 - auc: 0.7185 - accuracy: 0.7735 - val_loss: 0.4775 - val_auc: 0.7368 - val_accuracy: 0.7846\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4845 - auc: 0.7252 - accuracy: 0.7768 - val_loss: 0.4743 - val_auc: 0.7427 - val_accuracy: 0.7869\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4783 - auc: 0.7321 - accuracy: 0.7824 - val_loss: 0.4700 - val_auc: 0.7446 - val_accuracy: 0.7883\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4755 - auc: 0.7373 - accuracy: 0.7842 - val_loss: 0.4660 - val_auc: 0.7498 - val_accuracy: 0.7927\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4722 - auc: 0.7418 - accuracy: 0.7874 - val_loss: 0.4658 - val_auc: 0.7501 - val_accuracy: 0.7981\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4710 - auc: 0.7473 - accuracy: 0.7920 - val_loss: 0.4639 - val_auc: 0.7607 - val_accuracy: 0.7977\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4670 - auc: 0.7513 - accuracy: 0.7912 - val_loss: 0.4631 - val_auc: 0.7612 - val_accuracy: 0.7985\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4679 - auc: 0.7550 - accuracy: 0.7947 - val_loss: 0.4593 - val_auc: 0.7663 - val_accuracy: 0.8010\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4634 - auc: 0.7614 - accuracy: 0.7971 - val_loss: 0.4587 - val_auc: 0.7701 - val_accuracy: 0.8008\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4639 - auc: 0.7604 - accuracy: 0.7959 - val_loss: 0.4565 - val_auc: 0.7730 - val_accuracy: 0.8044\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4626 - auc: 0.7641 - accuracy: 0.7970 - val_loss: 0.4545 - val_auc: 0.7747 - val_accuracy: 0.8048\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4597 - auc: 0.7677 - accuracy: 0.7994 - val_loss: 0.4528 - val_auc: 0.7773 - val_accuracy: 0.8054\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4604 - auc: 0.7684 - accuracy: 0.7981 - val_loss: 0.4521 - val_auc: 0.7795 - val_accuracy: 0.8054\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4589 - auc: 0.7691 - accuracy: 0.8008 - val_loss: 0.4524 - val_auc: 0.7816 - val_accuracy: 0.8044\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4591 - auc: 0.7725 - accuracy: 0.7997 - val_loss: 0.4537 - val_auc: 0.7838 - val_accuracy: 0.8044\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4562 - auc: 0.7754 - accuracy: 0.8005 - val_loss: 0.4533 - val_auc: 0.7864 - val_accuracy: 0.8054\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4562 - auc: 0.7785 - accuracy: 0.7996 - val_loss: 0.4512 - val_auc: 0.7898 - val_accuracy: 0.8062\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4567 - auc: 0.7782 - accuracy: 0.7997 - val_loss: 0.4523 - val_auc: 0.7884 - val_accuracy: 0.8050\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4556 - auc: 0.7770 - accuracy: 0.8004 - val_loss: 0.4522 - val_auc: 0.7874 - val_accuracy: 0.8067\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4542 - auc: 0.7798 - accuracy: 0.8018 - val_loss: 0.4522 - val_auc: 0.7896 - val_accuracy: 0.8079\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4540 - auc: 0.7818 - accuracy: 0.8029 - val_loss: 0.4502 - val_auc: 0.7917 - val_accuracy: 0.8075\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4535 - auc: 0.7814 - accuracy: 0.8024 - val_loss: 0.4520 - val_auc: 0.7895 - val_accuracy: 0.8067\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4543 - auc: 0.7819 - accuracy: 0.8022 - val_loss: 0.4500 - val_auc: 0.7934 - val_accuracy: 0.8075\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4542 - auc: 0.7822 - accuracy: 0.8027 - val_loss: 0.4500 - val_auc: 0.7936 - val_accuracy: 0.8081\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4534 - auc: 0.7831 - accuracy: 0.8021 - val_loss: 0.4493 - val_auc: 0.7951 - val_accuracy: 0.8081\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4522 - auc: 0.7835 - accuracy: 0.8025 - val_loss: 0.4491 - val_auc: 0.7949 - val_accuracy: 0.8081\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4531 - auc: 0.7850 - accuracy: 0.8037 - val_loss: 0.4488 - val_auc: 0.7938 - val_accuracy: 0.8092\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4528 - auc: 0.7846 - accuracy: 0.8030 - val_loss: 0.4493 - val_auc: 0.7950 - val_accuracy: 0.8092\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4517 - auc: 0.7861 - accuracy: 0.8031 - val_loss: 0.4486 - val_auc: 0.7967 - val_accuracy: 0.8098\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4508 - auc: 0.7907 - accuracy: 0.8029 - val_loss: 0.4474 - val_auc: 0.7972 - val_accuracy: 0.8094\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4526 - auc: 0.7888 - accuracy: 0.8035 - val_loss: 0.4483 - val_auc: 0.7974 - val_accuracy: 0.8094\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4522 - auc: 0.7869 - accuracy: 0.8026 - val_loss: 0.4511 - val_auc: 0.7971 - val_accuracy: 0.8098\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4520 - auc: 0.7884 - accuracy: 0.8038 - val_loss: 0.4491 - val_auc: 0.7998 - val_accuracy: 0.8096\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4515 - auc: 0.7914 - accuracy: 0.8037 - val_loss: 0.4469 - val_auc: 0.8016 - val_accuracy: 0.8112\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4510 - auc: 0.7917 - accuracy: 0.8050 - val_loss: 0.4472 - val_auc: 0.8020 - val_accuracy: 0.8104\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4510 - auc: 0.7930 - accuracy: 0.8041 - val_loss: 0.4473 - val_auc: 0.8013 - val_accuracy: 0.8092\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4524 - auc: 0.7921 - accuracy: 0.8042 - val_loss: 0.4473 - val_auc: 0.8020 - val_accuracy: 0.8092\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4520 - auc: 0.7929 - accuracy: 0.8032 - val_loss: 0.4497 - val_auc: 0.7996 - val_accuracy: 0.8104\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4513 - auc: 0.7937 - accuracy: 0.8044 - val_loss: 0.4479 - val_auc: 0.8041 - val_accuracy: 0.8119\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4509 - auc: 0.7943 - accuracy: 0.8046 - val_loss: 0.4478 - val_auc: 0.8034 - val_accuracy: 0.8100\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4512 - auc: 0.7953 - accuracy: 0.8046 - val_loss: 0.4471 - val_auc: 0.8048 - val_accuracy: 0.8115\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4504 - auc: 0.7950 - accuracy: 0.8038 - val_loss: 0.4488 - val_auc: 0.8037 - val_accuracy: 0.8096\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4514 - auc: 0.7957 - accuracy: 0.8046 - val_loss: 0.4500 - val_auc: 0.8018 - val_accuracy: 0.8117\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4506 - auc: 0.7950 - accuracy: 0.8043 - val_loss: 0.4479 - val_auc: 0.8053 - val_accuracy: 0.8110\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4510 - auc: 0.7949 - accuracy: 0.8033 - val_loss: 0.4463 - val_auc: 0.8050 - val_accuracy: 0.8104\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4503 - auc: 0.7940 - accuracy: 0.8029 - val_loss: 0.4476 - val_auc: 0.8024 - val_accuracy: 0.8092\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4506 - auc: 0.7933 - accuracy: 0.8028 - val_loss: 0.4476 - val_auc: 0.8017 - val_accuracy: 0.8123\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4485 - auc: 0.7956 - accuracy: 0.8056 - val_loss: 0.4465 - val_auc: 0.8075 - val_accuracy: 0.8117\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4483 - auc: 0.7994 - accuracy: 0.8050 - val_loss: 0.4461 - val_auc: 0.8068 - val_accuracy: 0.8104\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4502 - auc: 0.7961 - accuracy: 0.8033 - val_loss: 0.4463 - val_auc: 0.8052 - val_accuracy: 0.8102\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4490 - auc: 0.7989 - accuracy: 0.8054 - val_loss: 0.4499 - val_auc: 0.8036 - val_accuracy: 0.8108\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4504 - auc: 0.7965 - accuracy: 0.8034 - val_loss: 0.4463 - val_auc: 0.8045 - val_accuracy: 0.8106\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4486 - auc: 0.7995 - accuracy: 0.8047 - val_loss: 0.4461 - val_auc: 0.8081 - val_accuracy: 0.8106\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4493 - auc: 0.8007 - accuracy: 0.8043 - val_loss: 0.4483 - val_auc: 0.8071 - val_accuracy: 0.8125\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4498 - auc: 0.7993 - accuracy: 0.8047 - val_loss: 0.4467 - val_auc: 0.8072 - val_accuracy: 0.8117\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4493 - auc: 0.7988 - accuracy: 0.8061 - val_loss: 0.4459 - val_auc: 0.8071 - val_accuracy: 0.8127\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4492 - auc: 0.7985 - accuracy: 0.8034 - val_loss: 0.4466 - val_auc: 0.8087 - val_accuracy: 0.8117\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4486 - auc: 0.7994 - accuracy: 0.8050 - val_loss: 0.4461 - val_auc: 0.8082 - val_accuracy: 0.8115\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4501 - auc: 0.8011 - accuracy: 0.8043 - val_loss: 0.4479 - val_auc: 0.8043 - val_accuracy: 0.8115\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4497 - auc: 0.7964 - accuracy: 0.8048 - val_loss: 0.4459 - val_auc: 0.8097 - val_accuracy: 0.8096\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4487 - auc: 0.8010 - accuracy: 0.8062 - val_loss: 0.4456 - val_auc: 0.8095 - val_accuracy: 0.8115\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4488 - auc: 0.7999 - accuracy: 0.8050 - val_loss: 0.4462 - val_auc: 0.8097 - val_accuracy: 0.8121\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4491 - auc: 0.7998 - accuracy: 0.8044 - val_loss: 0.4454 - val_auc: 0.8092 - val_accuracy: 0.8110\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4482 - auc: 0.8007 - accuracy: 0.8060 - val_loss: 0.4463 - val_auc: 0.8116 - val_accuracy: 0.8123\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4483 - auc: 0.7992 - accuracy: 0.8041 - val_loss: 0.4474 - val_auc: 0.8073 - val_accuracy: 0.8110\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4476 - auc: 0.8019 - accuracy: 0.8079 - val_loss: 0.4465 - val_auc: 0.8106 - val_accuracy: 0.8119\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4473 - auc: 0.8030 - accuracy: 0.8045 - val_loss: 0.4448 - val_auc: 0.8089 - val_accuracy: 0.8125\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4485 - auc: 0.8023 - accuracy: 0.8046 - val_loss: 0.4461 - val_auc: 0.8105 - val_accuracy: 0.8119\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4475 - auc: 0.8030 - accuracy: 0.8071 - val_loss: 0.4462 - val_auc: 0.8105 - val_accuracy: 0.8127\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4481 - auc: 0.8038 - accuracy: 0.8051 - val_loss: 0.4495 - val_auc: 0.8105 - val_accuracy: 0.8117\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4477 - auc: 0.8068 - accuracy: 0.8056 - val_loss: 0.4456 - val_auc: 0.8130 - val_accuracy: 0.8115\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4466 - auc: 0.8058 - accuracy: 0.8064 - val_loss: 0.4453 - val_auc: 0.8116 - val_accuracy: 0.8106\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4473 - auc: 0.8063 - accuracy: 0.8061 - val_loss: 0.4448 - val_auc: 0.8136 - val_accuracy: 0.8110\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4476 - auc: 0.8076 - accuracy: 0.8067 - val_loss: 0.4446 - val_auc: 0.8137 - val_accuracy: 0.8127\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4473 - auc: 0.8061 - accuracy: 0.8047 - val_loss: 0.4458 - val_auc: 0.8116 - val_accuracy: 0.8119\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4474 - auc: 0.8057 - accuracy: 0.8057 - val_loss: 0.4454 - val_auc: 0.8132 - val_accuracy: 0.8117\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4461 - auc: 0.8070 - accuracy: 0.8080 - val_loss: 0.4452 - val_auc: 0.8136 - val_accuracy: 0.8115\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4474 - auc: 0.8056 - accuracy: 0.8072 - val_loss: 0.4453 - val_auc: 0.8156 - val_accuracy: 0.8123\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4475 - auc: 0.8071 - accuracy: 0.8066 - val_loss: 0.4446 - val_auc: 0.8142 - val_accuracy: 0.8108\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4476 - auc: 0.8057 - accuracy: 0.8067 - val_loss: 0.4451 - val_auc: 0.8152 - val_accuracy: 0.8125\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4482 - auc: 0.8072 - accuracy: 0.8044 - val_loss: 0.4443 - val_auc: 0.8154 - val_accuracy: 0.8110\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4456 - auc: 0.8081 - accuracy: 0.8066 - val_loss: 0.4472 - val_auc: 0.8132 - val_accuracy: 0.8110\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4472 - auc: 0.8109 - accuracy: 0.8075 - val_loss: 0.4454 - val_auc: 0.8162 - val_accuracy: 0.8127\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4462 - auc: 0.8105 - accuracy: 0.8072 - val_loss: 0.4446 - val_auc: 0.8161 - val_accuracy: 0.8121\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4476 - auc: 0.8085 - accuracy: 0.8068 - val_loss: 0.4449 - val_auc: 0.8174 - val_accuracy: 0.8108\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 9s 16ms/step - loss: 0.4466 - auc: 0.8104 - accuracy: 0.8057 - val_loss: 0.4456 - val_auc: 0.8162 - val_accuracy: 0.8119\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4447 - auc: 0.8115 - accuracy: 0.8067 - val_loss: 0.4448 - val_auc: 0.8165 - val_accuracy: 0.8110s: 0.4417 - auc: 0 - ETA: 0s - loss: 0.4418 - auc: 0.813\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4471 - auc: 0.8093 - accuracy: 0.8075 - val_loss: 0.4465 - val_auc: 0.8146 - val_accuracy: 0.8117\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.4462 - auc: 0.8088 - accuracy: 0.8071 - val_loss: 0.4485 - val_auc: 0.8122 - val_accuracy: 0.8102\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4455 - auc: 0.8106 - accuracy: 0.8062 - val_loss: 0.4453 - val_auc: 0.8177 - val_accuracy: 0.8131\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4458 - auc: 0.8119 - accuracy: 0.8080 - val_loss: 0.4449 - val_auc: 0.8174 - val_accuracy: 0.8119\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4482 - auc: 0.8097 - accuracy: 0.8067 - val_loss: 0.4457 - val_auc: 0.8160 - val_accuracy: 0.8119\n",
      "\n",
      "\n",
      "Train data shape: (19710, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 1th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "616/616 [==============================] - 12s 19ms/step - loss: 0.6281 - auc: 0.5861 - accuracy: 0.5867 - val_loss: 0.5958 - val_auc: 0.5449 - val_accuracy: 0.6250\n",
      "Epoch 2/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.5974 - auc: 0.5495 - accuracy: 0.6187 - val_loss: 0.5721 - val_auc: 0.5652 - val_accuracy: 0.6469\n",
      "Epoch 3/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.5838 - auc: 0.5685 - accuracy: 0.6410 - val_loss: 0.5606 - val_auc: 0.5887 - val_accuracy: 0.6629\n",
      "Epoch 4/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.5752 - auc: 0.5883 - accuracy: 0.6589 - val_loss: 0.5483 - val_auc: 0.6099 - val_accuracy: 0.6854\n",
      "Epoch 5/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.5664 - auc: 0.6022 - accuracy: 0.6809 - val_loss: 0.5381 - val_auc: 0.6261 - val_accuracy: 0.7042\n",
      "Epoch 6/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.5566 - auc: 0.6206 - accuracy: 0.6984 - val_loss: 0.5320 - val_auc: 0.6404 - val_accuracy: 0.7196\n",
      "Epoch 7/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.5474 - auc: 0.6364 - accuracy: 0.7156 - val_loss: 0.5208 - val_auc: 0.6617 - val_accuracy: 0.7396\n",
      "Epoch 8/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.5364 - auc: 0.6593 - accuracy: 0.7368 - val_loss: 0.5114 - val_auc: 0.6835 - val_accuracy: 0.7533\n",
      "Epoch 9/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.5243 - auc: 0.6813 - accuracy: 0.7471 - val_loss: 0.4975 - val_auc: 0.7117 - val_accuracy: 0.7721\n",
      "Epoch 10/100\n",
      "616/616 [==============================] - 11s 17ms/step - loss: 0.5141 - auc: 0.7028 - accuracy: 0.7583 - val_loss: 0.4939 - val_auc: 0.7225 - val_accuracy: 0.7740\n",
      "Epoch 11/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.5077 - auc: 0.7143 - accuracy: 0.7645 - val_loss: 0.4937 - val_auc: 0.7262 - val_accuracy: 0.7802\n",
      "Epoch 12/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.5022 - auc: 0.7249 - accuracy: 0.7700 - val_loss: 0.4802 - val_auc: 0.7441 - val_accuracy: 0.7837\n",
      "Epoch 13/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4992 - auc: 0.7306 - accuracy: 0.7729 - val_loss: 0.4753 - val_auc: 0.7522 - val_accuracy: 0.7910\n",
      "Epoch 14/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4954 - auc: 0.7399 - accuracy: 0.7778 - val_loss: 0.4767 - val_auc: 0.7576 - val_accuracy: 0.7931\n",
      "Epoch 15/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4908 - auc: 0.7463 - accuracy: 0.7818 - val_loss: 0.4706 - val_auc: 0.7672 - val_accuracy: 0.7992\n",
      "Epoch 16/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4881 - auc: 0.7528 - accuracy: 0.7821 - val_loss: 0.4639 - val_auc: 0.7735 - val_accuracy: 0.8021\n",
      "Epoch 17/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4843 - auc: 0.7568 - accuracy: 0.7855 - val_loss: 0.4646 - val_auc: 0.7767 - val_accuracy: 0.8019\n",
      "Epoch 18/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4815 - auc: 0.7620 - accuracy: 0.7882 - val_loss: 0.4567 - val_auc: 0.7829 - val_accuracy: 0.8029\n",
      "Epoch 19/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4790 - auc: 0.7653 - accuracy: 0.7856 - val_loss: 0.4564 - val_auc: 0.7834 - val_accuracy: 0.8031\n",
      "Epoch 20/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4797 - auc: 0.7696 - accuracy: 0.7869 - val_loss: 0.4538 - val_auc: 0.7894 - val_accuracy: 0.8048\n",
      "Epoch 21/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4769 - auc: 0.7714 - accuracy: 0.7887 - val_loss: 0.4527 - val_auc: 0.7887 - val_accuracy: 0.8037\n",
      "Epoch 22/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4757 - auc: 0.7711 - accuracy: 0.7890 - val_loss: 0.4545 - val_auc: 0.7890 - val_accuracy: 0.8065\n",
      "Epoch 23/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4748 - auc: 0.7742 - accuracy: 0.7882 - val_loss: 0.4548 - val_auc: 0.7894 - val_accuracy: 0.8058\n",
      "Epoch 24/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4731 - auc: 0.7765 - accuracy: 0.7911 - val_loss: 0.4512 - val_auc: 0.7941 - val_accuracy: 0.8052\n",
      "Epoch 25/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4745 - auc: 0.7771 - accuracy: 0.7892 - val_loss: 0.4509 - val_auc: 0.7931 - val_accuracy: 0.8054\n",
      "Epoch 26/100\n",
      "616/616 [==============================] - 12s 19ms/step - loss: 0.4736 - auc: 0.7763 - accuracy: 0.7901 - val_loss: 0.4523 - val_auc: 0.7905 - val_accuracy: 0.8073\n",
      "Epoch 27/100\n",
      "616/616 [==============================] - 12s 20ms/step - loss: 0.4721 - auc: 0.7772 - accuracy: 0.7896 - val_loss: 0.4493 - val_auc: 0.7959 - val_accuracy: 0.8065\n",
      "Epoch 28/100\n",
      "616/616 [==============================] - 12s 20ms/step - loss: 0.4711 - auc: 0.7801 - accuracy: 0.7916 - val_loss: 0.4495 - val_auc: 0.7962 - val_accuracy: 0.8071.4709 - auc: 0.7799 - accu\n",
      "Epoch 29/100\n",
      "616/616 [==============================] - 12s 20ms/step - loss: 0.4705 - auc: 0.7796 - accuracy: 0.7901 - val_loss: 0.4503 - val_auc: 0.7978 - val_accuracy: 0.80730 - auc: 0.7798 - accuracy\n",
      "Epoch 30/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4706 - auc: 0.7829 - accuracy: 0.7907 - val_loss: 0.4485 - val_auc: 0.7974 - val_accuracy: 0.8075\n",
      "Epoch 31/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4701 - auc: 0.7807 - accuracy: 0.7916 - val_loss: 0.4505 - val_auc: 0.7982 - val_accuracy: 0.8071\n",
      "Epoch 32/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4709 - auc: 0.7827 - accuracy: 0.7892 - val_loss: 0.4540 - val_auc: 0.7975 - val_accuracy: 0.8075\n",
      "Epoch 33/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4694 - auc: 0.7832 - accuracy: 0.7915 - val_loss: 0.4493 - val_auc: 0.7994 - val_accuracy: 0.8075\n",
      "Epoch 34/100\n",
      "616/616 [==============================] - 13s 21ms/step - loss: 0.4681 - auc: 0.7850 - accuracy: 0.7903 - val_loss: 0.4479 - val_auc: 0.8025 - val_accuracy: 0.8085\n",
      "Epoch 35/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4699 - auc: 0.7845 - accuracy: 0.7900 - val_loss: 0.4474 - val_auc: 0.8011 - val_accuracy: 0.8100\n",
      "Epoch 36/100\n",
      "616/616 [==============================] - 11s 17ms/step - loss: 0.4689 - auc: 0.7859 - accuracy: 0.7935 - val_loss: 0.4511 - val_auc: 0.8017 - val_accuracy: 0.8079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "616/616 [==============================] - 11s 17ms/step - loss: 0.4694 - auc: 0.7868 - accuracy: 0.7911 - val_loss: 0.4481 - val_auc: 0.8021 - val_accuracy: 0.8098\n",
      "Epoch 38/100\n",
      "616/616 [==============================] - 12s 19ms/step - loss: 0.4684 - auc: 0.7863 - accuracy: 0.7926 - val_loss: 0.4472 - val_auc: 0.8020 - val_accuracy: 0.8090\n",
      "Epoch 39/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4679 - auc: 0.7876 - accuracy: 0.7921 - val_loss: 0.4499 - val_auc: 0.8032 - val_accuracy: 0.8075\n",
      "Epoch 40/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4678 - auc: 0.7892 - accuracy: 0.7906 - val_loss: 0.4485 - val_auc: 0.8024 - val_accuracy: 0.8094\n",
      "Epoch 41/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4672 - auc: 0.7890 - accuracy: 0.7917 - val_loss: 0.4463 - val_auc: 0.8048 - val_accuracy: 0.8090\n",
      "Epoch 42/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4668 - auc: 0.7911 - accuracy: 0.7926 - val_loss: 0.4461 - val_auc: 0.8077 - val_accuracy: 0.8125\n",
      "Epoch 43/100\n",
      "616/616 [==============================] - 12s 19ms/step - loss: 0.4663 - auc: 0.7906 - accuracy: 0.7927 - val_loss: 0.4472 - val_auc: 0.8063 - val_accuracy: 0.8090\n",
      "Epoch 44/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4667 - auc: 0.7917 - accuracy: 0.7903 - val_loss: 0.4487 - val_auc: 0.8061 - val_accuracy: 0.8087\n",
      "Epoch 45/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4645 - auc: 0.7931 - accuracy: 0.7917 - val_loss: 0.4468 - val_auc: 0.8059 - val_accuracy: 0.8085\n",
      "Epoch 46/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4658 - auc: 0.7899 - accuracy: 0.7924 - val_loss: 0.4485 - val_auc: 0.8087 - val_accuracy: 0.8110\n",
      "Epoch 47/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4656 - auc: 0.7939 - accuracy: 0.7931 - val_loss: 0.4455 - val_auc: 0.8075 - val_accuracy: 0.8092\n",
      "Epoch 48/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4650 - auc: 0.7922 - accuracy: 0.7930 - val_loss: 0.4477 - val_auc: 0.8047 - val_accuracy: 0.8115\n",
      "Epoch 49/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4641 - auc: 0.7933 - accuracy: 0.7945 - val_loss: 0.4458 - val_auc: 0.8072 - val_accuracy: 0.8098\n",
      "Epoch 50/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4636 - auc: 0.7946 - accuracy: 0.7929 - val_loss: 0.4493 - val_auc: 0.8047 - val_accuracy: 0.8077\n",
      "Epoch 51/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4649 - auc: 0.7918 - accuracy: 0.7921 - val_loss: 0.4468 - val_auc: 0.8062 - val_accuracy: 0.8125\n",
      "Epoch 52/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4648 - auc: 0.7923 - accuracy: 0.7934 - val_loss: 0.4449 - val_auc: 0.8072 - val_accuracy: 0.8112\n",
      "Epoch 53/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4637 - auc: 0.7921 - accuracy: 0.7922 - val_loss: 0.4458 - val_auc: 0.8024 - val_accuracy: 0.8096\n",
      "Epoch 54/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4640 - auc: 0.7925 - accuracy: 0.7940 - val_loss: 0.4475 - val_auc: 0.8042 - val_accuracy: 0.8092\n",
      "Epoch 55/100\n",
      "616/616 [==============================] - 11s 18ms/step - loss: 0.4646 - auc: 0.7919 - accuracy: 0.7926 - val_loss: 0.4457 - val_auc: 0.8050 - val_accuracy: 0.8138\n",
      "Epoch 56/100\n",
      "616/616 [==============================] - 11s 19ms/step - loss: 0.4635 - auc: 0.7938 - accuracy: 0.7926 - val_loss: 0.4465 - val_auc: 0.8064 - val_accuracy: 0.8087\n",
      "\n",
      "\n",
      "Train data shape: (20669, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 2th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "646/646 [==============================] - 11s 18ms/step - loss: 0.6944 - auc: 0.5872 - accuracy: 0.5379 - val_loss: 0.6174 - val_auc: 0.5506 - val_accuracy: 0.6302\n",
      "Epoch 2/100\n",
      "646/646 [==============================] - 11s 17ms/step - loss: 0.6184 - auc: 0.5589 - accuracy: 0.6206 - val_loss: 0.5765 - val_auc: 0.5813 - val_accuracy: 0.6621s: 0.6190 - auc: 0.5570 - accura - E\n",
      "Epoch 3/100\n",
      "646/646 [==============================] - 11s 17ms/step - loss: 0.6026 - auc: 0.5809 - accuracy: 0.6532 - val_loss: 0.5554 - val_auc: 0.6081 - val_accuracy: 0.6904\n",
      "Epoch 4/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5900 - auc: 0.6022 - accuracy: 0.6758 - val_loss: 0.5503 - val_auc: 0.6312 - val_accuracy: 0.7104\n",
      "Epoch 5/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5823 - auc: 0.6212 - accuracy: 0.6901 - val_loss: 0.5460 - val_auc: 0.6577 - val_accuracy: 0.7567\n",
      "Epoch 6/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5741 - auc: 0.6559 - accuracy: 0.7184 - val_loss: 0.5402 - val_auc: 0.6999 - val_accuracy: 0.7621\n",
      "Epoch 7/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5612 - auc: 0.7001 - accuracy: 0.7369 - val_loss: 0.5260 - val_auc: 0.7561 - val_accuracy: 0.7840\n",
      "Epoch 8/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5520 - auc: 0.7329 - accuracy: 0.7503 - val_loss: 0.4978 - val_auc: 0.7898 - val_accuracy: 0.8017\n",
      "Epoch 9/100\n",
      "646/646 [==============================] - 10s 15ms/step - loss: 0.5416 - auc: 0.7582 - accuracy: 0.7635 - val_loss: 0.4967 - val_auc: 0.8083 - val_accuracy: 0.8073\n",
      "Epoch 10/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5333 - auc: 0.7743 - accuracy: 0.7690 - val_loss: 0.4885 - val_auc: 0.8179 - val_accuracy: 0.8096\n",
      "Epoch 11/100\n",
      "646/646 [==============================] - 11s 16ms/step - loss: 0.5293 - auc: 0.7809 - accuracy: 0.7719 - val_loss: 0.4861 - val_auc: 0.8207 - val_accuracy: 0.8087 loss: 0.5293 - auc: 0.7 - ETA: 0s - loss: 0.5290 - auc: 0.7811 - accuracy: \n",
      "Epoch 12/100\n",
      "646/646 [==============================] - 11s 17ms/step - loss: 0.5240 - auc: 0.7862 - accuracy: 0.7724 - val_loss: 0.4787 - val_auc: 0.8230 - val_accuracy: 0.8102\n",
      "Epoch 13/100\n",
      "646/646 [==============================] - 11s 17ms/step - loss: 0.5208 - auc: 0.7870 - accuracy: 0.7725 - val_loss: 0.4752 - val_auc: 0.8245 - val_accuracy: 0.8098\n",
      "Epoch 14/100\n",
      "646/646 [==============================] - 11s 17ms/step - loss: 0.5184 - auc: 0.7905 - accuracy: 0.7724 - val_loss: 0.4758 - val_auc: 0.8271 - val_accuracy: 0.8108\n",
      "Epoch 15/100\n",
      "646/646 [==============================] - 11s 17ms/step - loss: 0.5158 - auc: 0.7929 - accuracy: 0.7731 - val_loss: 0.4735 - val_auc: 0.8275 - val_accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5153 - auc: 0.7928 - accuracy: 0.7732 - val_loss: 0.4715 - val_auc: 0.8274 - val_accuracy: 0.8098\n",
      "Epoch 17/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5136 - auc: 0.7955 - accuracy: 0.7728 - val_loss: 0.4648 - val_auc: 0.8292 - val_accuracy: 0.8094\n",
      "Epoch 18/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5128 - auc: 0.7954 - accuracy: 0.7725 - val_loss: 0.4657 - val_auc: 0.8307 - val_accuracy: 0.8110\n",
      "Epoch 19/100\n",
      "646/646 [==============================] - 12s 18ms/step - loss: 0.5116 - auc: 0.7958 - accuracy: 0.7736 - val_loss: 0.4682 - val_auc: 0.8301 - val_accuracy: 0.8102\n",
      "Epoch 20/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5111 - auc: 0.7970 - accuracy: 0.7730 - val_loss: 0.4660 - val_auc: 0.8300 - val_accuracy: 0.8092\n",
      "Epoch 21/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5096 - auc: 0.7981 - accuracy: 0.7728 - val_loss: 0.4683 - val_auc: 0.8290 - val_accuracy: 0.8096\n",
      "Epoch 22/100\n",
      "646/646 [==============================] - 11s 17ms/step - loss: 0.5097 - auc: 0.7972 - accuracy: 0.7719 - val_loss: 0.4667 - val_auc: 0.8305 - val_accuracy: 0.8092\n",
      "Epoch 23/100\n",
      "646/646 [==============================] - 11s 17ms/step - loss: 0.5077 - auc: 0.8001 - accuracy: 0.7733 - val_loss: 0.4608 - val_auc: 0.8338 - val_accuracy: 0.8104\n",
      "Epoch 24/100\n",
      "646/646 [==============================] - 11s 16ms/step - loss: 0.5078 - auc: 0.7985 - accuracy: 0.7723 - val_loss: 0.4597 - val_auc: 0.8332 - val_accuracy: 0.8098\n",
      "Epoch 25/100\n",
      "646/646 [==============================] - 13s 20ms/step - loss: 0.5067 - auc: 0.7990 - accuracy: 0.7753 - val_loss: 0.4651 - val_auc: 0.8319 - val_accuracy: 0.8100\n",
      "Epoch 26/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5056 - auc: 0.8001 - accuracy: 0.7727 - val_loss: 0.4668 - val_auc: 0.8310 - val_accuracy: 0.8096\n",
      "Epoch 27/100\n",
      "646/646 [==============================] - 11s 17ms/step - loss: 0.5063 - auc: 0.7995 - accuracy: 0.7734 - val_loss: 0.4653 - val_auc: 0.8304 - val_accuracy: 0.8092\n",
      "Epoch 28/100\n",
      "646/646 [==============================] - 11s 17ms/step - loss: 0.5061 - auc: 0.7992 - accuracy: 0.7721 - val_loss: 0.4650 - val_auc: 0.8309 - val_accuracy: 0.8100\n",
      "Epoch 29/100\n",
      "646/646 [==============================] - 11s 17ms/step - loss: 0.5056 - auc: 0.7988 - accuracy: 0.7735 - val_loss: 0.4628 - val_auc: 0.8312 - val_accuracy: 0.8102\n",
      "Epoch 30/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5057 - auc: 0.7990 - accuracy: 0.7733 - val_loss: 0.4609 - val_auc: 0.8321 - val_accuracy: 0.8096- accuracy - ETA: 0s - loss: 0.5067 - auc: 0.798\n",
      "Epoch 31/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5055 - auc: 0.7992 - accuracy: 0.7735 - val_loss: 0.4634 - val_auc: 0.8312 - val_accuracy: 0.8108\n",
      "Epoch 32/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5044 - auc: 0.7995 - accuracy: 0.7745 - val_loss: 0.4638 - val_auc: 0.8303 - val_accuracy: 0.8098\n",
      "Epoch 33/100\n",
      "646/646 [==============================] - 10s 16ms/step - loss: 0.5049 - auc: 0.7990 - accuracy: 0.7731 - val_loss: 0.4610 - val_auc: 0.8313 - val_accuracy: 0.8100\n",
      "\n",
      "\n",
      "Train data shape: (21629, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 3th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "676/676 [==============================] - 11s 17ms/step - loss: 0.6545 - auc: 0.6085 - accuracy: 0.5909 - val_loss: 0.6033 - val_auc: 0.5752 - val_accuracy: 0.6190\n",
      "Epoch 2/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.6122 - auc: 0.5821 - accuracy: 0.6481 - val_loss: 0.5632 - val_auc: 0.6151 - val_accuracy: 0.6650\n",
      "Epoch 3/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.6001 - auc: 0.5959 - accuracy: 0.6606 - val_loss: 0.5623 - val_auc: 0.6230 - val_accuracy: 0.6808\n",
      "Epoch 4/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5924 - auc: 0.6124 - accuracy: 0.6698 - val_loss: 0.5499 - val_auc: 0.6407 - val_accuracy: 0.6906\n",
      "Epoch 5/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5849 - auc: 0.6254 - accuracy: 0.6759 - val_loss: 0.5395 - val_auc: 0.6589 - val_accuracy: 0.7021\n",
      "Epoch 6/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5824 - auc: 0.6377 - accuracy: 0.6863 - val_loss: 0.5338 - val_auc: 0.6789 - val_accuracy: 0.7233\n",
      "Epoch 7/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5771 - auc: 0.6510 - accuracy: 0.6915 - val_loss: 0.5280 - val_auc: 0.6955 - val_accuracy: 0.7277\n",
      "Epoch 8/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5748 - auc: 0.6600 - accuracy: 0.6973 - val_loss: 0.5262 - val_auc: 0.6998 - val_accuracy: 0.7258\n",
      "Epoch 9/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5702 - auc: 0.6706 - accuracy: 0.7029 - val_loss: 0.5177 - val_auc: 0.7125 - val_accuracy: 0.7429\n",
      "Epoch 10/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5676 - auc: 0.6788 - accuracy: 0.7087 - val_loss: 0.5216 - val_auc: 0.7113 - val_accuracy: 0.7442\n",
      "Epoch 11/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5639 - auc: 0.6856 - accuracy: 0.7146 - val_loss: 0.5123 - val_auc: 0.7334 - val_accuracy: 0.7581\n",
      "Epoch 12/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5619 - auc: 0.6966 - accuracy: 0.7188 - val_loss: 0.5065 - val_auc: 0.7450 - val_accuracy: 0.7633\n",
      "Epoch 13/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5578 - auc: 0.7051 - accuracy: 0.7231 - val_loss: 0.5048 - val_auc: 0.7514 - val_accuracy: 0.7683\n",
      "Epoch 14/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5558 - auc: 0.7164 - accuracy: 0.7283 - val_loss: 0.5045 - val_auc: 0.7561 - val_accuracy: 0.7698\n",
      "Epoch 15/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5547 - auc: 0.7198 - accuracy: 0.7303 - val_loss: 0.4959 - val_auc: 0.7732 - val_accuracy: 0.7810\n",
      "Epoch 16/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5515 - auc: 0.7312 - accuracy: 0.7338 - val_loss: 0.4946 - val_auc: 0.7776 - val_accuracy: 0.7896\n",
      "Epoch 17/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5482 - auc: 0.7395 - accuracy: 0.7391 - val_loss: 0.4922 - val_auc: 0.7877 - val_accuracy: 0.7921\n",
      "Epoch 18/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5446 - auc: 0.7457 - accuracy: 0.7427 - val_loss: 0.4868 - val_auc: 0.8066 - val_accuracy: 0.8010\n",
      "Epoch 19/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5432 - auc: 0.7583 - accuracy: 0.7495 - val_loss: 0.4860 - val_auc: 0.8045 - val_accuracy: 0.8037\n",
      "Epoch 20/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5406 - auc: 0.7618 - accuracy: 0.7517 - val_loss: 0.4793 - val_auc: 0.8205 - val_accuracy: 0.8069\n",
      "Epoch 21/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5400 - auc: 0.7670 - accuracy: 0.7527 - val_loss: 0.4735 - val_auc: 0.8260 - val_accuracy: 0.8094\n",
      "Epoch 22/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5373 - auc: 0.7707 - accuracy: 0.7562 - val_loss: 0.4727 - val_auc: 0.8248 - val_accuracy: 0.8100\n",
      "Epoch 23/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5348 - auc: 0.7761 - accuracy: 0.7564 - val_loss: 0.4697 - val_auc: 0.8261 - val_accuracy: 0.8121\n",
      "Epoch 24/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5332 - auc: 0.7754 - accuracy: 0.7551 - val_loss: 0.4741 - val_auc: 0.8238 - val_accuracy: 0.8112cy: 0.75 - ETA: 0s - loss: 0.5\n",
      "Epoch 25/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5326 - auc: 0.7763 - accuracy: 0.7551 - val_loss: 0.4667 - val_auc: 0.8271 - val_accuracy: 0.8108\n",
      "Epoch 26/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5330 - auc: 0.7762 - accuracy: 0.7558 - val_loss: 0.4653 - val_auc: 0.8287 - val_accuracy: 0.8121\n",
      "Epoch 27/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5315 - auc: 0.7771 - accuracy: 0.7560 - val_loss: 0.4705 - val_auc: 0.8246 - val_accuracy: 0.8117\n",
      "Epoch 28/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5310 - auc: 0.7791 - accuracy: 0.7578 - val_loss: 0.4701 - val_auc: 0.8268 - val_accuracy: 0.8098\n",
      "Epoch 29/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5307 - auc: 0.7789 - accuracy: 0.7570 - val_loss: 0.4693 - val_auc: 0.8261 - val_accuracy: 0.8115\n",
      "Epoch 30/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5275 - auc: 0.7807 - accuracy: 0.7575 - val_loss: 0.4708 - val_auc: 0.8234 - val_accuracy: 0.8104\n",
      "Epoch 31/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5285 - auc: 0.7800 - accuracy: 0.7573 - val_loss: 0.4676 - val_auc: 0.8245 - val_accuracy: 0.8102\n",
      "Epoch 32/100\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.5297 - auc: 0.7785 - accuracy: 0.7575 - val_loss: 0.4695 - val_auc: 0.8250 - val_accuracy: 0.8106\n",
      "Epoch 33/100\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.5271 - auc: 0.7809 - accuracy: 0.7582 - val_loss: 0.4652 - val_auc: 0.8262 - val_accuracy: 0.8098\n",
      "Epoch 34/100\n",
      "676/676 [==============================] - 13s 20ms/step - loss: 0.5292 - auc: 0.7779 - accuracy: 0.7566 - val_loss: 0.4703 - val_auc: 0.8233 - val_accuracy: 0.8102\n",
      "Epoch 35/100\n",
      "676/676 [==============================] - 12s 18ms/step - loss: 0.5271 - auc: 0.7777 - accuracy: 0.7559 - val_loss: 0.4632 - val_auc: 0.8280 - val_accuracy: 0.8102\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676/676 [==============================] - 12s 18ms/step - loss: 0.5261 - auc: 0.7800 - accuracy: 0.7574 - val_loss: 0.4630 - val_auc: 0.8263 - val_accuracy: 0.8106\n",
      "\n",
      "\n",
      "Train data shape: (22589, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 4th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.6695 - auc: 0.6101 - accuracy: 0.5885 - val_loss: 0.6525 - val_auc: 0.5850 - val_accuracy: 0.6185\n",
      "Epoch 2/100\n",
      "706/706 [==============================] - 14s 19ms/step - loss: 0.6281 - auc: 0.6221 - accuracy: 0.6650 - val_loss: 0.6215 - val_auc: 0.6448 - val_accuracy: 0.6706\n",
      "Epoch 3/100\n",
      "706/706 [==============================] - 12s 18ms/step - loss: 0.6109 - auc: 0.6705 - accuracy: 0.6906 - val_loss: 0.5898 - val_auc: 0.6990 - val_accuracy: 0.7229s: 0.6114 - auc: 0.6\n",
      "Epoch 4/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5982 - auc: 0.6956 - accuracy: 0.7098 - val_loss: 0.5734 - val_auc: 0.7262 - val_accuracy: 0.7377\n",
      "Epoch 5/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5897 - auc: 0.7142 - accuracy: 0.7229 - val_loss: 0.5496 - val_auc: 0.7525 - val_accuracy: 0.7713\n",
      "Epoch 6/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5824 - auc: 0.7259 - accuracy: 0.7274 - val_loss: 0.5412 - val_auc: 0.7684 - val_accuracy: 0.7775\n",
      "Epoch 7/100\n",
      "706/706 [==============================] - 12s 16ms/step - loss: 0.5780 - auc: 0.7350 - accuracy: 0.7318 - val_loss: 0.5311 - val_auc: 0.7881 - val_accuracy: 0.7881\n",
      "Epoch 8/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5725 - auc: 0.7446 - accuracy: 0.7366 - val_loss: 0.5226 - val_auc: 0.7931 - val_accuracy: 0.7910\n",
      "Epoch 9/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5684 - auc: 0.7488 - accuracy: 0.7367 - val_loss: 0.5165 - val_auc: 0.7997 - val_accuracy: 0.7937\n",
      "Epoch 10/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5663 - auc: 0.7530 - accuracy: 0.7374 - val_loss: 0.5080 - val_auc: 0.8069 - val_accuracy: 0.7975\n",
      "Epoch 11/100\n",
      "706/706 [==============================] - 12s 18ms/step - loss: 0.5630 - auc: 0.7560 - accuracy: 0.7376 - val_loss: 0.5045 - val_auc: 0.8082 - val_accuracy: 0.7967\n",
      "Epoch 12/100\n",
      "706/706 [==============================] - 12s 16ms/step - loss: 0.5624 - auc: 0.7557 - accuracy: 0.7377 - val_loss: 0.4999 - val_auc: 0.8108 - val_accuracy: 0.7985\n",
      "Epoch 13/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5611 - auc: 0.7570 - accuracy: 0.7371 - val_loss: 0.5034 - val_auc: 0.8082 - val_accuracy: 0.7969\n",
      "Epoch 14/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5582 - auc: 0.7596 - accuracy: 0.7385 - val_loss: 0.4880 - val_auc: 0.8163 - val_accuracy: 0.8035\n",
      "Epoch 15/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5576 - auc: 0.7591 - accuracy: 0.7394 - val_loss: 0.4889 - val_auc: 0.8172 - val_accuracy: 0.8040\n",
      "Epoch 16/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5559 - auc: 0.7611 - accuracy: 0.7397 - val_loss: 0.4908 - val_auc: 0.8146 - val_accuracy: 0.8010\n",
      "Epoch 17/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5534 - auc: 0.7635 - accuracy: 0.7406 - val_loss: 0.4894 - val_auc: 0.8153 - val_accuracy: 0.8006\n",
      "Epoch 18/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5535 - auc: 0.7629 - accuracy: 0.7405 - val_loss: 0.4797 - val_auc: 0.8209 - val_accuracy: 0.8052\n",
      "Epoch 19/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5523 - auc: 0.7641 - accuracy: 0.7415 - val_loss: 0.4764 - val_auc: 0.8217 - val_accuracy: 0.8062\n",
      "Epoch 20/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5501 - auc: 0.7657 - accuracy: 0.7416 - val_loss: 0.4780 - val_auc: 0.8189 - val_accuracy: 0.8052\n",
      "Epoch 21/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5494 - auc: 0.7660 - accuracy: 0.7430 - val_loss: 0.4842 - val_auc: 0.8172 - val_accuracy: 0.8031\n",
      "Epoch 22/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5487 - auc: 0.7666 - accuracy: 0.7429 - val_loss: 0.4752 - val_auc: 0.8228 - val_accuracy: 0.8062\n",
      "Epoch 23/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5480 - auc: 0.7679 - accuracy: 0.7432 - val_loss: 0.4768 - val_auc: 0.8208 - val_accuracy: 0.8050\n",
      "Epoch 24/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5476 - auc: 0.7668 - accuracy: 0.7441 - val_loss: 0.4784 - val_auc: 0.8188 - val_accuracy: 0.8025\n",
      "Epoch 25/100\n",
      "706/706 [==============================] - 12s 16ms/step - loss: 0.5466 - auc: 0.7681 - accuracy: 0.7442 - val_loss: 0.4753 - val_auc: 0.8213 - val_accuracy: 0.8029\n",
      "Epoch 26/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5449 - auc: 0.7697 - accuracy: 0.7435 - val_loss: 0.4687 - val_auc: 0.8249 - val_accuracy: 0.8067\n",
      "Epoch 27/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5445 - auc: 0.7704 - accuracy: 0.7446 - val_loss: 0.4806 - val_auc: 0.8168 - val_accuracy: 0.8029\n",
      "Epoch 28/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5432 - auc: 0.7704 - accuracy: 0.7479 - val_loss: 0.4741 - val_auc: 0.8216 - val_accuracy: 0.8035\n",
      "Epoch 29/100\n",
      "706/706 [==============================] - 12s 16ms/step - loss: 0.5428 - auc: 0.7709 - accuracy: 0.7468 - val_loss: 0.4759 - val_auc: 0.8203 - val_accuracy: 0.8037\n",
      "Epoch 30/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5431 - auc: 0.7696 - accuracy: 0.7452 - val_loss: 0.4713 - val_auc: 0.8200 - val_accuracy: 0.8040 loss:\n",
      "Epoch 31/100\n",
      "706/706 [==============================] - 11s 15ms/step - loss: 0.5418 - auc: 0.7701 - accuracy: 0.7483 - val_loss: 0.4717 - val_auc: 0.8200 - val_accuracy: 0.8031\n",
      "Epoch 32/100\n",
      "706/706 [==============================] - 12s 16ms/step - loss: 0.5406 - auc: 0.7711 - accuracy: 0.7501 - val_loss: 0.4724 - val_auc: 0.8215 - val_accuracy: 0.8035\n",
      "Epoch 33/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5396 - auc: 0.7733 - accuracy: 0.7493 - val_loss: 0.4668 - val_auc: 0.8226 - val_accuracy: 0.8037\n",
      "Epoch 34/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5393 - auc: 0.7725 - accuracy: 0.7493 - val_loss: 0.4739 - val_auc: 0.8186 - val_accuracy: 0.8012\n",
      "Epoch 35/100\n",
      "706/706 [==============================] - 11s 16ms/step - loss: 0.5402 - auc: 0.7708 - accuracy: 0.7488 - val_loss: 0.4774 - val_auc: 0.8174 - val_accuracy: 0.8019\n",
      "Epoch 36/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5384 - auc: 0.7733 - accuracy: 0.7492 - val_loss: 0.4663 - val_auc: 0.8239 - val_accuracy: 0.8052\n",
      "\n",
      "\n",
      "Train data shape: (23549, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 5th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "736/736 [==============================] - 12s 17ms/step - loss: 0.6616 - auc: 0.5827 - accuracy: 0.5839 - val_loss: 0.5979 - val_auc: 0.5723 - val_accuracy: 0.6656\n",
      "Epoch 2/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.6183 - auc: 0.5847 - accuracy: 0.6555 - val_loss: 0.5790 - val_auc: 0.6129 - val_accuracy: 0.6825\n",
      "Epoch 3/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.6094 - auc: 0.6113 - accuracy: 0.6694 - val_loss: 0.5606 - val_auc: 0.6388 - val_accuracy: 0.7154\n",
      "Epoch 4/100\n",
      "736/736 [==============================] - 13s 17ms/step - loss: 0.6015 - auc: 0.6255 - accuracy: 0.6813 - val_loss: 0.5491 - val_auc: 0.6623 - val_accuracy: 0.7448\n",
      "Epoch 5/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5962 - auc: 0.6429 - accuracy: 0.6955 - val_loss: 0.5490 - val_auc: 0.6751 - val_accuracy: 0.7563\n",
      "Epoch 6/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5922 - auc: 0.6605 - accuracy: 0.7075 - val_loss: 0.5365 - val_auc: 0.6976 - val_accuracy: 0.7840\n",
      "Epoch 7/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5847 - auc: 0.6838 - accuracy: 0.7199 - val_loss: 0.5328 - val_auc: 0.7365 - val_accuracy: 0.7775\n",
      "Epoch 8/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5795 - auc: 0.7155 - accuracy: 0.7267 - val_loss: 0.5143 - val_auc: 0.7727 - val_accuracy: 0.8040\n",
      "Epoch 9/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5752 - auc: 0.7258 - accuracy: 0.7311 - val_loss: 0.5038 - val_auc: 0.7985 - val_accuracy: 0.8110\n",
      "Epoch 10/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5735 - auc: 0.7320 - accuracy: 0.7318 - val_loss: 0.5001 - val_auc: 0.8050 - val_accuracy: 0.8112\n",
      "Epoch 11/100\n",
      "736/736 [==============================] - 11s 16ms/step - loss: 0.5710 - auc: 0.7351 - accuracy: 0.7332 - val_loss: 0.5126 - val_auc: 0.7832 - val_accuracy: 0.8092\n",
      "Epoch 12/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5688 - auc: 0.7382 - accuracy: 0.7344 - val_loss: 0.4941 - val_auc: 0.8138 - val_accuracy: 0.8121\n",
      "Epoch 13/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5668 - auc: 0.7420 - accuracy: 0.7326 - val_loss: 0.4900 - val_auc: 0.8151 - val_accuracy: 0.8127\n",
      "Epoch 14/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5663 - auc: 0.7420 - accuracy: 0.7347 - val_loss: 0.4862 - val_auc: 0.8181 - val_accuracy: 0.8129\n",
      "Epoch 15/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5663 - auc: 0.7464 - accuracy: 0.7357 - val_loss: 0.4865 - val_auc: 0.8211 - val_accuracy: 0.8121\n",
      "Epoch 16/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5649 - auc: 0.7472 - accuracy: 0.7332 - val_loss: 0.4841 - val_auc: 0.8221 - val_accuracy: 0.8117\n",
      "Epoch 17/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5635 - auc: 0.7495 - accuracy: 0.7355 - val_loss: 0.4803 - val_auc: 0.8224 - val_accuracy: 0.8115\n",
      "Epoch 18/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5633 - auc: 0.7493 - accuracy: 0.7357 - val_loss: 0.4853 - val_auc: 0.8204 - val_accuracy: 0.8098TA: 0s - loss: 0.5632 - auc: 0.7494 - accura\n",
      "Epoch 19/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5632 - auc: 0.7497 - accuracy: 0.7346 - val_loss: 0.4875 - val_auc: 0.8169 - val_accuracy: 0.8115\n",
      "Epoch 20/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5614 - auc: 0.7512 - accuracy: 0.7357 - val_loss: 0.4823 - val_auc: 0.8248 - val_accuracy: 0.8112\n",
      "Epoch 21/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5607 - auc: 0.7523 - accuracy: 0.7360 - val_loss: 0.4761 - val_auc: 0.8273 - val_accuracy: 0.8123\n",
      "Epoch 22/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5595 - auc: 0.7544 - accuracy: 0.7359 - val_loss: 0.4834 - val_auc: 0.8255 - val_accuracy: 0.8123\n",
      "Epoch 23/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5608 - auc: 0.7536 - accuracy: 0.7363 - val_loss: 0.4824 - val_auc: 0.8231 - val_accuracy: 0.8129\n",
      "Epoch 24/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5602 - auc: 0.7543 - accuracy: 0.7362 - val_loss: 0.4772 - val_auc: 0.8269 - val_accuracy: 0.8135\n",
      "Epoch 25/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5595 - auc: 0.7554 - accuracy: 0.7366 - val_loss: 0.4803 - val_auc: 0.8246 - val_accuracy: 0.8123\n",
      "Epoch 26/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5578 - auc: 0.7559 - accuracy: 0.7365 - val_loss: 0.4764 - val_auc: 0.8274 - val_accuracy: 0.8135\n",
      "Epoch 27/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5580 - auc: 0.7566 - accuracy: 0.7371 - val_loss: 0.4771 - val_auc: 0.8274 - val_accuracy: 0.8131\n",
      "Epoch 28/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5586 - auc: 0.7556 - accuracy: 0.7373 - val_loss: 0.4757 - val_auc: 0.8269 - val_accuracy: 0.8129\n",
      "Epoch 29/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5585 - auc: 0.7553 - accuracy: 0.7369 - val_loss: 0.4718 - val_auc: 0.8304 - val_accuracy: 0.8131\n",
      "Epoch 30/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5569 - auc: 0.7569 - accuracy: 0.7377 - val_loss: 0.4720 - val_auc: 0.8294 - val_accuracy: 0.8129\n",
      "Epoch 31/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5570 - auc: 0.7570 - accuracy: 0.7363 - val_loss: 0.4744 - val_auc: 0.8289 - val_accuracy: 0.8117\n",
      "Epoch 32/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5558 - auc: 0.7581 - accuracy: 0.7380 - val_loss: 0.4722 - val_auc: 0.8307 - val_accuracy: 0.8123\n",
      "Epoch 33/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5556 - auc: 0.7580 - accuracy: 0.7361 - val_loss: 0.4741 - val_auc: 0.8283 - val_accuracy: 0.8129\n",
      "Epoch 34/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5564 - auc: 0.7590 - accuracy: 0.7388 - val_loss: 0.4723 - val_auc: 0.8296 - val_accuracy: 0.8129\n",
      "Epoch 35/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5544 - auc: 0.7607 - accuracy: 0.7380 - val_loss: 0.4797 - val_auc: 0.8250 - val_accuracy: 0.8121\n",
      "Epoch 36/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5543 - auc: 0.7596 - accuracy: 0.7374 - val_loss: 0.4682 - val_auc: 0.8332 - val_accuracy: 0.8135\n",
      "Epoch 37/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5539 - auc: 0.7622 - accuracy: 0.7377 - val_loss: 0.4702 - val_auc: 0.8314 - val_accuracy: 0.8138\n",
      "Epoch 38/100\n",
      "736/736 [==============================] - 13s 18ms/step - loss: 0.5532 - auc: 0.7615 - accuracy: 0.7388 - val_loss: 0.4746 - val_auc: 0.8255 - val_accuracy: 0.8131\n",
      "Epoch 39/100\n",
      "736/736 [==============================] - 13s 18ms/step - loss: 0.5550 - auc: 0.7595 - accuracy: 0.7384 - val_loss: 0.4754 - val_auc: 0.8277 - val_accuracy: 0.8127\n",
      "Epoch 40/100\n",
      "736/736 [==============================] - 11s 16ms/step - loss: 0.5539 - auc: 0.7607 - accuracy: 0.7391 - val_loss: 0.4695 - val_auc: 0.8326 - val_accuracy: 0.8121\n",
      "Epoch 41/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5531 - auc: 0.7623 - accuracy: 0.7386 - val_loss: 0.4705 - val_auc: 0.8297 - val_accuracy: 0.8127\n",
      "Epoch 42/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5534 - auc: 0.7614 - accuracy: 0.7379 - val_loss: 0.4698 - val_auc: 0.8304 - val_accuracy: 0.8127\n",
      "Epoch 43/100\n",
      "736/736 [==============================] - 11s 16ms/step - loss: 0.5530 - auc: 0.7613 - accuracy: 0.7373 - val_loss: 0.4749 - val_auc: 0.8280 - val_accuracy: 0.8123\n",
      "Epoch 44/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5514 - auc: 0.7629 - accuracy: 0.7394 - val_loss: 0.4691 - val_auc: 0.8301 - val_accuracy: 0.8121\n",
      "Epoch 45/100\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.5532 - auc: 0.7619 - accuracy: 0.7377 - val_loss: 0.4676 - val_auc: 0.8319 - val_accuracy: 0.8133\n",
      "Epoch 46/100\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.5518 - auc: 0.7627 - accuracy: 0.7400 - val_loss: 0.4683 - val_auc: 0.8318 - val_accuracy: 0.8119\n",
      "\n",
      "\n",
      "Train data shape: (24509, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 6th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6756 - auc: 0.6124 - accuracy: 0.5948 - val_loss: 0.6072 - val_auc: 0.6041 - val_accuracy: 0.7013 - loss: 0.6771 - auc: 0.6147 - accuracy: 0. - ETA: 0s - loss: 0.6770 - auc: 0.614\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.6279 - auc: 0.6020 - accuracy: 0.6555 - val_loss: 0.5867 - val_auc: 0.6521 - val_accuracy: 0.6958\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.6134 - auc: 0.6358 - accuracy: 0.6731 - val_loss: 0.5726 - val_auc: 0.6747 - val_accuracy: 0.7204\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.6071 - auc: 0.6529 - accuracy: 0.6832 - val_loss: 0.5642 - val_auc: 0.7198 - val_accuracy: 0.7513\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5996 - auc: 0.6760 - accuracy: 0.6931 - val_loss: 0.5542 - val_auc: 0.7357 - val_accuracy: 0.7533\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5949 - auc: 0.6920 - accuracy: 0.7024 - val_loss: 0.5418 - val_auc: 0.7526 - val_accuracy: 0.7763\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 13s 16ms/step - loss: 0.5896 - auc: 0.7038 - accuracy: 0.7081 - val_loss: 0.5438 - val_auc: 0.7533 - val_accuracy: 0.7790\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5856 - auc: 0.7157 - accuracy: 0.7107 - val_loss: 0.5329 - val_auc: 0.7781 - val_accuracy: 0.7962\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5826 - auc: 0.7245 - accuracy: 0.7146 - val_loss: 0.5278 - val_auc: 0.7919 - val_accuracy: 0.7910\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 13s 16ms/step - loss: 0.5804 - auc: 0.7315 - accuracy: 0.7144 - val_loss: 0.5206 - val_auc: 0.7957 - val_accuracy: 0.7987- auc: - ETA: 0s - loss: 0.579\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5795 - auc: 0.7318 - accuracy: 0.7142 - val_loss: 0.5248 - val_auc: 0.7986 - val_accuracy: 0.7956\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5792 - auc: 0.7325 - accuracy: 0.7160 - val_loss: 0.5167 - val_auc: 0.8020 - val_accuracy: 0.7987\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5767 - auc: 0.7365 - accuracy: 0.7158 - val_loss: 0.5115 - val_auc: 0.8093 - val_accuracy: 0.7992\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5759 - auc: 0.7387 - accuracy: 0.7160 - val_loss: 0.5119 - val_auc: 0.8055 - val_accuracy: 0.7994\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5734 - auc: 0.7409 - accuracy: 0.7172 - val_loss: 0.5177 - val_auc: 0.8041 - val_accuracy: 0.7962\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5730 - auc: 0.7428 - accuracy: 0.7180 - val_loss: 0.5160 - val_auc: 0.8035 - val_accuracy: 0.7952\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5731 - auc: 0.7428 - accuracy: 0.7187 - val_loss: 0.5056 - val_auc: 0.8125 - val_accuracy: 0.7971\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5712 - auc: 0.7442 - accuracy: 0.7207 - val_loss: 0.5130 - val_auc: 0.8035 - val_accuracy: 0.7946\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5722 - auc: 0.7433 - accuracy: 0.7189 - val_loss: 0.5033 - val_auc: 0.8141 - val_accuracy: 0.7987\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5712 - auc: 0.7445 - accuracy: 0.7201 - val_loss: 0.5025 - val_auc: 0.8134 - val_accuracy: 0.7987\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5714 - auc: 0.7444 - accuracy: 0.7185 - val_loss: 0.5028 - val_auc: 0.8148 - val_accuracy: 0.7977\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5690 - auc: 0.7462 - accuracy: 0.7192 - val_loss: 0.5073 - val_auc: 0.8106 - val_accuracy: 0.7952\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5702 - auc: 0.7460 - accuracy: 0.7219 - val_loss: 0.5033 - val_auc: 0.8126 - val_accuracy: 0.7960\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5695 - auc: 0.7466 - accuracy: 0.7201 - val_loss: 0.4964 - val_auc: 0.8187 - val_accuracy: 0.7990\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5687 - auc: 0.7464 - accuracy: 0.7204 - val_loss: 0.5119 - val_auc: 0.8058 - val_accuracy: 0.7921\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5694 - auc: 0.7458 - accuracy: 0.7189 - val_loss: 0.5030 - val_auc: 0.8128 - val_accuracy: 0.7950\n",
      "Epoch 27/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5677 - auc: 0.7473 - accuracy: 0.7230 - val_loss: 0.5144 - val_auc: 0.8036 - val_accuracy: 0.7904\n",
      "Epoch 28/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5682 - auc: 0.7473 - accuracy: 0.7210 - val_loss: 0.5026 - val_auc: 0.8127 - val_accuracy: 0.7952\n",
      "Epoch 29/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5684 - auc: 0.7481 - accuracy: 0.7226 - val_loss: 0.4920 - val_auc: 0.8210 - val_accuracy: 0.8002\n",
      "Epoch 30/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5673 - auc: 0.7481 - accuracy: 0.7223 - val_loss: 0.4991 - val_auc: 0.8143 - val_accuracy: 0.7971\n",
      "Epoch 31/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5667 - auc: 0.7499 - accuracy: 0.7231 - val_loss: 0.4963 - val_auc: 0.8173 - val_accuracy: 0.7971\n",
      "Epoch 32/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5648 - auc: 0.7509 - accuracy: 0.7228 - val_loss: 0.5042 - val_auc: 0.8110 - val_accuracy: 0.7910\n",
      "Epoch 33/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5656 - auc: 0.7497 - accuracy: 0.7245 - val_loss: 0.4978 - val_auc: 0.8149 - val_accuracy: 0.7954\n",
      "Epoch 34/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5657 - auc: 0.7503 - accuracy: 0.7222 - val_loss: 0.4992 - val_auc: 0.8144 - val_accuracy: 0.7954\n",
      "Epoch 35/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5654 - auc: 0.7504 - accuracy: 0.7259 - val_loss: 0.5004 - val_auc: 0.8128 - val_accuracy: 0.7946\n",
      "Epoch 36/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5661 - auc: 0.7503 - accuracy: 0.7238 - val_loss: 0.4947 - val_auc: 0.8174 - val_accuracy: 0.7954\n",
      "Epoch 37/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5653 - auc: 0.7502 - accuracy: 0.7235 - val_loss: 0.4901 - val_auc: 0.8197 - val_accuracy: 0.7977\n",
      "Epoch 38/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5651 - auc: 0.7501 - accuracy: 0.7237 - val_loss: 0.5009 - val_auc: 0.8125 - val_accuracy: 0.7940\n",
      "Epoch 39/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5648 - auc: 0.7508 - accuracy: 0.7263 - val_loss: 0.4905 - val_auc: 0.8203 - val_accuracy: 0.7975\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 각각의 모델로 각각의 표본 학습 \n",
    "\n",
    "epochs = 100\n",
    "plot_list = []\n",
    "model_list = []\n",
    "learning_rate = 0.00001\n",
    "list_index = 0\n",
    "\n",
    "for (j, sample) in enumerate(sampling_list):\n",
    "    \n",
    "    X_train_preprocessing = sample[0]\n",
    "    X_train_add_feature = sample[1]\n",
    "    y_train_preprocessing = sample[3]\n",
    "    \n",
    "    length = len(X_train_preprocessing)\n",
    "    \n",
    "    print(\"Train data shape: {} Val data shape: {}\".format(X_train_preprocessing.shape, X_val_preprocessing.shape))\n",
    "    print(\"Training the model with {}th sample\".format(j))\n",
    "    print(\"-----------------------------------------------\")\n",
    "    \n",
    "    model = RNN_Model(learning_rate)\n",
    "    epoch, hist = train_model(model, [X_train_preprocessing, X_train_add_feature], y_train_preprocessing, \n",
    "                              [X_val_preprocessing, X_val_add_feature], y_val_preprocessing, epochs = epochs, batch_size = 32, patience = 10)\n",
    "    model_list.append(model)\n",
    "    plot_list.append([epoch, hist])\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the 0th model\n",
      "0th model's \u001b[35m Precision \u001b[30m: 62.57 \u001b[35m Recall \u001b[30m: 39.03 \u001b[35m F1-score \u001b[30m: 0.48 \u001b[35m Accuracy\u001b[30m: 0.81 \n",
      "\n",
      "Predicting the 1th model\n",
      "1th model's \u001b[35m Precision \u001b[30m: 63.36 \u001b[35m Recall \u001b[30m: 36.32 \u001b[35m F1-score \u001b[30m: 0.46 \u001b[35m Accuracy\u001b[30m: 0.81 \n",
      "\n",
      "Predicting the 2th model\n",
      "2th model's \u001b[35m Precision \u001b[30m: 62.64 \u001b[35m Recall \u001b[30m: 37.25 \u001b[35m F1-score \u001b[30m: 0.47 \u001b[35m Accuracy\u001b[30m: 0.81 \n",
      "\n",
      "Predicting the 3th model\n",
      "3th model's \u001b[35m Precision \u001b[30m: 62.67 \u001b[35m Recall \u001b[30m: 39.03 \u001b[35m F1-score \u001b[30m: 0.48 \u001b[35m Accuracy\u001b[30m: 0.81 \n",
      "\n",
      "Predicting the 4th model\n",
      "4th model's \u001b[35m Precision \u001b[30m: 58.71 \u001b[35m Recall \u001b[30m: 45.00 \u001b[35m F1-score \u001b[30m: 0.51 \u001b[35m Accuracy\u001b[30m: 0.81 \n",
      "\n",
      "Predicting the 5th model\n",
      "5th model's \u001b[35m Precision \u001b[30m: 62.50 \u001b[35m Recall \u001b[30m: 41.08 \u001b[35m F1-score \u001b[30m: 0.50 \u001b[35m Accuracy\u001b[30m: 0.81 \n",
      "\n",
      "Predicting the 6th model\n",
      "6th model's \u001b[35m Precision \u001b[30m: 56.07 \u001b[35m Recall \u001b[30m: 48.27 \u001b[35m F1-score \u001b[30m: 0.52 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# f1-score\n",
    "for (i, sample) in enumerate(sampling_list):\n",
    "    \n",
    "    print(\"Predicting the {}th model\".format(i))\n",
    "    \n",
    "    model = model_list[i]\n",
    "    y_proba = model.predict([X_val_preprocessing, X_val_add_feature])\n",
    "    y_pred = np.argmax(y_proba, axis = 1)\n",
    "    \n",
    "    precision, recall, f1, accuracy = f1_score(y_val, y_pred)\n",
    "    print(\"{}th model's \\033[35m Precision \\033[30m: {:.2f} \\033[35m Recall \\033[30m: {:.2f} \\033[35m F1-score \\033[30m: {:.2f} \\033[35m Accuracy\\033[30m: {:.2f} \\n\".format(i, precision * 100, recall * 100, f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_list = np.array([.0] * (len(X_val_preprocessing) * 2)).reshape(-1, 2)\n",
    "\n",
    "for (i, model) in enumerate(model_list):\n",
    "    \n",
    "    y_proba = model.predict([X_val_preprocessing, X_val_add_feature])\n",
    "    proba_list += y_proba\n",
    "    \n",
    "y_pred = np.argmax((proba_list / len(model_list)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION SET\n",
      "\u001b[35mPrecision\u001b[30m: 0.62, \u001b[35mRecall\u001b[30m: 0.41, \u001b[35mF1-Score\u001b[30m: 0.50, \u001b[35mAccuracy\u001b[30m: 0.81\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1,accuracy = f1_score(y_val, y_pred)\n",
    "print(\"VALIDATION SET\")\n",
    "print(\"\\033[35mPrecision\\033[30m: {:.2f}, \\033[35mRecall\\033[30m: {:.2f}, \\033[35mF1-Score\\033[30m: {:.2f}, \\033[35mAccuracy\\033[30m: {:.2f}\".format(precision, recall, f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_list = np.array([.0] * (len(X_test) * 2)).reshape(-1, 2)\n",
    "\n",
    "for (i, model) in enumerate(model_list):\n",
    "    \n",
    "    y_proba = model.predict([X_test_preprocessing, X_test_add_feature])\n",
    "    proba_list += y_proba\n",
    "    \n",
    "y_pred = np.argmax((proba_list / len(model_list)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SET\n",
      "\u001b[35mPrecision\u001b[30m: 0.62, \u001b[35mRecall\u001b[30m: 0.45, \u001b[35mF1-Score\u001b[30m: 0.52, \u001b[35mAccuracy\u001b[30m: 0.82\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1,accuracy = f1_score(y_test, y_pred)\n",
    "print(\"TEST SET\")\n",
    "print(\"\\033[35mPrecision\\033[30m: {:.2f}, \\033[35mRecall\\033[30m: {:.2f}, \\033[35mF1-Score\\033[30m: {:.2f}, \\033[35mAccuracy\\033[30m: {:.2f}\".format(precision, recall, f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## default의 비율이 0.4%가 되도록 뽑는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "sample_size = [0.4, 0.4, 0.4, 0.4, 0.4, 0.4]\n",
    "sampling_list = []\n",
    "\n",
    "for (i, size) in enumerate(sample_size):\n",
    "    if size == 0:    \n",
    "        df = load_sampling(split_train, size, return_default = True)\n",
    "    else:\n",
    "        df = load_sampling(split_train, size)\n",
    "    \n",
    "    X_train_preprocessing, X_train_add_feature, y_train_before, y_train_preprocessing = preprocessing(df)\n",
    "    \n",
    "    sampling_list.append([X_train_preprocessing, X_train_add_feature, y_train_before, y_train_preprocessing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (22589, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 0th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.6764 - auc: 0.5298 - accuracy: 0.5619 - val_loss: 0.6268 - val_auc: 0.5737 - val_accuracy: 0.6183\n",
      "Epoch 2/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.6393 - auc: 0.5662 - accuracy: 0.6059 - val_loss: 0.5955 - val_auc: 0.5936 - val_accuracy: 0.6506\n",
      "Epoch 3/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.6274 - auc: 0.5736 - accuracy: 0.6252 - val_loss: 0.5840 - val_auc: 0.6013 - val_accuracy: 0.6710 loss: 0.6274 - auc: 0.5735 - accura\n",
      "Epoch 4/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.6214 - auc: 0.5812 - accuracy: 0.6342 - val_loss: 0.5789 - val_auc: 0.6130 - val_accuracy: 0.6704\n",
      "Epoch 5/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.6179 - auc: 0.5899 - accuracy: 0.6437 - val_loss: 0.5733 - val_auc: 0.6300 - val_accuracy: 0.6883\n",
      "Epoch 6/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.6142 - auc: 0.6013 - accuracy: 0.6513 - val_loss: 0.5700 - val_auc: 0.6354 - val_accuracy: 0.6963\n",
      "Epoch 7/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.6106 - auc: 0.6077 - accuracy: 0.6605 - val_loss: 0.5621 - val_auc: 0.6440 - val_accuracy: 0.6983\n",
      "Epoch 8/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.6085 - auc: 0.6137 - accuracy: 0.6635 - val_loss: 0.5573 - val_auc: 0.6544 - val_accuracy: 0.7179\n",
      "Epoch 9/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.6069 - auc: 0.6209 - accuracy: 0.6723 - val_loss: 0.5597 - val_auc: 0.6558 - val_accuracy: 0.6979\n",
      "Epoch 10/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.6059 - auc: 0.6268 - accuracy: 0.6731 - val_loss: 0.5562 - val_auc: 0.6693 - val_accuracy: 0.7229\n",
      "Epoch 11/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.6024 - auc: 0.6370 - accuracy: 0.6797 - val_loss: 0.5512 - val_auc: 0.6776 - val_accuracy: 0.7319\n",
      "Epoch 12/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5998 - auc: 0.6450 - accuracy: 0.6868 - val_loss: 0.5461 - val_auc: 0.6987 - val_accuracy: 0.7565\n",
      "Epoch 13/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5985 - auc: 0.6555 - accuracy: 0.6894 - val_loss: 0.5471 - val_auc: 0.7009 - val_accuracy: 0.7473\n",
      "Epoch 14/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5972 - auc: 0.6652 - accuracy: 0.6952 - val_loss: 0.5450 - val_auc: 0.7131 - val_accuracy: 0.7579\n",
      "Epoch 15/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5966 - auc: 0.6749 - accuracy: 0.6991 - val_loss: 0.5385 - val_auc: 0.7320 - val_accuracy: 0.7675\n",
      "Epoch 16/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5933 - auc: 0.6889 - accuracy: 0.7037 - val_loss: 0.5459 - val_auc: 0.7369 - val_accuracy: 0.7665\n",
      "Epoch 17/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5913 - auc: 0.6971 - accuracy: 0.7054 - val_loss: 0.5370 - val_auc: 0.7683 - val_accuracy: 0.7890\n",
      "Epoch 18/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5885 - auc: 0.7123 - accuracy: 0.7138 - val_loss: 0.5281 - val_auc: 0.7863 - val_accuracy: 0.7937\n",
      "Epoch 19/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.5873 - auc: 0.7221 - accuracy: 0.7162 - val_loss: 0.5299 - val_auc: 0.7840 - val_accuracy: 0.7946\n",
      "Epoch 20/100\n",
      "706/706 [==============================] - 12s 18ms/step - loss: 0.5861 - auc: 0.7273 - accuracy: 0.7163 - val_loss: 0.5204 - val_auc: 0.8048 - val_accuracy: 0.7990\n",
      "Epoch 21/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5845 - auc: 0.7331 - accuracy: 0.7174 - val_loss: 0.5130 - val_auc: 0.8118 - val_accuracy: 0.8015\n",
      "Epoch 22/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5835 - auc: 0.7353 - accuracy: 0.7168 - val_loss: 0.5178 - val_auc: 0.8109 - val_accuracy: 0.8019auc: 0.7346 - accuracy: 0. - ETA: 1s - loss: 0.5841 - auc: 0.7346 - accuracy:  - ETA: 0s - loss: 0.5843 - auc: 0.7343 - accuracy - ETA: 0s - loss: 0.5836 - auc: 0\n",
      "Epoch 23/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5839 - auc: 0.7347 - accuracy: 0.7184 - val_loss: 0.5185 - val_auc: 0.8125 - val_accuracy: 0.8004 loss: 0.585 - ETA: 1s\n",
      "Epoch 24/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5832 - auc: 0.7366 - accuracy: 0.7194 - val_loss: 0.5077 - val_auc: 0.8174 - val_accuracy: 0.8019\n",
      "Epoch 25/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5833 - auc: 0.7375 - accuracy: 0.7173 - val_loss: 0.5083 - val_auc: 0.8187 - val_accuracy: 0.8015\n",
      "Epoch 26/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5811 - auc: 0.7413 - accuracy: 0.7180 - val_loss: 0.5050 - val_auc: 0.8209 - val_accuracy: 0.8017\n",
      "Epoch 27/100\n",
      "706/706 [==============================] - 12s 18ms/step - loss: 0.5813 - auc: 0.7413 - accuracy: 0.7179 - val_loss: 0.5064 - val_auc: 0.8204 - val_accuracy: 0.8012\n",
      "Epoch 28/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5810 - auc: 0.7405 - accuracy: 0.7169 - val_loss: 0.5058 - val_auc: 0.8189 - val_accuracy: 0.8027\n",
      "Epoch 29/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5809 - auc: 0.7401 - accuracy: 0.7177 - val_loss: 0.5046 - val_auc: 0.8230 - val_accuracy: 0.8023\n",
      "Epoch 30/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5811 - auc: 0.7402 - accuracy: 0.7183 - val_loss: 0.5047 - val_auc: 0.8179 - val_accuracy: 0.8031\n",
      "Epoch 31/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5814 - auc: 0.7402 - accuracy: 0.7174 - val_loss: 0.5064 - val_auc: 0.8179 - val_accuracy: 0.8008\n",
      "Epoch 32/100\n",
      "706/706 [==============================] - 12s 18ms/step - loss: 0.5817 - auc: 0.7377 - accuracy: 0.7176 - val_loss: 0.5031 - val_auc: 0.8200 - val_accuracy: 0.8029\n",
      "Epoch 33/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5790 - auc: 0.7420 - accuracy: 0.7195 - val_loss: 0.5060 - val_auc: 0.8188 - val_accuracy: 0.8027\n",
      "Epoch 34/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5778 - auc: 0.7435 - accuracy: 0.7190 - val_loss: 0.5098 - val_auc: 0.8149 - val_accuracy: 0.8040\n",
      "\n",
      "\n",
      "Train data shape: (22589, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 1th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "706/706 [==============================] - 17s 23ms/step - loss: 0.6803 - auc: 0.5955 - accuracy: 0.5593 - val_loss: 0.6383 - val_auc: 0.5546 - val_accuracy: 0.6121\n",
      "Epoch 2/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6467 - auc: 0.5558 - accuracy: 0.5924 - val_loss: 0.5985 - val_auc: 0.5846 - val_accuracy: 0.6442\n",
      "Epoch 3/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6390 - auc: 0.5652 - accuracy: 0.6076 - val_loss: 0.5987 - val_auc: 0.5903 - val_accuracy: 0.6581653 - accu\n",
      "Epoch 4/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6333 - auc: 0.5742 - accuracy: 0.6230 - val_loss: 0.5989 - val_auc: 0.5975 - val_accuracy: 0.6627\n",
      "Epoch 5/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6297 - auc: 0.5826 - accuracy: 0.6289 - val_loss: 0.5841 - val_auc: 0.6146 - val_accuracy: 0.6650\n",
      "Epoch 6/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6267 - auc: 0.5914 - accuracy: 0.6385 - val_loss: 0.5869 - val_auc: 0.6238 - val_accuracy: 0.6790\n",
      "Epoch 7/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6238 - auc: 0.6027 - accuracy: 0.6466 - val_loss: 0.5788 - val_auc: 0.6407 - val_accuracy: 0.6919\n",
      "Epoch 8/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6208 - auc: 0.6094 - accuracy: 0.6566 - val_loss: 0.5801 - val_auc: 0.6478 - val_accuracy: 0.6873\n",
      "Epoch 9/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6181 - auc: 0.6175 - accuracy: 0.6566 - val_loss: 0.5714 - val_auc: 0.6662 - val_accuracy: 0.7215\n",
      "Epoch 10/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6158 - auc: 0.6260 - accuracy: 0.6624 - val_loss: 0.5686 - val_auc: 0.6724 - val_accuracy: 0.7106\n",
      "Epoch 11/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6125 - auc: 0.6368 - accuracy: 0.6660 - val_loss: 0.5611 - val_auc: 0.6853 - val_accuracy: 0.7233\n",
      "Epoch 12/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6104 - auc: 0.6434 - accuracy: 0.6738 - val_loss: 0.5547 - val_auc: 0.7042 - val_accuracy: 0.7387\n",
      "Epoch 13/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6092 - auc: 0.6521 - accuracy: 0.6776 - val_loss: 0.5517 - val_auc: 0.7114 - val_accuracy: 0.7433\n",
      "Epoch 14/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6058 - auc: 0.6597 - accuracy: 0.6799 - val_loss: 0.5580 - val_auc: 0.7117 - val_accuracy: 0.7360\n",
      "Epoch 15/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6043 - auc: 0.6686 - accuracy: 0.6875 - val_loss: 0.5623 - val_auc: 0.7219 - val_accuracy: 0.7412\n",
      "Epoch 16/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6033 - auc: 0.6761 - accuracy: 0.6867 - val_loss: 0.5486 - val_auc: 0.7448 - val_accuracy: 0.7617\n",
      "Epoch 17/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6018 - auc: 0.6834 - accuracy: 0.6900 - val_loss: 0.5402 - val_auc: 0.7524 - val_accuracy: 0.7690\n",
      "Epoch 18/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5993 - auc: 0.6898 - accuracy: 0.6937 - val_loss: 0.5486 - val_auc: 0.7612 - val_accuracy: 0.7727\n",
      "Epoch 19/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5984 - auc: 0.6982 - accuracy: 0.6965 - val_loss: 0.5308 - val_auc: 0.7860 - val_accuracy: 0.7867\n",
      "Epoch 20/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5964 - auc: 0.7049 - accuracy: 0.7015 - val_loss: 0.5351 - val_auc: 0.7761 - val_accuracy: 0.7848\n",
      "Epoch 21/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5950 - auc: 0.7098 - accuracy: 0.7049 - val_loss: 0.5290 - val_auc: 0.7927 - val_accuracy: 0.7890\n",
      "Epoch 22/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5939 - auc: 0.7189 - accuracy: 0.7045 - val_loss: 0.5297 - val_auc: 0.7990 - val_accuracy: 0.7946 - loss: 0.5951 - auc: 0.7165 - accu - -\n",
      "Epoch 23/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5922 - auc: 0.7249 - accuracy: 0.7080 - val_loss: 0.5322 - val_auc: 0.7972 - val_accuracy: 0.7856\n",
      "Epoch 24/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5898 - auc: 0.7290 - accuracy: 0.7092 - val_loss: 0.5187 - val_auc: 0.8115 - val_accuracy: 0.7950\n",
      "Epoch 25/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5898 - auc: 0.7320 - accuracy: 0.7083 - val_loss: 0.5206 - val_auc: 0.8127 - val_accuracy: 0.7962\n",
      "Epoch 26/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5904 - auc: 0.7310 - accuracy: 0.7072 - val_loss: 0.5296 - val_auc: 0.8034 - val_accuracy: 0.7910\n",
      "Epoch 27/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5894 - auc: 0.7344 - accuracy: 0.7107 - val_loss: 0.5210 - val_auc: 0.8166 - val_accuracy: 0.7965\n",
      "Epoch 28/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5897 - auc: 0.7347 - accuracy: 0.7092 - val_loss: 0.5223 - val_auc: 0.8093 - val_accuracy: 0.7935TA: 0s - loss: 0.5898 - auc: 0.7348 \n",
      "Epoch 29/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5877 - auc: 0.7357 - accuracy: 0.7092 - val_loss: 0.5187 - val_auc: 0.8150 - val_accuracy: 0.7952\n",
      "Epoch 30/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5887 - auc: 0.7358 - accuracy: 0.7107 - val_loss: 0.5272 - val_auc: 0.8071 - val_accuracy: 0.7948\n",
      "Epoch 31/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5882 - auc: 0.7374 - accuracy: 0.7096 - val_loss: 0.5262 - val_auc: 0.8156 - val_accuracy: 0.7931\n",
      "Epoch 32/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5888 - auc: 0.7372 - accuracy: 0.7103 - val_loss: 0.5152 - val_auc: 0.8194 - val_accuracy: 0.7985\n",
      "Epoch 33/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5876 - auc: 0.7379 - accuracy: 0.7106 - val_loss: 0.5088 - val_auc: 0.8191 - val_accuracy: 0.7998\n",
      "Epoch 34/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5862 - auc: 0.7379 - accuracy: 0.7106 - val_loss: 0.5164 - val_auc: 0.8168 - val_accuracy: 0.7983\n",
      "Epoch 35/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5882 - auc: 0.7369 - accuracy: 0.7089 - val_loss: 0.5107 - val_auc: 0.8170 - val_accuracy: 0.7985\n",
      "Epoch 36/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5862 - auc: 0.7376 - accuracy: 0.7110 - val_loss: 0.5144 - val_auc: 0.8198 - val_accuracy: 0.8004\n",
      "Epoch 37/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5865 - auc: 0.7372 - accuracy: 0.7120 - val_loss: 0.5275 - val_auc: 0.8110 - val_accuracy: 0.7894\n",
      "Epoch 38/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5855 - auc: 0.7397 - accuracy: 0.7121 - val_loss: 0.5141 - val_auc: 0.8222 - val_accuracy: 0.7992\n",
      "Epoch 39/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5855 - auc: 0.7403 - accuracy: 0.7111 - val_loss: 0.5167 - val_auc: 0.8169 - val_accuracy: 0.7969\n",
      "Epoch 40/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5851 - auc: 0.7388 - accuracy: 0.7110 - val_loss: 0.5166 - val_auc: 0.8171 - val_accuracy: 0.7994\n",
      "Epoch 41/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5860 - auc: 0.7392 - accuracy: 0.7125 - val_loss: 0.5119 - val_auc: 0.8202 - val_accuracy: 0.7985\n",
      "Epoch 42/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5850 - auc: 0.7420 - accuracy: 0.7115 - val_loss: 0.5092 - val_auc: 0.8211 - val_accuracy: 0.7985\n",
      "Epoch 43/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5844 - auc: 0.7417 - accuracy: 0.7114 - val_loss: 0.5091 - val_auc: 0.8193 - val_accuracy: 0.7994\n",
      "\n",
      "\n",
      "Train data shape: (22589, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 2th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.6979 - auc: 0.5610 - accuracy: 0.5317 - val_loss: 0.6633 - val_auc: 0.5176 - val_accuracy: 0.5671\n",
      "Epoch 2/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6633 - auc: 0.5211 - accuracy: 0.5674 - val_loss: 0.6434 - val_auc: 0.5247 - val_accuracy: 0.5860\n",
      "Epoch 3/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6527 - auc: 0.5301 - accuracy: 0.5848 - val_loss: 0.6137 - val_auc: 0.5470 - val_accuracy: 0.6296\n",
      "Epoch 4/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6486 - auc: 0.5404 - accuracy: 0.5987 - val_loss: 0.6069 - val_auc: 0.5644 - val_accuracy: 0.6521\n",
      "Epoch 5/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6427 - auc: 0.5526 - accuracy: 0.6135 - val_loss: 0.5993 - val_auc: 0.5840 - val_accuracy: 0.6627\n",
      "Epoch 6/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6369 - auc: 0.5655 - accuracy: 0.6238 - val_loss: 0.5913 - val_auc: 0.6017 - val_accuracy: 0.6840\n",
      "Epoch 7/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.6310 - auc: 0.5791 - accuracy: 0.6362 - val_loss: 0.5949 - val_auc: 0.6087 - val_accuracy: 0.6985 loss: 0.6309 - auc: 0.5792 - accuracy: 0.63\n",
      "Epoch 8/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6259 - auc: 0.5928 - accuracy: 0.6489 - val_loss: 0.5962 - val_auc: 0.6209 - val_accuracy: 0.6898\n",
      "Epoch 9/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6215 - auc: 0.6064 - accuracy: 0.6581 - val_loss: 0.5662 - val_auc: 0.6699 - val_accuracy: 0.7271\n",
      "Epoch 10/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6152 - auc: 0.6270 - accuracy: 0.6717 - val_loss: 0.5770 - val_auc: 0.6798 - val_accuracy: 0.7360\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6100 - auc: 0.6554 - accuracy: 0.6846 - val_loss: 0.5603 - val_auc: 0.7295 - val_accuracy: 0.7592\n",
      "Epoch 12/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6039 - auc: 0.6842 - accuracy: 0.6954 - val_loss: 0.5581 - val_auc: 0.7557 - val_accuracy: 0.7654\n",
      "Epoch 13/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5988 - auc: 0.7103 - accuracy: 0.7019 - val_loss: 0.5361 - val_auc: 0.7916 - val_accuracy: 0.7871\n",
      "Epoch 14/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5953 - auc: 0.7224 - accuracy: 0.7072 - val_loss: 0.5382 - val_auc: 0.7983 - val_accuracy: 0.7912\n",
      "Epoch 15/100\n",
      "706/706 [==============================] - 15s 21ms/step - loss: 0.5912 - auc: 0.7317 - accuracy: 0.7086 - val_loss: 0.5247 - val_auc: 0.8109 - val_accuracy: 0.7977\n",
      "Epoch 16/100\n",
      "706/706 [==============================] - 16s 23ms/step - loss: 0.5896 - auc: 0.7352 - accuracy: 0.7082 - val_loss: 0.5407 - val_auc: 0.7965 - val_accuracy: 0.7852\n",
      "Epoch 17/100\n",
      "706/706 [==============================] - 15s 22ms/step - loss: 0.5898 - auc: 0.7369 - accuracy: 0.7106 - val_loss: 0.5270 - val_auc: 0.8064 - val_accuracy: 0.7946\n",
      "Epoch 18/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.5885 - auc: 0.7358 - accuracy: 0.7098 - val_loss: 0.5116 - val_auc: 0.8187 - val_accuracy: 0.7996\n",
      "Epoch 19/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.5843 - auc: 0.7417 - accuracy: 0.7107 - val_loss: 0.5130 - val_auc: 0.8187 - val_accuracy: 0.7998\n",
      "Epoch 20/100\n",
      "706/706 [==============================] - 16s 23ms/step - loss: 0.5857 - auc: 0.7403 - accuracy: 0.7102 - val_loss: 0.5172 - val_auc: 0.8155 - val_accuracy: 0.7969\n",
      "Epoch 21/100\n",
      "706/706 [==============================] - 16s 23ms/step - loss: 0.5857 - auc: 0.7425 - accuracy: 0.7134 - val_loss: 0.5170 - val_auc: 0.8210 - val_accuracy: 0.7969\n",
      "Epoch 22/100\n",
      "706/706 [==============================] - 15s 21ms/step - loss: 0.5841 - auc: 0.7421 - accuracy: 0.7124 - val_loss: 0.5046 - val_auc: 0.8238 - val_accuracy: 0.7985\n",
      "Epoch 23/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5853 - auc: 0.7395 - accuracy: 0.7107 - val_loss: 0.5116 - val_auc: 0.8186 - val_accuracy: 0.7962\n",
      "Epoch 24/100\n",
      "706/706 [==============================] - 16s 22ms/step - loss: 0.5845 - auc: 0.7405 - accuracy: 0.7126 - val_loss: 0.5171 - val_auc: 0.8105 - val_accuracy: 0.7944\n",
      "Epoch 25/100\n",
      "706/706 [==============================] - 15s 21ms/step - loss: 0.5844 - auc: 0.7410 - accuracy: 0.7136 - val_loss: 0.5121 - val_auc: 0.8191 - val_accuracy: 0.7985\n",
      "Epoch 26/100\n",
      "706/706 [==============================] - 14s 19ms/step - loss: 0.5833 - auc: 0.7421 - accuracy: 0.7120 - val_loss: 0.5061 - val_auc: 0.8218 - val_accuracy: 0.7994\n",
      "Epoch 27/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5820 - auc: 0.7441 - accuracy: 0.7131 - val_loss: 0.5000 - val_auc: 0.8283 - val_accuracy: 0.7990\n",
      "Epoch 28/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5831 - auc: 0.7438 - accuracy: 0.7134 - val_loss: 0.4950 - val_auc: 0.8311 - val_accuracy: 0.8002\n",
      "Epoch 29/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5824 - auc: 0.7449 - accuracy: 0.7141 - val_loss: 0.4996 - val_auc: 0.8249 - val_accuracy: 0.7990\n",
      "Epoch 30/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5815 - auc: 0.7426 - accuracy: 0.7139 - val_loss: 0.5065 - val_auc: 0.8206 - val_accuracy: 0.7996\n",
      "Epoch 31/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5827 - auc: 0.7428 - accuracy: 0.7131 - val_loss: 0.5106 - val_auc: 0.8178 - val_accuracy: 0.7971\n",
      "Epoch 32/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.5817 - auc: 0.7410 - accuracy: 0.7118 - val_loss: 0.5043 - val_auc: 0.8189 - val_accuracy: 0.7998\n",
      "Epoch 33/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5808 - auc: 0.7445 - accuracy: 0.7153 - val_loss: 0.5005 - val_auc: 0.8196 - val_accuracy: 0.8012\n",
      "\n",
      "\n",
      "Train data shape: (22589, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 3th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "706/706 [==============================] - 17s 24ms/step - loss: 0.6929 - auc: 0.5706 - accuracy: 0.5350 - val_loss: 0.6437 - val_auc: 0.5308 - val_accuracy: 0.5967\n",
      "Epoch 2/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.6619 - auc: 0.5299 - accuracy: 0.5837 - val_loss: 0.6208 - val_auc: 0.5421 - val_accuracy: 0.6358\n",
      "Epoch 3/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.6500 - auc: 0.5392 - accuracy: 0.6024 - val_loss: 0.6101 - val_auc: 0.5601 - val_accuracy: 0.6635\n",
      "Epoch 4/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6433 - auc: 0.5489 - accuracy: 0.6180 - val_loss: 0.5910 - val_auc: 0.5779 - val_accuracy: 0.6833\n",
      "Epoch 5/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6349 - auc: 0.5612 - accuracy: 0.6359 - val_loss: 0.5756 - val_auc: 0.6070 - val_accuracy: 0.7094\n",
      "Epoch 6/100\n",
      "706/706 [==============================] - 14s 21ms/step - loss: 0.6269 - auc: 0.5798 - accuracy: 0.6521 - val_loss: 0.5689 - val_auc: 0.6246 - val_accuracy: 0.7383\n",
      "Epoch 7/100\n",
      "706/706 [==============================] - 15s 21ms/step - loss: 0.6188 - auc: 0.5996 - accuracy: 0.6656 - val_loss: 0.5551 - val_auc: 0.6585 - val_accuracy: 0.7494\n",
      "Epoch 8/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6106 - auc: 0.6262 - accuracy: 0.6856 - val_loss: 0.5444 - val_auc: 0.6903 - val_accuracy: 0.7683\n",
      "Epoch 9/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6036 - auc: 0.6507 - accuracy: 0.6920 - val_loss: 0.5451 - val_auc: 0.7098 - val_accuracy: 0.7765\n",
      "Epoch 10/100\n",
      "706/706 [==============================] - 14s 19ms/step - loss: 0.5976 - auc: 0.6721 - accuracy: 0.7026 - val_loss: 0.5440 - val_auc: 0.7374 - val_accuracy: 0.7837\n",
      "Epoch 11/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.5924 - auc: 0.6950 - accuracy: 0.7048 - val_loss: 0.5225 - val_auc: 0.7755 - val_accuracy: 0.7946\n",
      "Epoch 12/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.5877 - auc: 0.7116 - accuracy: 0.7093 - val_loss: 0.5265 - val_auc: 0.7831 - val_accuracy: 0.7923\n",
      "Epoch 13/100\n",
      "706/706 [==============================] - 14s 19ms/step - loss: 0.5873 - auc: 0.7206 - accuracy: 0.7079 - val_loss: 0.5017 - val_auc: 0.8136 - val_accuracy: 0.8004\n",
      "Epoch 14/100\n",
      "706/706 [==============================] - 15s 21ms/step - loss: 0.5856 - auc: 0.7276 - accuracy: 0.7099 - val_loss: 0.5078 - val_auc: 0.8141 - val_accuracy: 0.7971\n",
      "Epoch 15/100\n",
      "706/706 [==============================] - 16s 22ms/step - loss: 0.5828 - auc: 0.7322 - accuracy: 0.7120 - val_loss: 0.5038 - val_auc: 0.8169 - val_accuracy: 0.7987\n",
      "Epoch 16/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.5828 - auc: 0.7342 - accuracy: 0.7127 - val_loss: 0.5020 - val_auc: 0.8205 - val_accuracy: 0.7990\n",
      "Epoch 17/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5823 - auc: 0.7377 - accuracy: 0.7132 - val_loss: 0.4960 - val_auc: 0.8221 - val_accuracy: 0.8004\n",
      "Epoch 18/100\n",
      "706/706 [==============================] - 15s 21ms/step - loss: 0.5814 - auc: 0.7393 - accuracy: 0.7148 - val_loss: 0.5009 - val_auc: 0.8234 - val_accuracy: 0.8002\n",
      "Epoch 19/100\n",
      "706/706 [==============================] - 15s 21ms/step - loss: 0.5802 - auc: 0.7409 - accuracy: 0.7119 - val_loss: 0.4957 - val_auc: 0.8238 - val_accuracy: 0.7998\n",
      "Epoch 20/100\n",
      "706/706 [==============================] - 15s 22ms/step - loss: 0.5801 - auc: 0.7405 - accuracy: 0.7142 - val_loss: 0.4984 - val_auc: 0.8198 - val_accuracy: 0.7973\n",
      "Epoch 21/100\n",
      "706/706 [==============================] - 15s 21ms/step - loss: 0.5801 - auc: 0.7407 - accuracy: 0.7144 - val_loss: 0.5014 - val_auc: 0.8205 - val_accuracy: 0.7987\n",
      "Epoch 22/100\n",
      "706/706 [==============================] - 15s 21ms/step - loss: 0.5793 - auc: 0.7419 - accuracy: 0.7150 - val_loss: 0.4974 - val_auc: 0.8224 - val_accuracy: 0.8002\n",
      "Epoch 23/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5780 - auc: 0.7428 - accuracy: 0.7149 - val_loss: 0.4926 - val_auc: 0.8251 - val_accuracy: 0.7996\n",
      "Epoch 24/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.5783 - auc: 0.7420 - accuracy: 0.7171 - val_loss: 0.5024 - val_auc: 0.8175 - val_accuracy: 0.7985\n",
      "Epoch 25/100\n",
      "706/706 [==============================] - 14s 19ms/step - loss: 0.5783 - auc: 0.7424 - accuracy: 0.7154 - val_loss: 0.4973 - val_auc: 0.8211 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.5786 - auc: 0.7414 - accuracy: 0.7150 - val_loss: 0.4962 - val_auc: 0.8241 - val_accuracy: 0.8006\n",
      "Epoch 27/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.5763 - auc: 0.7445 - accuracy: 0.7160 - val_loss: 0.4952 - val_auc: 0.8230 - val_accuracy: 0.7969\n",
      "Epoch 28/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.5782 - auc: 0.7424 - accuracy: 0.7169 - val_loss: 0.5048 - val_auc: 0.8169 - val_accuracy: 0.7962\n",
      "\n",
      "\n",
      "Train data shape: (22589, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 4th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "706/706 [==============================] - 15s 21ms/step - loss: 0.6894 - auc: 0.5837 - accuracy: 0.5424 - val_loss: 0.6442 - val_auc: 0.5471 - val_accuracy: 0.5913\n",
      "Epoch 2/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.6528 - auc: 0.5408 - accuracy: 0.5904 - val_loss: 0.6084 - val_auc: 0.5658 - val_accuracy: 0.6544\n",
      "Epoch 3/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6423 - auc: 0.5502 - accuracy: 0.6123 - val_loss: 0.5976 - val_auc: 0.5765 - val_accuracy: 0.6475\n",
      "Epoch 4/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6350 - auc: 0.5598 - accuracy: 0.6228 - val_loss: 0.5806 - val_auc: 0.5982 - val_accuracy: 0.6800\n",
      "Epoch 5/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6301 - auc: 0.5722 - accuracy: 0.6373 - val_loss: 0.5815 - val_auc: 0.6151 - val_accuracy: 0.6913\n",
      "Epoch 6/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6250 - auc: 0.5882 - accuracy: 0.6461 - val_loss: 0.5692 - val_auc: 0.6352 - val_accuracy: 0.7283\n",
      "Epoch 7/100\n",
      "706/706 [==============================] - 14s 19ms/step - loss: 0.6213 - auc: 0.6012 - accuracy: 0.6570 - val_loss: 0.5637 - val_auc: 0.6546 - val_accuracy: 0.7204 loss: 0.6213 \n",
      "Epoch 8/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6165 - auc: 0.6136 - accuracy: 0.6627 - val_loss: 0.5609 - val_auc: 0.6708 - val_accuracy: 0.7390\n",
      "Epoch 9/100\n",
      "706/706 [==============================] - 14s 19ms/step - loss: 0.6139 - auc: 0.6254 - accuracy: 0.6703 - val_loss: 0.5641 - val_auc: 0.6686 - val_accuracy: 0.7173\n",
      "Epoch 10/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.6098 - auc: 0.6357 - accuracy: 0.6749 - val_loss: 0.5491 - val_auc: 0.7000 - val_accuracy: 0.7538\n",
      "Epoch 11/100\n",
      "706/706 [==============================] - 14s 19ms/step - loss: 0.6078 - auc: 0.6487 - accuracy: 0.6813 - val_loss: 0.5480 - val_auc: 0.7105 - val_accuracy: 0.7573\n",
      "Epoch 12/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.6055 - auc: 0.6574 - accuracy: 0.6858 - val_loss: 0.5457 - val_auc: 0.7223 - val_accuracy: 0.7483\n",
      "Epoch 13/100\n",
      "706/706 [==============================] - 14s 19ms/step - loss: 0.6018 - auc: 0.6689 - accuracy: 0.6900 - val_loss: 0.5437 - val_auc: 0.7298 - val_accuracy: 0.7552\n",
      "Epoch 14/100\n",
      "706/706 [==============================] - 15s 21ms/step - loss: 0.5994 - auc: 0.6813 - accuracy: 0.6959 - val_loss: 0.5350 - val_auc: 0.7493 - val_accuracy: 0.7658\n",
      "Epoch 15/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.5976 - auc: 0.6889 - accuracy: 0.6972 - val_loss: 0.5303 - val_auc: 0.7720 - val_accuracy: 0.7844\n",
      "Epoch 16/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.5938 - auc: 0.7032 - accuracy: 0.7047 - val_loss: 0.5288 - val_auc: 0.7772 - val_accuracy: 0.7860\n",
      "Epoch 17/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.5926 - auc: 0.7120 - accuracy: 0.7079 - val_loss: 0.5208 - val_auc: 0.7949 - val_accuracy: 0.7954\n",
      "Epoch 18/100\n",
      "706/706 [==============================] - 15s 21ms/step - loss: 0.5928 - auc: 0.7158 - accuracy: 0.7074 - val_loss: 0.5233 - val_auc: 0.7989 - val_accuracy: 0.7935\n",
      "Epoch 19/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.5889 - auc: 0.7251 - accuracy: 0.7110 - val_loss: 0.5207 - val_auc: 0.7972 - val_accuracy: 0.7944\n",
      "Epoch 20/100\n",
      "706/706 [==============================] - 15s 21ms/step - loss: 0.5871 - auc: 0.7273 - accuracy: 0.7118 - val_loss: 0.5066 - val_auc: 0.8214 - val_accuracy: 0.8002\n",
      "Epoch 21/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.5875 - auc: 0.7298 - accuracy: 0.7112 - val_loss: 0.5110 - val_auc: 0.8161 - val_accuracy: 0.7994\n",
      "Epoch 22/100\n",
      "706/706 [==============================] - 15s 21ms/step - loss: 0.5856 - auc: 0.7347 - accuracy: 0.7157 - val_loss: 0.5110 - val_auc: 0.8172 - val_accuracy: 0.8006\n",
      "Epoch 23/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.5855 - auc: 0.7329 - accuracy: 0.7122 - val_loss: 0.5116 - val_auc: 0.8106 - val_accuracy: 0.7990\n",
      "Epoch 24/100\n",
      "706/706 [==============================] - 14s 19ms/step - loss: 0.5846 - auc: 0.7351 - accuracy: 0.7165 - val_loss: 0.5043 - val_auc: 0.8220 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.5848 - auc: 0.7367 - accuracy: 0.7155 - val_loss: 0.5072 - val_auc: 0.8164 - val_accuracy: 0.7992\n",
      "Epoch 26/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.5837 - auc: 0.7357 - accuracy: 0.7150 - val_loss: 0.5041 - val_auc: 0.8213 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.5846 - auc: 0.7347 - accuracy: 0.7136 - val_loss: 0.5071 - val_auc: 0.8194 - val_accuracy: 0.7990\n",
      "Epoch 28/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.5836 - auc: 0.7358 - accuracy: 0.7132 - val_loss: 0.5020 - val_auc: 0.8214 - val_accuracy: 0.8010\n",
      "Epoch 29/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.5833 - auc: 0.7361 - accuracy: 0.7161 - val_loss: 0.5062 - val_auc: 0.8162 - val_accuracy: 0.7996\n",
      "\n",
      "\n",
      "Train data shape: (22589, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 5th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "706/706 [==============================] - 15s 22ms/step - loss: 0.6786 - auc: 0.5879 - accuracy: 0.5507 - val_loss: 0.6296 - val_auc: 0.5711 - val_accuracy: 0.6044\n",
      "Epoch 2/100\n",
      "706/706 [==============================] - 14s 19ms/step - loss: 0.6522 - auc: 0.5572 - accuracy: 0.5790 - val_loss: 0.5991 - val_auc: 0.5891 - val_accuracy: 0.6408\n",
      "Epoch 3/100\n",
      "706/706 [==============================] - 14s 19ms/step - loss: 0.6477 - auc: 0.5609 - accuracy: 0.5854 - val_loss: 0.6122 - val_auc: 0.5748 - val_accuracy: 0.6246\n",
      "Epoch 4/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6445 - auc: 0.5642 - accuracy: 0.5935 - val_loss: 0.6032 - val_auc: 0.5846 - val_accuracy: 0.6381 0.5643 - accura\n",
      "Epoch 5/100\n",
      "706/706 [==============================] - 14s 19ms/step - loss: 0.6417 - auc: 0.5681 - accuracy: 0.6000 - val_loss: 0.6001 - val_auc: 0.5882 - val_accuracy: 0.6583\n",
      "Epoch 6/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.6402 - auc: 0.5709 - accuracy: 0.6076 - val_loss: 0.5965 - val_auc: 0.5945 - val_accuracy: 0.6508\n",
      "Epoch 7/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6381 - auc: 0.5752 - accuracy: 0.6125 - val_loss: 0.5929 - val_auc: 0.6017 - val_accuracy: 0.6700\n",
      "Epoch 8/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.6339 - auc: 0.5799 - accuracy: 0.6196 - val_loss: 0.5962 - val_auc: 0.5977 - val_accuracy: 0.6598\n",
      "Epoch 9/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.6322 - auc: 0.5841 - accuracy: 0.6277 - val_loss: 0.5992 - val_auc: 0.6010 - val_accuracy: 0.6544\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 14s 20ms/step - loss: 0.6286 - auc: 0.5901 - accuracy: 0.6346 - val_loss: 0.5886 - val_auc: 0.6177 - val_accuracy: 0.6642\n",
      "Epoch 11/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.6239 - auc: 0.5996 - accuracy: 0.6447 - val_loss: 0.5767 - val_auc: 0.6345 - val_accuracy: 0.7144\n",
      "Epoch 12/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.6207 - auc: 0.6081 - accuracy: 0.6531 - val_loss: 0.5763 - val_auc: 0.6435 - val_accuracy: 0.7208\n",
      "Epoch 13/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6153 - auc: 0.6203 - accuracy: 0.6680 - val_loss: 0.5727 - val_auc: 0.6561 - val_accuracy: 0.7250\n",
      "Epoch 14/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.6103 - auc: 0.6367 - accuracy: 0.6756 - val_loss: 0.5614 - val_auc: 0.6801 - val_accuracy: 0.7342\n",
      "Epoch 15/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.6051 - auc: 0.6544 - accuracy: 0.6910 - val_loss: 0.5740 - val_auc: 0.6853 - val_accuracy: 0.7296\n",
      "Epoch 16/100\n",
      "706/706 [==============================] - 13s 19ms/step - loss: 0.6001 - auc: 0.6739 - accuracy: 0.6945 - val_loss: 0.5608 - val_auc: 0.7217 - val_accuracy: 0.7694\n",
      "Epoch 17/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.5971 - auc: 0.6969 - accuracy: 0.7003 - val_loss: 0.5595 - val_auc: 0.7418 - val_accuracy: 0.7615\n",
      "Epoch 18/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.5932 - auc: 0.7167 - accuracy: 0.7071 - val_loss: 0.5443 - val_auc: 0.7774 - val_accuracy: 0.7908\n",
      "Epoch 19/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5904 - auc: 0.7283 - accuracy: 0.7107 - val_loss: 0.5509 - val_auc: 0.7768 - val_accuracy: 0.7744\n",
      "Epoch 20/100\n",
      "706/706 [==============================] - 14s 20ms/step - loss: 0.5875 - auc: 0.7352 - accuracy: 0.7122 - val_loss: 0.5366 - val_auc: 0.7939 - val_accuracy: 0.7881\n",
      "Epoch 21/100\n",
      "706/706 [==============================] - 13s 18ms/step - loss: 0.5870 - auc: 0.7385 - accuracy: 0.7142 - val_loss: 0.5234 - val_auc: 0.8117 - val_accuracy: 0.7969 0.7388 - ac - ETA: 4s - loss: 0.585 - ETA: 0s - loss: 0.5866 - auc: 0.7390 - accuracy: 0.\n",
      "Epoch 22/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5855 - auc: 0.7409 - accuracy: 0.7127 - val_loss: 0.5267 - val_auc: 0.8040 - val_accuracy: 0.7969\n",
      "Epoch 23/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5843 - auc: 0.7451 - accuracy: 0.7156 - val_loss: 0.5283 - val_auc: 0.8104 - val_accuracy: 0.7975\n",
      "Epoch 24/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5862 - auc: 0.7425 - accuracy: 0.7138 - val_loss: 0.5123 - val_auc: 0.8200 - val_accuracy: 0.7998TA: \n",
      "Epoch 25/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5835 - auc: 0.7462 - accuracy: 0.7161 - val_loss: 0.5180 - val_auc: 0.8158 - val_accuracy: 0.7990\n",
      "Epoch 26/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5820 - auc: 0.7478 - accuracy: 0.7177 - val_loss: 0.5103 - val_auc: 0.8220 - val_accuracy: 0.7987\n",
      "Epoch 27/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5821 - auc: 0.7489 - accuracy: 0.7163 - val_loss: 0.5156 - val_auc: 0.8201 - val_accuracy: 0.8008\n",
      "Epoch 28/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5828 - auc: 0.7473 - accuracy: 0.7164 - val_loss: 0.5168 - val_auc: 0.8186 - val_accuracy: 0.7973\n",
      "Epoch 29/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5810 - auc: 0.7488 - accuracy: 0.7160 - val_loss: 0.5214 - val_auc: 0.8117 - val_accuracy: 0.7975\n",
      "Epoch 30/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5802 - auc: 0.7500 - accuracy: 0.7171 - val_loss: 0.5132 - val_auc: 0.8194 - val_accuracy: 0.8023\n",
      "Epoch 31/100\n",
      "706/706 [==============================] - 12s 17ms/step - loss: 0.5784 - auc: 0.7524 - accuracy: 0.7176 - val_loss: 0.5112 - val_auc: 0.8215 - val_accuracy: 0.8002\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "plot_list = []\n",
    "model_list = []\n",
    "learning_rate = 0.00001\n",
    "\n",
    "for (j, sample) in enumerate(sampling_list):\n",
    "    \n",
    "    X_train_preprocessing = sample[0]\n",
    "    X_train_add_feature = sample[1]\n",
    "    y_train_preprocessing = sample[3]\n",
    "    \n",
    "    print(\"Train data shape: {} Val data shape: {}\".format(X_train_preprocessing.shape, X_val_preprocessing.shape))\n",
    "    print(\"Training the model with {}th sample\".format(j))\n",
    "    print(\"-----------------------------------------------\")\n",
    "    \n",
    "    model = RNN_Model(learning_rate)\n",
    "    epoch, hist = train_model(model, [X_train_preprocessing, X_train_add_feature], y_train_preprocessing, \n",
    "                              [X_val_preprocessing, X_val_add_feature], y_val_preprocessing, epochs = epochs, batch_size = 32)\n",
    "    \n",
    "    model_list.append(model)\n",
    "    plot_list.append([epoch, hist])\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the 0th model\n",
      "0th model's \u001b[35m Precision \u001b[30m: 60.03 \u001b[35m Recall \u001b[30m: 34.08 \u001b[35m F1-score \u001b[30m: 0.43 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n",
      "Predicting the 1th model\n",
      "1th model's \u001b[35m Precision \u001b[30m: 59.71 \u001b[35m Recall \u001b[30m: 30.72 \u001b[35m F1-score \u001b[30m: 0.41 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n",
      "Predicting the 2th model\n",
      "2th model's \u001b[35m Precision \u001b[30m: 60.07 \u001b[35m Recall \u001b[30m: 31.19 \u001b[35m F1-score \u001b[30m: 0.41 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n",
      "Predicting the 3th model\n",
      "3th model's \u001b[35m Precision \u001b[30m: 58.75 \u001b[35m Recall \u001b[30m: 34.17 \u001b[35m F1-score \u001b[30m: 0.43 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n",
      "Predicting the 4th model\n",
      "4th model's \u001b[35m Precision \u001b[30m: 60.99 \u001b[35m Recall \u001b[30m: 28.76 \u001b[35m F1-score \u001b[30m: 0.39 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n",
      "Predicting the 5th model\n",
      "5th model's \u001b[35m Precision \u001b[30m: 58.35 \u001b[35m Recall \u001b[30m: 34.27 \u001b[35m F1-score \u001b[30m: 0.43 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# f1-score\n",
    "for (i, sample) in enumerate(sampling_list):\n",
    "    \n",
    "    print(\"Predicting the {}th model\".format(i))\n",
    "    \n",
    "    model = model_list[i]\n",
    "    y_proba = model.predict([X_val_preprocessing, X_val_add_feature])\n",
    "    y_pred = np.argmax(y_proba, axis = 1)\n",
    "    \n",
    "    precision, recall, f1, accuracy = f1_score(y_val, y_pred)\n",
    "    print(\"{}th model's \\033[35m Precision \\033[30m: {:.2f} \\033[35m Recall \\033[30m: {:.2f} \\033[35m F1-score \\033[30m: {:.2f} \\033[35m Accuracy\\033[30m: {:.2f} \\n\".format(i, precision * 100, recall * 100, f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_list = np.array([.0] * (len(X_test) * 2)).reshape(-1, 2)\n",
    "\n",
    "for (i, model) in enumerate(model_list):\n",
    "    \n",
    "    y_proba = model.predict([X_test_preprocessing, X_test_add_feature])\n",
    "    proba_list += y_proba\n",
    "    \n",
    "y_pred = np.argmax((proba_list / len(model_list)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1, accuracy = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mPrecision\u001b[30m: 0.59, \u001b[35mRecall\u001b[30m: 0.32, \u001b[35mF1-Score\u001b[30m: 0.42, \u001b[35mAccuracy\u001b[30m: 0.81\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[35mPrecision\\033[30m: {:.2f}, \\033[35mRecall\\033[30m: {:.2f}, \\033[35mF1-Score\\033[30m: {:.2f}, \\033[35mAccuracy\\033[30m: {:.2f}\".format(precision, recall, f1, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## default의 비율이 0.5%가 되도록 뽑는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "sample_size = [0.5] * 6\n",
    "sampling_list_5 = []\n",
    "\n",
    "for (i, size) in enumerate(sample_size):\n",
    "    if size == 0:    \n",
    "        df = load_sampling(split_train, size, return_default = True)\n",
    "    else:\n",
    "        df = load_sampling(split_train, size)\n",
    "    \n",
    "    X_train_preprocessing, X_train_add_feature, y_train_before, y_train_preprocessing = preprocessing(df)\n",
    "    \n",
    "    sampling_list_5.append([X_train_preprocessing, X_train_add_feature, y_train_before, y_train_preprocessing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (24509, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 0th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.6623 - auc: 0.6402 - accuracy: 0.6104 - val_loss: 0.6042 - val_auc: 0.6632 - val_accuracy: 0.6929\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.6112 - auc: 0.6704 - accuracy: 0.6855 - val_loss: 0.5971 - val_auc: 0.6804 - val_accuracy: 0.7077\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.6010 - auc: 0.6922 - accuracy: 0.7020 - val_loss: 0.5708 - val_auc: 0.7303 - val_accuracy: 0.7496\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5928 - auc: 0.7143 - accuracy: 0.7128 - val_loss: 0.5506 - val_auc: 0.7656 - val_accuracy: 0.8017\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5879 - auc: 0.7277 - accuracy: 0.7208 - val_loss: 0.5410 - val_auc: 0.7866 - val_accuracy: 0.8075\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5820 - auc: 0.7399 - accuracy: 0.7267 - val_loss: 0.5363 - val_auc: 0.8022 - val_accuracy: 0.8081\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5785 - auc: 0.7495 - accuracy: 0.7274 - val_loss: 0.5233 - val_auc: 0.8142 - val_accuracy: 0.8092\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5736 - auc: 0.7549 - accuracy: 0.7293 - val_loss: 0.5201 - val_auc: 0.8170 - val_accuracy: 0.8083\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5729 - auc: 0.7565 - accuracy: 0.7273 - val_loss: 0.5153 - val_auc: 0.8187 - val_accuracy: 0.8073\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5704 - auc: 0.7575 - accuracy: 0.7294 - val_loss: 0.5087 - val_auc: 0.8229 - val_accuracy: 0.8081\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5712 - auc: 0.7567 - accuracy: 0.7281 - val_loss: 0.5127 - val_auc: 0.8189 - val_accuracy: 0.8037\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5672 - auc: 0.7614 - accuracy: 0.7307 - val_loss: 0.5041 - val_auc: 0.8234 - val_accuracy: 0.8067\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5672 - auc: 0.7610 - accuracy: 0.7306 - val_loss: 0.5173 - val_auc: 0.8153 - val_accuracy: 0.8002\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5658 - auc: 0.7627 - accuracy: 0.7314 - val_loss: 0.5069 - val_auc: 0.8204 - val_accuracy: 0.8025\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5666 - auc: 0.7615 - accuracy: 0.7313 - val_loss: 0.5035 - val_auc: 0.8235 - val_accuracy: 0.8031\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5653 - auc: 0.7626 - accuracy: 0.7316 - val_loss: 0.5100 - val_auc: 0.8171 - val_accuracy: 0.8012\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5665 - auc: 0.7605 - accuracy: 0.7314 - val_loss: 0.5153 - val_auc: 0.8148 - val_accuracy: 0.7992\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5639 - auc: 0.7633 - accuracy: 0.7318 - val_loss: 0.4928 - val_auc: 0.8271 - val_accuracy: 0.8056\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5642 - auc: 0.7626 - accuracy: 0.7322 - val_loss: 0.4929 - val_auc: 0.8266 - val_accuracy: 0.8027\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5632 - auc: 0.7630 - accuracy: 0.7324 - val_loss: 0.5007 - val_auc: 0.8228 - val_accuracy: 0.8040\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5633 - auc: 0.7628 - accuracy: 0.7326 - val_loss: 0.5097 - val_auc: 0.8151 - val_accuracy: 0.8015\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5625 - auc: 0.7629 - accuracy: 0.7324 - val_loss: 0.4978 - val_auc: 0.8235 - val_accuracy: 0.8035\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5620 - auc: 0.7630 - accuracy: 0.7325 - val_loss: 0.5118 - val_auc: 0.8125 - val_accuracy: 0.7981\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5622 - auc: 0.7635 - accuracy: 0.7350 - val_loss: 0.4931 - val_auc: 0.8220 - val_accuracy: 0.8040\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5619 - auc: 0.7631 - accuracy: 0.7340 - val_loss: 0.4902 - val_auc: 0.8281 - val_accuracy: 0.8046\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5614 - auc: 0.7641 - accuracy: 0.7334 - val_loss: 0.5131 - val_auc: 0.8074 - val_accuracy: 0.7952\n",
      "Epoch 27/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5597 - auc: 0.7653 - accuracy: 0.7351 - val_loss: 0.4987 - val_auc: 0.8207 - val_accuracy: 0.8006\n",
      "Epoch 28/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5599 - auc: 0.7641 - accuracy: 0.7340 - val_loss: 0.5055 - val_auc: 0.8172 - val_accuracy: 0.7990\n",
      "Epoch 29/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5609 - auc: 0.7633 - accuracy: 0.7339 - val_loss: 0.4975 - val_auc: 0.8197 - val_accuracy: 0.8002\n",
      "Epoch 30/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5595 - auc: 0.7633 - accuracy: 0.7332 - val_loss: 0.5057 - val_auc: 0.8144 - val_accuracy: 0.7990\n",
      "Epoch 31/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5598 - auc: 0.7641 - accuracy: 0.7337 - val_loss: 0.5014 - val_auc: 0.8166 - val_accuracy: 0.8004\n",
      "Epoch 32/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5595 - auc: 0.7638 - accuracy: 0.7341 - val_loss: 0.4894 - val_auc: 0.8247 - val_accuracy: 0.8035\n",
      "Epoch 33/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5596 - auc: 0.7620 - accuracy: 0.7351 - val_loss: 0.4922 - val_auc: 0.8227 - val_accuracy: 0.8008\n",
      "Epoch 34/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5585 - auc: 0.7636 - accuracy: 0.7333 - val_loss: 0.4972 - val_auc: 0.8171 - val_accuracy: 0.8002\n",
      "Epoch 35/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5589 - auc: 0.7619 - accuracy: 0.7336 - val_loss: 0.5081 - val_auc: 0.8125 - val_accuracy: 0.7979\n",
      "\n",
      "\n",
      "Train data shape: (24509, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 1th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.7477 - auc: 0.5899 - accuracy: 0.5668 - val_loss: 0.6047 - val_auc: 0.6735 - val_accuracy: 0.7133\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.6163 - auc: 0.6733 - accuracy: 0.6832 - val_loss: 0.5660 - val_auc: 0.7347 - val_accuracy: 0.7806\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.6021 - auc: 0.6930 - accuracy: 0.7065 - val_loss: 0.5692 - val_auc: 0.7310 - val_accuracy: 0.7560\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5925 - auc: 0.7120 - accuracy: 0.7128 - val_loss: 0.5580 - val_auc: 0.7608 - val_accuracy: 0.7904\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5867 - auc: 0.7316 - accuracy: 0.7196 - val_loss: 0.5421 - val_auc: 0.7969 - val_accuracy: 0.8054\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5800 - auc: 0.7464 - accuracy: 0.7243 - val_loss: 0.5400 - val_auc: 0.7961 - val_accuracy: 0.8054\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5755 - auc: 0.7515 - accuracy: 0.7248 - val_loss: 0.5283 - val_auc: 0.8037 - val_accuracy: 0.8079\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5729 - auc: 0.7535 - accuracy: 0.7254 - val_loss: 0.5271 - val_auc: 0.8132 - val_accuracy: 0.8081\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5706 - auc: 0.7582 - accuracy: 0.7275 - val_loss: 0.5285 - val_auc: 0.8119 - val_accuracy: 0.8071\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5702 - auc: 0.7582 - accuracy: 0.7275 - val_loss: 0.5197 - val_auc: 0.8160 - val_accuracy: 0.8067\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5683 - auc: 0.7602 - accuracy: 0.7282 - val_loss: 0.5275 - val_auc: 0.8073 - val_accuracy: 0.8042\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5679 - auc: 0.7603 - accuracy: 0.7263 - val_loss: 0.5169 - val_auc: 0.8175 - val_accuracy: 0.8060\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5678 - auc: 0.7601 - accuracy: 0.7270 - val_loss: 0.5086 - val_auc: 0.8229 - val_accuracy: 0.8077\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5666 - auc: 0.7617 - accuracy: 0.7287 - val_loss: 0.5371 - val_auc: 0.7993 - val_accuracy: 0.7962\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5645 - auc: 0.7635 - accuracy: 0.7290 - val_loss: 0.5185 - val_auc: 0.8132 - val_accuracy: 0.8031\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5642 - auc: 0.7632 - accuracy: 0.7308 - val_loss: 0.5244 - val_auc: 0.8100 - val_accuracy: 0.8023\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5637 - auc: 0.7640 - accuracy: 0.7302 - val_loss: 0.5175 - val_auc: 0.8148 - val_accuracy: 0.8029\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5636 - auc: 0.7640 - accuracy: 0.7300 - val_loss: 0.5184 - val_auc: 0.8136 - val_accuracy: 0.8017\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5642 - auc: 0.7630 - accuracy: 0.7286 - val_loss: 0.5157 - val_auc: 0.8150 - val_accuracy: 0.8004\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5623 - auc: 0.7653 - accuracy: 0.7300 - val_loss: 0.5160 - val_auc: 0.8122 - val_accuracy: 0.8004\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5634 - auc: 0.7641 - accuracy: 0.7321 - val_loss: 0.5303 - val_auc: 0.8015 - val_accuracy: 0.7917\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5610 - auc: 0.7676 - accuracy: 0.7302 - val_loss: 0.5126 - val_auc: 0.8153 - val_accuracy: 0.8015\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5618 - auc: 0.7657 - accuracy: 0.7320 - val_loss: 0.5118 - val_auc: 0.8153 - val_accuracy: 0.8000\n",
      "\n",
      "\n",
      "Train data shape: (24509, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 2th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6636 - auc: 0.6296 - accuracy: 0.6016 - val_loss: 0.6498 - val_auc: 0.6018 - val_accuracy: 0.6110\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.6150 - auc: 0.6684 - accuracy: 0.6830 - val_loss: 0.5889 - val_auc: 0.7025 - val_accuracy: 0.7229\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5964 - auc: 0.7044 - accuracy: 0.7070 - val_loss: 0.5702 - val_auc: 0.7518 - val_accuracy: 0.7606\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5856 - auc: 0.7344 - accuracy: 0.7179 - val_loss: 0.5527 - val_auc: 0.7731 - val_accuracy: 0.7721\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5793 - auc: 0.7447 - accuracy: 0.7243 - val_loss: 0.5365 - val_auc: 0.7984 - val_accuracy: 0.7858\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5726 - auc: 0.7536 - accuracy: 0.7271 - val_loss: 0.5266 - val_auc: 0.8038 - val_accuracy: 0.7921\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5708 - auc: 0.7569 - accuracy: 0.7299 - val_loss: 0.5122 - val_auc: 0.8133 - val_accuracy: 0.7994\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5669 - auc: 0.7623 - accuracy: 0.7319 - val_loss: 0.5053 - val_auc: 0.8165 - val_accuracy: 0.7996\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5663 - auc: 0.7626 - accuracy: 0.7313 - val_loss: 0.5084 - val_auc: 0.8122 - val_accuracy: 0.7973\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5658 - auc: 0.7624 - accuracy: 0.7316 - val_loss: 0.4990 - val_auc: 0.8203 - val_accuracy: 0.7998\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5635 - auc: 0.7657 - accuracy: 0.7333 - val_loss: 0.4929 - val_auc: 0.8242 - val_accuracy: 0.8008\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5632 - auc: 0.7658 - accuracy: 0.7324 - val_loss: 0.4999 - val_auc: 0.8180 - val_accuracy: 0.7998\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5634 - auc: 0.7658 - accuracy: 0.7345 - val_loss: 0.5059 - val_auc: 0.8144 - val_accuracy: 0.7969\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5622 - auc: 0.7659 - accuracy: 0.7345 - val_loss: 0.4910 - val_auc: 0.8219 - val_accuracy: 0.8004\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5596 - auc: 0.7686 - accuracy: 0.7339 - val_loss: 0.5066 - val_auc: 0.8131 - val_accuracy: 0.7954\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5621 - auc: 0.7657 - accuracy: 0.7339 - val_loss: 0.5074 - val_auc: 0.8134 - val_accuracy: 0.7954\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5613 - auc: 0.7674 - accuracy: 0.7347 - val_loss: 0.5000 - val_auc: 0.8176 - val_accuracy: 0.7965\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5604 - auc: 0.7673 - accuracy: 0.7343 - val_loss: 0.4931 - val_auc: 0.8224 - val_accuracy: 0.7987\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5600 - auc: 0.7673 - accuracy: 0.7347 - val_loss: 0.4944 - val_auc: 0.8192 - val_accuracy: 0.7987\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5599 - auc: 0.7668 - accuracy: 0.7350 - val_loss: 0.5135 - val_auc: 0.8075 - val_accuracy: 0.7906\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5595 - auc: 0.7681 - accuracy: 0.7353 - val_loss: 0.4969 - val_auc: 0.8179 - val_accuracy: 0.7990\n",
      "\n",
      "\n",
      "Train data shape: (24509, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 3th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 15s 19ms/step - loss: 0.6725 - auc: 0.5972 - accuracy: 0.5878 - val_loss: 0.5878 - val_auc: 0.6322 - val_accuracy: 0.7285\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.6262 - auc: 0.6195 - accuracy: 0.6655 - val_loss: 0.5750 - val_auc: 0.6693 - val_accuracy: 0.7398\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6121 - auc: 0.6505 - accuracy: 0.6861 - val_loss: 0.5703 - val_auc: 0.6968 - val_accuracy: 0.7456ss: 0.6089 - auc: 0.\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 15s 19ms/step - loss: 0.6044 - auc: 0.6740 - accuracy: 0.6964 - val_loss: 0.5417 - val_auc: 0.7425 - val_accuracy: 0.7715\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.5989 - auc: 0.6894 - accuracy: 0.7011 - val_loss: 0.5464 - val_auc: 0.7439 - val_accuracy: 0.7796\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 16s 21ms/step - loss: 0.5934 - auc: 0.7024 - accuracy: 0.7097 - val_loss: 0.5483 - val_auc: 0.7524 - val_accuracy: 0.7771\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 15s 19ms/step - loss: 0.5895 - auc: 0.7116 - accuracy: 0.7111 - val_loss: 0.5323 - val_auc: 0.7746 - val_accuracy: 0.7919\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 13s 16ms/step - loss: 0.5890 - auc: 0.7166 - accuracy: 0.7126 - val_loss: 0.5212 - val_auc: 0.7879 - val_accuracy: 0.8004\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5849 - auc: 0.7250 - accuracy: 0.7163 - val_loss: 0.5244 - val_auc: 0.7905 - val_accuracy: 0.8023\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 16s 21ms/step - loss: 0.5834 - auc: 0.7301 - accuracy: 0.7174 - val_loss: 0.5105 - val_auc: 0.8047 - val_accuracy: 0.8048\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5800 - auc: 0.7367 - accuracy: 0.7211 - val_loss: 0.5142 - val_auc: 0.8058 - val_accuracy: 0.8071\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5799 - auc: 0.7408 - accuracy: 0.7193 - val_loss: 0.5030 - val_auc: 0.8194 - val_accuracy: 0.8098\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5783 - auc: 0.7436 - accuracy: 0.7220 - val_loss: 0.5115 - val_auc: 0.8124 - val_accuracy: 0.8079\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5769 - auc: 0.7445 - accuracy: 0.7227 - val_loss: 0.4980 - val_auc: 0.8222 - val_accuracy: 0.8106\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 11s 15ms/step - loss: 0.5753 - auc: 0.7459 - accuracy: 0.7216 - val_loss: 0.5056 - val_auc: 0.8143 - val_accuracy: 0.8081\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5752 - auc: 0.7468 - accuracy: 0.7235 - val_loss: 0.4971 - val_auc: 0.8217 - val_accuracy: 0.8096\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5752 - auc: 0.7466 - accuracy: 0.7225 - val_loss: 0.4938 - val_auc: 0.8257 - val_accuracy: 0.8110\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5743 - auc: 0.7477 - accuracy: 0.7223 - val_loss: 0.4979 - val_auc: 0.8209 - val_accuracy: 0.8098\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 13s 16ms/step - loss: 0.5735 - auc: 0.7475 - accuracy: 0.7223 - val_loss: 0.4966 - val_auc: 0.8206 - val_accuracy: 0.8110: 1s\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5737 - auc: 0.7468 - accuracy: 0.7223 - val_loss: 0.4973 - val_auc: 0.8222 - val_accuracy: 0.8112\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5720 - auc: 0.7495 - accuracy: 0.7244 - val_loss: 0.4973 - val_auc: 0.8209 - val_accuracy: 0.8112\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5707 - auc: 0.7494 - accuracy: 0.7232 - val_loss: 0.4965 - val_auc: 0.8209 - val_accuracy: 0.8108\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5697 - auc: 0.7513 - accuracy: 0.7240 - val_loss: 0.4942 - val_auc: 0.8226 - val_accuracy: 0.8104\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5710 - auc: 0.7495 - accuracy: 0.7238 - val_loss: 0.4904 - val_auc: 0.8241 - val_accuracy: 0.8121\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5701 - auc: 0.7499 - accuracy: 0.7236 - val_loss: 0.4980 - val_auc: 0.8197 - val_accuracy: 0.8112\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5709 - auc: 0.7499 - accuracy: 0.7244 - val_loss: 0.4844 - val_auc: 0.8271 - val_accuracy: 0.8106\n",
      "Epoch 27/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5703 - auc: 0.7494 - accuracy: 0.7232 - val_loss: 0.4906 - val_auc: 0.8234 - val_accuracy: 0.8106\n",
      "Epoch 28/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5683 - auc: 0.7516 - accuracy: 0.7249 - val_loss: 0.4889 - val_auc: 0.8226 - val_accuracy: 0.8108\n",
      "Epoch 29/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5684 - auc: 0.7517 - accuracy: 0.7238 - val_loss: 0.4894 - val_auc: 0.8224 - val_accuracy: 0.8115\n",
      "Epoch 30/100\n",
      "766/766 [==============================] - 12s 15ms/step - loss: 0.5680 - auc: 0.7523 - accuracy: 0.7240 - val_loss: 0.4958 - val_auc: 0.8213 - val_accuracy: 0.8125\n",
      "Epoch 31/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5686 - auc: 0.7507 - accuracy: 0.7241 - val_loss: 0.4896 - val_auc: 0.8230 - val_accuracy: 0.8106\n",
      "Epoch 32/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5687 - auc: 0.7508 - accuracy: 0.7247 - val_loss: 0.4936 - val_auc: 0.8212 - val_accuracy: 0.8108\n",
      "Epoch 33/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5674 - auc: 0.7516 - accuracy: 0.7247 - val_loss: 0.4970 - val_auc: 0.8176 - val_accuracy: 0.8100\n",
      "Epoch 34/100\n",
      "766/766 [==============================] - 12s 16ms/step - loss: 0.5664 - auc: 0.7522 - accuracy: 0.7254 - val_loss: 0.4912 - val_auc: 0.8217 - val_accuracy: 0.8119\n",
      "Epoch 35/100\n",
      "766/766 [==============================] - 13s 16ms/step - loss: 0.5668 - auc: 0.7518 - accuracy: 0.7260 - val_loss: 0.4906 - val_auc: 0.8210 - val_accuracy: 0.8104\n",
      "Epoch 36/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5663 - auc: 0.7513 - accuracy: 0.7244 - val_loss: 0.4903 - val_auc: 0.8203 - val_accuracy: 0.8110\n",
      "\n",
      "\n",
      "Train data shape: (24509, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 4th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 15s 20ms/step - loss: 0.6689 - auc: 0.6007 - accuracy: 0.5819 - val_loss: 0.6362 - val_auc: 0.5689 - val_accuracy: 0.6052\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 15s 20ms/step - loss: 0.6462 - auc: 0.5836 - accuracy: 0.6367 - val_loss: 0.5959 - val_auc: 0.6326 - val_accuracy: 0.7056\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.6323 - auc: 0.6140 - accuracy: 0.6569 - val_loss: 0.5998 - val_auc: 0.6494 - val_accuracy: 0.7031\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.6229 - auc: 0.6400 - accuracy: 0.6735 - val_loss: 0.5917 - val_auc: 0.6754 - val_accuracy: 0.7160\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6166 - auc: 0.6574 - accuracy: 0.6803 - val_loss: 0.5693 - val_auc: 0.7095 - val_accuracy: 0.7604\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.6105 - auc: 0.6717 - accuracy: 0.6883 - val_loss: 0.5549 - val_auc: 0.7480 - val_accuracy: 0.7742\n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6052 - auc: 0.6874 - accuracy: 0.6963 - val_loss: 0.5553 - val_auc: 0.7580 - val_accuracy: 0.7817\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 13s 18ms/step - loss: 0.6015 - auc: 0.6992 - accuracy: 0.7019 - val_loss: 0.5547 - val_auc: 0.7653 - val_accuracy: 0.7873\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 13s 18ms/step - loss: 0.5966 - auc: 0.7121 - accuracy: 0.7078 - val_loss: 0.5308 - val_auc: 0.7919 - val_accuracy: 0.7933\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5952 - auc: 0.7175 - accuracy: 0.7092 - val_loss: 0.5482 - val_auc: 0.7785 - val_accuracy: 0.7896\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5915 - auc: 0.7246 - accuracy: 0.7119 - val_loss: 0.5397 - val_auc: 0.7911 - val_accuracy: 0.7952\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 13s 18ms/step - loss: 0.5900 - auc: 0.7280 - accuracy: 0.7146 - val_loss: 0.5529 - val_auc: 0.7858 - val_accuracy: 0.7887\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5866 - auc: 0.7330 - accuracy: 0.7168 - val_loss: 0.5174 - val_auc: 0.8097 - val_accuracy: 0.8025\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 15s 19ms/step - loss: 0.5865 - auc: 0.7356 - accuracy: 0.7174 - val_loss: 0.5457 - val_auc: 0.7933 - val_accuracy: 0.7981\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 16s 22ms/step - loss: 0.5838 - auc: 0.7404 - accuracy: 0.7201 - val_loss: 0.5337 - val_auc: 0.8027 - val_accuracy: 0.8019 loss: 0.5862 - auc: 0.7377 - accuracy - ETA: 6s - l\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 15s 20ms/step - loss: 0.5825 - auc: 0.7426 - accuracy: 0.7208 - val_loss: 0.5303 - val_auc: 0.8074 - val_accuracy: 0.8040\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.5785 - auc: 0.7483 - accuracy: 0.7226 - val_loss: 0.5361 - val_auc: 0.8040 - val_accuracy: 0.8044\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5792 - auc: 0.7490 - accuracy: 0.7225 - val_loss: 0.5141 - val_auc: 0.8186 - val_accuracy: 0.8073racy: 0.72\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5773 - auc: 0.7496 - accuracy: 0.7218 - val_loss: 0.5129 - val_auc: 0.8199 - val_accuracy: 0.8071\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5767 - auc: 0.7500 - accuracy: 0.7243 - val_loss: 0.5271 - val_auc: 0.8081 - val_accuracy: 0.8015\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5769 - auc: 0.7505 - accuracy: 0.7230 - val_loss: 0.5446 - val_auc: 0.7975 - val_accuracy: 0.7856\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5762 - auc: 0.7513 - accuracy: 0.7222 - val_loss: 0.5126 - val_auc: 0.8208 - val_accuracy: 0.8046\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5728 - auc: 0.7541 - accuracy: 0.7247 - val_loss: 0.5127 - val_auc: 0.8187 - val_accuracy: 0.8002\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5737 - auc: 0.7534 - accuracy: 0.7241 - val_loss: 0.5179 - val_auc: 0.8171 - val_accuracy: 0.7981\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5728 - auc: 0.7548 - accuracy: 0.7254 - val_loss: 0.5178 - val_auc: 0.8172 - val_accuracy: 0.7973\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.5725 - auc: 0.7544 - accuracy: 0.7251 - val_loss: 0.5212 - val_auc: 0.8119 - val_accuracy: 0.7937\n",
      "Epoch 27/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5729 - auc: 0.7533 - accuracy: 0.7250 - val_loss: 0.5184 - val_auc: 0.8167 - val_accuracy: 0.7940\n",
      "Epoch 28/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5716 - auc: 0.7549 - accuracy: 0.7242 - val_loss: 0.5249 - val_auc: 0.8091 - val_accuracy: 0.7894\n",
      "Epoch 29/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5713 - auc: 0.7551 - accuracy: 0.7262 - val_loss: 0.5189 - val_auc: 0.8115 - val_accuracy: 0.7931\n",
      "Epoch 30/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5704 - auc: 0.7552 - accuracy: 0.7247 - val_loss: 0.5169 - val_auc: 0.8155 - val_accuracy: 0.7935\n",
      "Epoch 31/100\n",
      "766/766 [==============================] - 13s 18ms/step - loss: 0.5725 - auc: 0.7533 - accuracy: 0.7242 - val_loss: 0.5245 - val_auc: 0.8092 - val_accuracy: 0.7921\n",
      "Epoch 32/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5700 - auc: 0.7567 - accuracy: 0.7244 - val_loss: 0.5337 - val_auc: 0.8007 - val_accuracy: 0.7840\n",
      "\n",
      "\n",
      "Train data shape: (24509, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 5th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "766/766 [==============================] - 15s 20ms/step - loss: 0.6963 - auc: 0.5895 - accuracy: 0.5483 - val_loss: 0.6497 - val_auc: 0.5709 - val_accuracy: 0.6077\n",
      "Epoch 2/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6415 - auc: 0.6000 - accuracy: 0.6349 - val_loss: 0.6387 - val_auc: 0.6078 - val_accuracy: 0.6379\n",
      "Epoch 3/100\n",
      "766/766 [==============================] - 15s 19ms/step - loss: 0.6234 - auc: 0.6347 - accuracy: 0.6711 - val_loss: 0.6062 - val_auc: 0.6633 - val_accuracy: 0.7085\n",
      "Epoch 4/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.6104 - auc: 0.6562 - accuracy: 0.6865 - val_loss: 0.5937 - val_auc: 0.6767 - val_accuracy: 0.7217\n",
      "Epoch 5/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.6004 - auc: 0.6780 - accuracy: 0.6989 - val_loss: 0.5858 - val_auc: 0.7024 - val_accuracy: 0.7400\n",
      "Epoch 6/100\n",
      "766/766 [==============================] - 15s 19ms/step - loss: 0.5925 - auc: 0.6940 - accuracy: 0.7061 - val_loss: 0.5574 - val_auc: 0.7531 - val_accuracy: 0.7646cy: 0.70 - ETA: 0s - loss: 0.5928 - auc: 0.6933 \n",
      "Epoch 7/100\n",
      "766/766 [==============================] - 16s 21ms/step - loss: 0.5877 - auc: 0.7148 - accuracy: 0.7149 - val_loss: 0.5670 - val_auc: 0.7465 - val_accuracy: 0.7604\n",
      "Epoch 8/100\n",
      "766/766 [==============================] - 15s 19ms/step - loss: 0.5823 - auc: 0.7240 - accuracy: 0.7198 - val_loss: 0.5638 - val_auc: 0.7592 - val_accuracy: 0.7569\n",
      "Epoch 9/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5782 - auc: 0.7364 - accuracy: 0.7227 - val_loss: 0.5502 - val_auc: 0.7691 - val_accuracy: 0.7698\n",
      "Epoch 10/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5752 - auc: 0.7411 - accuracy: 0.7264 - val_loss: 0.5363 - val_auc: 0.7859 - val_accuracy: 0.7829\n",
      "Epoch 11/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5739 - auc: 0.7435 - accuracy: 0.7261 - val_loss: 0.5300 - val_auc: 0.7938 - val_accuracy: 0.7879 0.574 - ETA: 0s - los\n",
      "Epoch 12/100\n",
      "766/766 [==============================] - 16s 20ms/step - loss: 0.5724 - auc: 0.7449 - accuracy: 0.7281 - val_loss: 0.5389 - val_auc: 0.7894 - val_accuracy: 0.7800\n",
      "Epoch 13/100\n",
      "766/766 [==============================] - 15s 19ms/step - loss: 0.5698 - auc: 0.7504 - accuracy: 0.7288 - val_loss: 0.5254 - val_auc: 0.7978 - val_accuracy: 0.7848\n",
      "Epoch 14/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5696 - auc: 0.7498 - accuracy: 0.7271 - val_loss: 0.5226 - val_auc: 0.8027 - val_accuracy: 0.7865\n",
      "Epoch 15/100\n",
      "766/766 [==============================] - 15s 20ms/step - loss: 0.5668 - auc: 0.7541 - accuracy: 0.7297 - val_loss: 0.5194 - val_auc: 0.8052 - val_accuracy: 0.7906\n",
      "Epoch 16/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5676 - auc: 0.7531 - accuracy: 0.7298 - val_loss: 0.5219 - val_auc: 0.8036 - val_accuracy: 0.7873\n",
      "Epoch 17/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5671 - auc: 0.7541 - accuracy: 0.7294 - val_loss: 0.5133 - val_auc: 0.8095 - val_accuracy: 0.7904\n",
      "Epoch 18/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.5655 - auc: 0.7545 - accuracy: 0.7292 - val_loss: 0.5100 - val_auc: 0.8122 - val_accuracy: 0.7942\n",
      "Epoch 19/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5658 - auc: 0.7557 - accuracy: 0.7312 - val_loss: 0.5056 - val_auc: 0.8159 - val_accuracy: 0.7944\n",
      "Epoch 20/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5665 - auc: 0.7555 - accuracy: 0.7300 - val_loss: 0.5137 - val_auc: 0.8091 - val_accuracy: 0.7894oss: 0.5693  - ETA: 1s - loss: 0.5679 - auc: - ETA: 1s\n",
      "Epoch 21/100\n",
      "766/766 [==============================] - 13s 17ms/step - loss: 0.5642 - auc: 0.7582 - accuracy: 0.7313 - val_loss: 0.5120 - val_auc: 0.8093 - val_accuracy: 0.7896\n",
      "Epoch 22/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5633 - auc: 0.7568 - accuracy: 0.7323 - val_loss: 0.4999 - val_auc: 0.8167 - val_accuracy: 0.7954\n",
      "Epoch 23/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5647 - auc: 0.7555 - accuracy: 0.7305 - val_loss: 0.4997 - val_auc: 0.8173 - val_accuracy: 0.7937\n",
      "Epoch 24/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.5638 - auc: 0.7571 - accuracy: 0.7318 - val_loss: 0.5124 - val_auc: 0.8103 - val_accuracy: 0.7894\n",
      "Epoch 25/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5640 - auc: 0.7574 - accuracy: 0.7325 - val_loss: 0.4973 - val_auc: 0.8219 - val_accuracy: 0.7948\n",
      "Epoch 26/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.5615 - auc: 0.7594 - accuracy: 0.7312 - val_loss: 0.5022 - val_auc: 0.8158 - val_accuracy: 0.7935\n",
      "Epoch 27/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5620 - auc: 0.7587 - accuracy: 0.7320 - val_loss: 0.5054 - val_auc: 0.8148 - val_accuracy: 0.7927\n",
      "Epoch 28/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5615 - auc: 0.7588 - accuracy: 0.7319 - val_loss: 0.5112 - val_auc: 0.8101 - val_accuracy: 0.7915\n",
      "Epoch 29/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5606 - auc: 0.7595 - accuracy: 0.7340 - val_loss: 0.5082 - val_auc: 0.8134 - val_accuracy: 0.7904\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5607 - auc: 0.7608 - accuracy: 0.7334 - val_loss: 0.5050 - val_auc: 0.8145 - val_accuracy: 0.7910s: 0.5576  -\n",
      "Epoch 31/100\n",
      "766/766 [==============================] - 15s 19ms/step - loss: 0.5592 - auc: 0.7601 - accuracy: 0.7352 - val_loss: 0.5025 - val_auc: 0.8154 - val_accuracy: 0.7927\n",
      "Epoch 32/100\n",
      "766/766 [==============================] - 15s 19ms/step - loss: 0.5604 - auc: 0.7600 - accuracy: 0.7344 - val_loss: 0.5031 - val_auc: 0.8135 - val_accuracy: 0.7925\n",
      "Epoch 33/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5596 - auc: 0.7605 - accuracy: 0.7357 - val_loss: 0.5031 - val_auc: 0.8159 - val_accuracy: 0.7925\n",
      "Epoch 34/100\n",
      "766/766 [==============================] - 14s 18ms/step - loss: 0.5581 - auc: 0.7613 - accuracy: 0.7343 - val_loss: 0.5145 - val_auc: 0.8066 - val_accuracy: 0.7896\n",
      "Epoch 35/100\n",
      "766/766 [==============================] - 14s 19ms/step - loss: 0.5588 - auc: 0.7608 - accuracy: 0.7332 - val_loss: 0.5056 - val_auc: 0.8120 - val_accuracy: 0.7904\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 각각의 모델로 각각의 표본 학습 \n",
    "\n",
    "epochs = 100\n",
    "plot_list = []\n",
    "model_list = []\n",
    "learning_rate = 0.00001\n",
    "list_index = 0\n",
    "\n",
    "for (j, sample) in enumerate(sampling_list_5):\n",
    "    \n",
    "    X_train_preprocessing = sample[0]\n",
    "    X_train_add_feature = sample[1]\n",
    "    y_train_preprocessing = sample[3]\n",
    "    \n",
    "    length = len(X_train_preprocessing)\n",
    "    \n",
    "    print(\"Train data shape: {} Val data shape: {}\".format(X_train_preprocessing.shape, X_val_preprocessing.shape))\n",
    "    print(\"Training the model with {}th sample\".format(j))\n",
    "    print(\"-----------------------------------------------\")\n",
    "    \n",
    "    model = RNN_Model(learning_rate)\n",
    "    epoch, hist = train_model(model, [X_train_preprocessing, X_train_add_feature], y_train_preprocessing, \n",
    "                              [X_val_preprocessing, X_val_add_feature], y_val_preprocessing, epochs = epochs, batch_size = 32, patience = 10)\n",
    "    model_list.append(model)\n",
    "    plot_list.append([epoch, hist])\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the 0th model\n",
      "0th model's \u001b[35m Precision \u001b[30m: 57.85 \u001b[35m Recall \u001b[30m: 45.75 \u001b[35m F1-score \u001b[30m: 0.51 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n",
      "Predicting the 1th model\n",
      "1th model's \u001b[35m Precision \u001b[30m: 59.30 \u001b[35m Recall \u001b[30m: 44.07 \u001b[35m F1-score \u001b[30m: 0.51 \u001b[35m Accuracy\u001b[30m: 0.81 \n",
      "\n",
      "Predicting the 2th model\n",
      "2th model's \u001b[35m Precision \u001b[30m: 56.51 \u001b[35m Recall \u001b[30m: 46.59 \u001b[35m F1-score \u001b[30m: 0.51 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n",
      "Predicting the 3th model\n",
      "3th model's \u001b[35m Precision \u001b[30m: 61.19 \u001b[35m Recall \u001b[30m: 41.36 \u001b[35m F1-score \u001b[30m: 0.49 \u001b[35m Accuracy\u001b[30m: 0.81 \n",
      "\n",
      "Predicting the 4th model\n",
      "4th model's \u001b[35m Precision \u001b[30m: 58.14 \u001b[35m Recall \u001b[30m: 44.35 \u001b[35m F1-score \u001b[30m: 0.50 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n",
      "Predicting the 5th model\n",
      "5th model's \u001b[35m Precision \u001b[30m: 54.47 \u001b[35m Recall \u001b[30m: 48.93 \u001b[35m F1-score \u001b[30m: 0.52 \u001b[35m Accuracy\u001b[30m: 0.79 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# f1-score\n",
    "for (i, sample) in enumerate(sampling_list_5):\n",
    "    \n",
    "    print(\"Predicting the {}th model\".format(i))\n",
    "    \n",
    "    model = model_list[i]\n",
    "    y_proba = model.predict([X_val_preprocessing, X_val_add_feature])\n",
    "    y_pred = np.argmax(y_proba, axis = 1)\n",
    "    \n",
    "    precision, recall, f1, accuracy = f1_score(y_val, y_pred)\n",
    "    print(\"{}th model's \\033[35m Precision \\033[30m: {:.2f} \\033[35m Recall \\033[30m: {:.2f} \\033[35m F1-score \\033[30m: {:.2f} \\033[35m Accuracy\\033[30m: {:.2f} \\n\".format(i, precision * 100, recall * 100, f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_list = np.array([.0] * (len(X_test) * 2)).reshape(-1, 2)\n",
    "\n",
    "for (i, model) in enumerate(model_list):\n",
    "    \n",
    "    y_proba = model.predict([X_test_preprocessing, X_test_add_feature])\n",
    "    proba_list += y_proba\n",
    "    \n",
    "y_pred = np.argmax((proba_list / len(model_list)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mPrecision\u001b[30m: 0.60, \u001b[35mRecall\u001b[30m: 0.49, \u001b[35mF1-Score\u001b[30m: 0.54, \u001b[35mAccuracy\u001b[30m: 0.82\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, accuracy = f1_score(y_test, y_pred)\n",
    "print(\"\\033[35mPrecision\\033[30m: {:.2f}, \\033[35mRecall\\033[30m: {:.2f}, \\033[35mF1-Score\\033[30m: {:.2f}, \\033[35mAccuracy\\033[30m: {:.2f}\".format(precision, recall, f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## default가 succeed와 같은 수가 되도록 뽑는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "sample_size = [\"same\"] * 10\n",
    "sampling_list_half = []\n",
    "\n",
    "for (i, size) in enumerate(sample_size):\n",
    "    if size == 0:    \n",
    "        df = load_sampling(split_train, size, return_default = True)\n",
    "    else:\n",
    "        df = load_sampling(split_train, 0, size)\n",
    "    \n",
    "    X_train_preprocessing, X_train_add_feature, y_train_before, y_train_preprocessing = preprocessing(df)\n",
    "    \n",
    "    sampling_list_half.append([X_train_preprocessing, X_train_add_feature, y_train_before, y_train_preprocessing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 0th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.6520 - auc: 0.6305 - accuracy: 0.6054 - val_loss: 0.6292 - val_auc: 0.6532 - val_accuracy: 0.7017s: 0.6524 - auc: 0.6303 - accu\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.6237 - auc: 0.6517 - accuracy: 0.6491 - val_loss: 0.6200 - val_auc: 0.7042 - val_accuracy: 0.7485\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 17s 19ms/step - loss: 0.6180 - auc: 0.6591 - accuracy: 0.6579 - val_loss: 0.6317 - val_auc: 0.6951 - val_accuracy: 0.7069\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 16s 18ms/step - loss: 0.6157 - auc: 0.6640 - accuracy: 0.6638 - val_loss: 0.6114 - val_auc: 0.7261 - val_accuracy: 0.7502\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6122 - auc: 0.6708 - accuracy: 0.6677 - val_loss: 0.6256 - val_auc: 0.7128 - val_accuracy: 0.7373\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.6125 - auc: 0.6677 - accuracy: 0.6685 - val_loss: 0.6280 - val_auc: 0.7162 - val_accuracy: 0.7290\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.6101 - auc: 0.6691 - accuracy: 0.6689 - val_loss: 0.6241 - val_auc: 0.7081 - val_accuracy: 0.7429\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 17s 19ms/step - loss: 0.6088 - auc: 0.6702 - accuracy: 0.6686 - val_loss: 0.6078 - val_auc: 0.7373 - val_accuracy: 0.7640\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.6067 - auc: 0.6721 - accuracy: 0.6709 - val_loss: 0.5929 - val_auc: 0.7528 - val_accuracy: 0.7844\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.6059 - auc: 0.6743 - accuracy: 0.6731 - val_loss: 0.6110 - val_auc: 0.7288 - val_accuracy: 0.7606\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.6046 - auc: 0.6760 - accuracy: 0.6742 - val_loss: 0.6075 - val_auc: 0.7332 - val_accuracy: 0.7588\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6035 - auc: 0.6769 - accuracy: 0.6745 - val_loss: 0.6003 - val_auc: 0.7401 - val_accuracy: 0.7571\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6017 - auc: 0.6775 - accuracy: 0.6766 - val_loss: 0.6205 - val_auc: 0.7114 - val_accuracy: 0.7267\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6021 - auc: 0.6765 - accuracy: 0.6744 - val_loss: 0.6077 - val_auc: 0.7279 - val_accuracy: 0.7485\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6006 - auc: 0.6798 - accuracy: 0.6764 - val_loss: 0.5944 - val_auc: 0.7424 - val_accuracy: 0.7679 loss: 0.6005 - auc: 0.6802 - \n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6002 - auc: 0.6799 - accuracy: 0.6768 - val_loss: 0.6068 - val_auc: 0.7283 - val_accuracy: 0.7446\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5987 - auc: 0.6787 - accuracy: 0.6778 - val_loss: 0.6064 - val_auc: 0.7209 - val_accuracy: 0.7588\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5969 - auc: 0.6811 - accuracy: 0.6803 - val_loss: 0.6079 - val_auc: 0.7212 - val_accuracy: 0.7535\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5981 - auc: 0.6825 - accuracy: 0.6784 - val_loss: 0.5809 - val_auc: 0.7597 - val_accuracy: 0.7752\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5962 - auc: 0.6872 - accuracy: 0.6807 - val_loss: 0.5998 - val_auc: 0.7250 - val_accuracy: 0.7565\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5963 - auc: 0.6854 - accuracy: 0.6769 - val_loss: 0.6073 - val_auc: 0.7306 - val_accuracy: 0.7496\n",
      "Epoch 22/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5951 - auc: 0.6853 - accuracy: 0.6792 - val_loss: 0.5912 - val_auc: 0.7475 - val_accuracy: 0.7658\n",
      "Epoch 23/100\n",
      "932/932 [==============================] - 16s 18ms/step - loss: 0.5953 - auc: 0.6856 - accuracy: 0.6807 - val_loss: 0.5934 - val_auc: 0.7364 - val_accuracy: 0.7471\n",
      "Epoch 24/100\n",
      "932/932 [==============================] - 16s 18ms/step - loss: 0.5948 - auc: 0.6885 - accuracy: 0.6831 - val_loss: 0.5960 - val_auc: 0.7372 - val_accuracy: 0.7529\n",
      "Epoch 25/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5932 - auc: 0.6892 - accuracy: 0.6811 - val_loss: 0.5962 - val_auc: 0.7361 - val_accuracy: 0.7429cy - ETA: 8s - loss: 0.5951 - auc: 0 - ETA: 0s - loss: 0.5945 - auc: 0.6878 - accura - ETA: 0s - loss: 0.5941 - auc: 0\n",
      "Epoch 26/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5921 - auc: 0.6903 - accuracy: 0.6841 - val_loss: 0.5968 - val_auc: 0.7376 - val_accuracy: 0.7483\n",
      "Epoch 27/100\n",
      "932/932 [==============================] - 17s 19ms/step - loss: 0.5913 - auc: 0.6920 - accuracy: 0.6846 - val_loss: 0.5978 - val_auc: 0.7308 - val_accuracy: 0.7496 0.5917 - auc: 0.6919 - accuracy: \n",
      "Epoch 28/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5912 - auc: 0.6900 - accuracy: 0.6834 - val_loss: 0.5879 - val_auc: 0.7315 - val_accuracy: 0.7544\n",
      "Epoch 29/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5918 - auc: 0.6885 - accuracy: 0.6834 - val_loss: 0.5977 - val_auc: 0.7322 - val_accuracy: 0.7440\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 1th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.6588 - auc: 0.6174 - accuracy: 0.6035 - val_loss: 0.6322 - val_auc: 0.6732 - val_accuracy: 0.6804\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 21s 23ms/step - loss: 0.6177 - auc: 0.6673 - accuracy: 0.6617 - val_loss: 0.6130 - val_auc: 0.7133 - val_accuracy: 0.7462\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 20s 21ms/step - loss: 0.6086 - auc: 0.6621 - accuracy: 0.6701 - val_loss: 0.6014 - val_auc: 0.7334 - val_accuracy: 0.7752\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.6057 - auc: 0.6623 - accuracy: 0.6732 - val_loss: 0.5998 - val_auc: 0.7297 - val_accuracy: 0.7812\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6029 - auc: 0.6594 - accuracy: 0.6762 - val_loss: 0.5916 - val_auc: 0.7404 - val_accuracy: 0.7860\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.6012 - auc: 0.6610 - accuracy: 0.6769 - val_loss: 0.5954 - val_auc: 0.7259 - val_accuracy: 0.7971\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6000 - auc: 0.6581 - accuracy: 0.6762 - val_loss: 0.6002 - val_auc: 0.7233 - val_accuracy: 0.7919\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5990 - auc: 0.6581 - accuracy: 0.6799 - val_loss: 0.6073 - val_auc: 0.7132 - val_accuracy: 0.7671\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5991 - auc: 0.6585 - accuracy: 0.6801 - val_loss: 0.5923 - val_auc: 0.7151 - val_accuracy: 0.7769\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 17s 19ms/step - loss: 0.5971 - auc: 0.6580 - accuracy: 0.6805 - val_loss: 0.5834 - val_auc: 0.7324 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 15s 17ms/step - loss: 0.5965 - auc: 0.6586 - accuracy: 0.6805 - val_loss: 0.6001 - val_auc: 0.7063 - val_accuracy: 0.7633\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 15s 17ms/step - loss: 0.5959 - auc: 0.6590 - accuracy: 0.6815 - val_loss: 0.5851 - val_auc: 0.7211 - val_accuracy: 0.7948\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.5947 - auc: 0.6605 - accuracy: 0.6830 - val_loss: 0.5855 - val_auc: 0.7229 - val_accuracy: 0.7981\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.5947 - auc: 0.6600 - accuracy: 0.6831 - val_loss: 0.5911 - val_auc: 0.7209 - val_accuracy: 0.7844\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 17s 19ms/step - loss: 0.5937 - auc: 0.6625 - accuracy: 0.6821 - val_loss: 0.5863 - val_auc: 0.7152 - val_accuracy: 0.7858 0.6627 - ac - ETA: 1s -\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 2th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6485 - auc: 0.6090 - accuracy: 0.6238 - val_loss: 0.5916 - val_auc: 0.6993 - val_accuracy: 0.7842\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 16s 18ms/step - loss: 0.6102 - auc: 0.6623 - accuracy: 0.6726 - val_loss: 0.5696 - val_auc: 0.7555 - val_accuracy: 0.7996\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.6015 - auc: 0.6853 - accuracy: 0.6793 - val_loss: 0.5684 - val_auc: 0.7600 - val_accuracy: 0.7937\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 16s 18ms/step - loss: 0.5958 - auc: 0.6979 - accuracy: 0.6851 - val_loss: 0.5757 - val_auc: 0.7500 - val_accuracy: 0.7865\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5944 - auc: 0.7063 - accuracy: 0.6878 - val_loss: 0.5816 - val_auc: 0.7422 - val_accuracy: 0.7796\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5921 - auc: 0.7097 - accuracy: 0.6884 - val_loss: 0.5602 - val_auc: 0.7650 - val_accuracy: 0.7915\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5903 - auc: 0.7131 - accuracy: 0.6904 - val_loss: 0.5453 - val_auc: 0.7770 - val_accuracy: 0.7948\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5909 - auc: 0.7130 - accuracy: 0.6890 - val_loss: 0.5601 - val_auc: 0.7617 - val_accuracy: 0.7810\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.5892 - auc: 0.7149 - accuracy: 0.6903 - val_loss: 0.5621 - val_auc: 0.7586 - val_accuracy: 0.7804\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5863 - auc: 0.7185 - accuracy: 0.6930 - val_loss: 0.5752 - val_auc: 0.7480 - val_accuracy: 0.7715969 - auc: 0.7086 - accuracy: 0. - ETA: 13s - loss - ETA: 5s - loss: 0.5864 - auc: - ETA: 3s - loss: 0.5867 - auc: - ETA: 0s - loss: 0.5862 - auc: 0.7186 - accu\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5856 - auc: 0.7207 - accuracy: 0.6951 - val_loss: 0.5668 - val_auc: 0.7535 - val_accuracy: 0.7729 0.5855 - auc: 0.7208 - ac\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5859 - auc: 0.7186 - accuracy: 0.6952 - val_loss: 0.5632 - val_auc: 0.7557 - val_accuracy: 0.7742\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5851 - auc: 0.7214 - accuracy: 0.6959 - val_loss: 0.5473 - val_auc: 0.7746 - val_accuracy: 0.7856\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 20s 21ms/step - loss: 0.5842 - auc: 0.7213 - accuracy: 0.6939 - val_loss: 0.5438 - val_auc: 0.7773 - val_accuracy: 0.7869\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 20s 21ms/step - loss: 0.5838 - auc: 0.7204 - accuracy: 0.6976 - val_loss: 0.5543 - val_auc: 0.7661 - val_accuracy: 0.7788\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.5818 - auc: 0.7214 - accuracy: 0.6959 - val_loss: 0.5836 - val_auc: 0.7340 - val_accuracy: 0.7546\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5818 - auc: 0.7221 - accuracy: 0.6972 - val_loss: 0.5390 - val_auc: 0.7834 - val_accuracy: 0.7879\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.5823 - auc: 0.7223 - accuracy: 0.6971 - val_loss: 0.5932 - val_auc: 0.7216 - val_accuracy: 0.7400\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5808 - auc: 0.7226 - accuracy: 0.6981 - val_loss: 0.5518 - val_auc: 0.7698 - val_accuracy: 0.7788\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5809 - auc: 0.7219 - accuracy: 0.7008 - val_loss: 0.5497 - val_auc: 0.7720 - val_accuracy: 0.7783\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5805 - auc: 0.7229 - accuracy: 0.6992 - val_loss: 0.5358 - val_auc: 0.7873 - val_accuracy: 0.7881\n",
      "Epoch 22/100\n",
      "932/932 [==============================] - 16s 18ms/step - loss: 0.5806 - auc: 0.7216 - accuracy: 0.6984 - val_loss: 0.5467 - val_auc: 0.7777 - val_accuracy: 0.7775\n",
      "Epoch 23/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5801 - auc: 0.7226 - accuracy: 0.7006 - val_loss: 0.5815 - val_auc: 0.7396 - val_accuracy: 0.7588\n",
      "Epoch 24/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.5790 - auc: 0.7230 - accuracy: 0.6990 - val_loss: 0.5508 - val_auc: 0.7719 - val_accuracy: 0.7746\n",
      "Epoch 25/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5778 - auc: 0.7241 - accuracy: 0.7009 - val_loss: 0.5501 - val_auc: 0.7715 - val_accuracy: 0.7758\n",
      "Epoch 26/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.5782 - auc: 0.7224 - accuracy: 0.6982 - val_loss: 0.5653 - val_auc: 0.7605 - val_accuracy: 0.7673\n",
      "Epoch 27/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.5774 - auc: 0.7229 - accuracy: 0.7003 - val_loss: 0.5365 - val_auc: 0.7876 - val_accuracy: 0.7808\n",
      "Epoch 28/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5781 - auc: 0.7200 - accuracy: 0.7003 - val_loss: 0.5355 - val_auc: 0.7888 - val_accuracy: 0.7825\n",
      "Epoch 29/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5783 - auc: 0.7193 - accuracy: 0.7020 - val_loss: 0.5494 - val_auc: 0.7741 - val_accuracy: 0.7754\n",
      "Epoch 30/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5779 - auc: 0.7195 - accuracy: 0.7015 - val_loss: 0.5540 - val_auc: 0.7702 - val_accuracy: 0.7750\n",
      "Epoch 31/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5773 - auc: 0.7209 - accuracy: 0.7021 - val_loss: 0.5522 - val_auc: 0.7741 - val_accuracy: 0.7738\n",
      "Epoch 32/100\n",
      "932/932 [==============================] - 17s 19ms/step - loss: 0.5768 - auc: 0.7207 - accuracy: 0.7026 - val_loss: 0.5516 - val_auc: 0.7717 - val_accuracy: 0.7777auc: 0.7250  - ETA: 5s - loss: 0.5747 - auc: 0 - ETA: 3s - - ETA: 2s - loss: 0.5766 - auc: 0\n",
      "Epoch 33/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5764 - auc: 0.7191 - accuracy: 0.7007 - val_loss: 0.5627 - val_auc: 0.7608 - val_accuracy: 0.7700767 - auc: 0.7189 \n",
      "Epoch 34/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5766 - auc: 0.7188 - accuracy: 0.7015 - val_loss: 0.5658 - val_auc: 0.7516 - val_accuracy: 0.7600\n",
      "Epoch 35/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5753 - auc: 0.7194 - accuracy: 0.7029 - val_loss: 0.5460 - val_auc: 0.7745 - val_accuracy: 0.7748\n",
      "Epoch 36/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5762 - auc: 0.7198 - accuracy: 0.7018 - val_loss: 0.5645 - val_auc: 0.7489 - val_accuracy: 0.7529\n",
      "Epoch 37/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.5754 - auc: 0.7194 - accuracy: 0.7029 - val_loss: 0.5420 - val_auc: 0.7817 - val_accuracy: 0.7763\n",
      "Epoch 38/100\n",
      "932/932 [==============================] - 16s 18ms/step - loss: 0.5750 - auc: 0.7205 - accuracy: 0.7035 - val_loss: 0.5443 - val_auc: 0.7794 - val_accuracy: 0.7788\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 3th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 16s 18ms/step - loss: 0.6649 - auc: 0.6247 - accuracy: 0.6072 - val_loss: 0.6327 - val_auc: 0.6614 - val_accuracy: 0.6625\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6325 - auc: 0.6462 - accuracy: 0.6378 - val_loss: 0.6430 - val_auc: 0.6495 - val_accuracy: 0.6427\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.6205 - auc: 0.6481 - accuracy: 0.6515 - val_loss: 0.6184 - val_auc: 0.6900 - val_accuracy: 0.7090\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6150 - auc: 0.6483 - accuracy: 0.6557 - val_loss: 0.6220 - val_auc: 0.6816 - val_accuracy: 0.7094\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6104 - auc: 0.6493 - accuracy: 0.6616 - val_loss: 0.6126 - val_auc: 0.6928 - val_accuracy: 0.7250\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.6074 - auc: 0.6501 - accuracy: 0.6668 - val_loss: 0.6056 - val_auc: 0.6961 - val_accuracy: 0.7450\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6065 - auc: 0.6451 - accuracy: 0.6619 - val_loss: 0.5996 - val_auc: 0.7020 - val_accuracy: 0.7688\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.6029 - auc: 0.6514 - accuracy: 0.6698 - val_loss: 0.5991 - val_auc: 0.6942 - val_accuracy: 0.7548\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.6008 - auc: 0.6512 - accuracy: 0.6715 - val_loss: 0.5909 - val_auc: 0.7004 - val_accuracy: 0.7665\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 22s 23ms/step - loss: 0.5990 - auc: 0.6555 - accuracy: 0.6740 - val_loss: 0.5908 - val_auc: 0.7019 - val_accuracy: 0.7702- loss: 0.6001 - auc: 0.6565\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 18s 20ms/step - loss: 0.5974 - auc: 0.6604 - accuracy: 0.6765 - val_loss: 0.5816 - val_auc: 0.7104 - val_accuracy: 0.7823\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5969 - auc: 0.6599 - accuracy: 0.6760 - val_loss: 0.5801 - val_auc: 0.7078 - val_accuracy: 0.7812\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 22s 24ms/step - loss: 0.5942 - auc: 0.6625 - accuracy: 0.6766 - val_loss: 0.5825 - val_auc: 0.6981 - val_accuracy: 0.7644\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 20s 21ms/step - loss: 0.5941 - auc: 0.6662 - accuracy: 0.6800 - val_loss: 0.5782 - val_auc: 0.7075 - val_accuracy: 0.7750\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.5929 - auc: 0.6679 - accuracy: 0.6820 - val_loss: 0.5679 - val_auc: 0.7165 - val_accuracy: 0.7831\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 20s 21ms/step - loss: 0.5899 - auc: 0.6736 - accuracy: 0.6854 - val_loss: 0.5671 - val_auc: 0.7137 - val_accuracy: 0.7850\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 20s 21ms/step - loss: 0.5890 - auc: 0.6745 - accuracy: 0.6875 - val_loss: 0.5712 - val_auc: 0.7106 - val_accuracy: 0.7800\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5885 - auc: 0.6767 - accuracy: 0.6896 - val_loss: 0.5821 - val_auc: 0.6934 - val_accuracy: 0.7554\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 19s 21ms/step - loss: 0.5872 - auc: 0.6802 - accuracy: 0.6912 - val_loss: 0.5894 - val_auc: 0.6884 - val_accuracy: 0.7465 - loss: 0.5870 - auc: 0.6804 - accuracy: 0.\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5864 - auc: 0.6805 - accuracy: 0.6867 - val_loss: 0.5912 - val_auc: 0.6882 - val_accuracy: 0.73401 - auc: 0.6 - ETA: 5s - loss: 0.5868 - auc: 0.6796 - accuracy: 0.68 - - ETA: 4s - loss: 0.5\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5841 - auc: 0.6858 - accuracy: 0.6931 - val_loss: 0.5657 - val_auc: 0.7156 - val_accuracy: 0.7704\n",
      "Epoch 22/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.5837 - auc: 0.6881 - accuracy: 0.6909 - val_loss: 0.5695 - val_auc: 0.7054 - val_accuracy: 0.7671\n",
      "Epoch 23/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5831 - auc: 0.6912 - accuracy: 0.6934 - val_loss: 0.5794 - val_auc: 0.7042 - val_accuracy: 0.7431\n",
      "Epoch 24/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5828 - auc: 0.6932 - accuracy: 0.6948 - val_loss: 0.5781 - val_auc: 0.7062 - val_accuracy: 0.7496oss: 0.5828 - auc: 0.6933 - accuracy\n",
      "Epoch 25/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5820 - auc: 0.6958 - accuracy: 0.6968 - val_loss: 0.5700 - val_auc: 0.7180 - val_accuracy: 0.7610\n",
      "Epoch 26/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5810 - auc: 0.7013 - accuracy: 0.6967 - val_loss: 0.5874 - val_auc: 0.6944 - val_accuracy: 0.7383\n",
      "Epoch 27/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5807 - auc: 0.7052 - accuracy: 0.6992 - val_loss: 0.6165 - val_auc: 0.6683 - val_accuracy: 0.687569\n",
      "Epoch 28/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5805 - auc: 0.7073 - accuracy: 0.7006 - val_loss: 0.5843 - val_auc: 0.7019 - val_accuracy: 0.7360\n",
      "Epoch 29/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5796 - auc: 0.7092 - accuracy: 0.6970 - val_loss: 0.5895 - val_auc: 0.6961 - val_accuracy: 0.7183.5758 - auc: 0.7182 - accuracy:  - ETA: 13s - loss: 0.5756 - auc: 0.7164 - acc - ETA: 11s - loss: 0.5707 - - ETA: 10s - loss: 0.5689 - auc: 0.71 - ETA:  - ETA: 6s - loss: 0.5747 -  - ETA: 4s - loss: 0.5770  - ETA: \n",
      "Epoch 30/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5794 - auc: 0.7090 - accuracy: 0.7008 - val_loss: 0.5780 - val_auc: 0.7165 - val_accuracy: 0.7475\n",
      "Epoch 31/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5789 - auc: 0.7143 - accuracy: 0.7004 - val_loss: 0.5751 - val_auc: 0.7154 - val_accuracy: 0.7460\n",
      "Epoch 32/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5779 - auc: 0.7155 - accuracy: 0.7025 - val_loss: 0.5865 - val_auc: 0.7044 - val_accuracy: 0.7300\n",
      "Epoch 33/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5770 - auc: 0.7166 - accuracy: 0.7036 - val_loss: 0.5796 - val_auc: 0.7134 - val_accuracy: 0.7379\n",
      "Epoch 34/100\n",
      "932/932 [==============================] - 15s 17ms/step - loss: 0.5777 - auc: 0.7172 - accuracy: 0.6987 - val_loss: 0.5812 - val_auc: 0.7148 - val_accuracy: 0.7358\n",
      "Epoch 35/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5764 - auc: 0.7205 - accuracy: 0.7023 - val_loss: 0.6081 - val_auc: 0.6830 - val_accuracy: 0.6983\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 4th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 16s 18ms/step - loss: 0.6391 - auc: 0.6415 - accuracy: 0.6344 - val_loss: 0.6329 - val_auc: 0.6804 - val_accuracy: 0.6917\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6154 - auc: 0.6700 - accuracy: 0.6628 - val_loss: 0.6152 - val_auc: 0.7179 - val_accuracy: 0.7494\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6116 - auc: 0.6765 - accuracy: 0.6682 - val_loss: 0.6080 - val_auc: 0.7177 - val_accuracy: 0.7502.6110 - auc:\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 15s 17ms/step - loss: 0.6093 - auc: 0.6767 - accuracy: 0.6716 - val_loss: 0.6055 - val_auc: 0.7225 - val_accuracy: 0.7631\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 15s 17ms/step - loss: 0.6070 - auc: 0.6778 - accuracy: 0.6732 - val_loss: 0.6017 - val_auc: 0.7229 - val_accuracy: 0.7608\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6044 - auc: 0.6820 - accuracy: 0.6726 - val_loss: 0.5968 - val_auc: 0.7254 - val_accuracy: 0.7752\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6032 - auc: 0.6813 - accuracy: 0.6759 - val_loss: 0.5986 - val_auc: 0.7199 - val_accuracy: 0.7623\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 20s 21ms/step - loss: 0.6026 - auc: 0.6812 - accuracy: 0.6750 - val_loss: 0.5927 - val_auc: 0.7279 - val_accuracy: 0.77425 \n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.6002 - auc: 0.6850 - accuracy: 0.6777 - val_loss: 0.6085 - val_auc: 0.7065 - val_accuracy: 0.7633\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.6006 - auc: 0.6824 - accuracy: 0.6791 - val_loss: 0.6021 - val_auc: 0.7076 - val_accuracy: 0.7690\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5992 - auc: 0.6834 - accuracy: 0.6790 - val_loss: 0.5869 - val_auc: 0.7302 - val_accuracy: 0.7835\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.5981 - auc: 0.6847 - accuracy: 0.6802 - val_loss: 0.5936 - val_auc: 0.7185 - val_accuracy: 0.7763\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 21s 22ms/step - loss: 0.5959 - auc: 0.6863 - accuracy: 0.6795 - val_loss: 0.5874 - val_auc: 0.7260 - val_accuracy: 0.7763\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 21s 22ms/step - loss: 0.5964 - auc: 0.6847 - accuracy: 0.6803 - val_loss: 0.5814 - val_auc: 0.7260 - val_accuracy: 0.7817\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 20s 22ms/step - loss: 0.5941 - auc: 0.6868 - accuracy: 0.6832 - val_loss: 0.5936 - val_auc: 0.7124 - val_accuracy: 0.7758\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 19s 21ms/step - loss: 0.5939 - auc: 0.6878 - accuracy: 0.6824 - val_loss: 0.5813 - val_auc: 0.7216 - val_accuracy: 0.7837\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5928 - auc: 0.6842 - accuracy: 0.6831 - val_loss: 0.5837 - val_auc: 0.7242 - val_accuracy: 0.7835\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5934 - auc: 0.6880 - accuracy: 0.6841 - val_loss: 0.5878 - val_auc: 0.7093 - val_accuracy: 0.7700\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 22s 24ms/step - loss: 0.5921 - auc: 0.6876 - accuracy: 0.6853 - val_loss: 0.5805 - val_auc: 0.7261 - val_accuracy: 0.7802\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 23s 25ms/step - loss: 0.5920 - auc: 0.6891 - accuracy: 0.6851 - val_loss: 0.5806 - val_auc: 0.7227 - val_accuracy: 0.7858\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 25s 27ms/step - loss: 0.5901 - auc: 0.6894 - accuracy: 0.6892 - val_loss: 0.5777 - val_auc: 0.7293 - val_accuracy: 0.7715\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 5th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 25s 27ms/step - loss: 0.6904 - auc: 0.5875 - accuracy: 0.5846 - val_loss: 0.6219 - val_auc: 0.6504 - val_accuracy: 0.7060\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 21s 23ms/step - loss: 0.6161 - auc: 0.6443 - accuracy: 0.6609 - val_loss: 0.5985 - val_auc: 0.7050 - val_accuracy: 0.7450\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 21s 22ms/step - loss: 0.6076 - auc: 0.6537 - accuracy: 0.6693 - val_loss: 0.5973 - val_auc: 0.7119 - val_accuracy: 0.7673\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 23s 25ms/step - loss: 0.6029 - auc: 0.6617 - accuracy: 0.6741 - val_loss: 0.5842 - val_auc: 0.7338 - val_accuracy: 0.7835\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 20s 21ms/step - loss: 0.6004 - auc: 0.6714 - accuracy: 0.6791 - val_loss: 0.5731 - val_auc: 0.7495 - val_accuracy: 0.7773\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 26s 28ms/step - loss: 0.5986 - auc: 0.6782 - accuracy: 0.6804 - val_loss: 0.5742 - val_auc: 0.7461 - val_accuracy: 0.7785 - auc: 0.675 - ETA: 17s - loss: 0.5983 - auc: 0.6763  - ETA: 16s - loss: 0.59 - E\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 21s 22ms/step - loss: 0.5961 - auc: 0.6834 - accuracy: 0.6815 - val_loss: 0.5715 - val_auc: 0.7589 - val_accuracy: 0.7933 ETA: 1s - loss: 0.5963  - ETA: 0s - loss: 0.5965 - auc: 0.682\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 19s 21ms/step - loss: 0.5943 - auc: 0.6900 - accuracy: 0.6843 - val_loss: 0.5546 - val_auc: 0.7749 - val_accuracy: 0.7946\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5922 - auc: 0.6954 - accuracy: 0.6866 - val_loss: 0.5715 - val_auc: 0.7536 - val_accuracy: 0.7865\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 20s 21ms/step - loss: 0.5914 - auc: 0.6991 - accuracy: 0.6882 - val_loss: 0.5676 - val_auc: 0.7591 - val_accuracy: 0.7885\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5911 - auc: 0.7004 - accuracy: 0.6871 - val_loss: 0.5553 - val_auc: 0.7794 - val_accuracy: 0.7933\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5887 - auc: 0.7058 - accuracy: 0.6922 - val_loss: 0.5498 - val_auc: 0.7803 - val_accuracy: 0.7946\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5883 - auc: 0.7060 - accuracy: 0.6932 - val_loss: 0.5685 - val_auc: 0.7558 - val_accuracy: 0.7785\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 19s 21ms/step - loss: 0.5877 - auc: 0.7070 - accuracy: 0.6924 - val_loss: 0.5555 - val_auc: 0.7665 - val_accuracy: 0.7802\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 25s 27ms/step - loss: 0.5873 - auc: 0.7084 - accuracy: 0.6931 - val_loss: 0.5554 - val_auc: 0.7725 - val_accuracy: 0.7867\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 22s 24ms/step - loss: 0.5875 - auc: 0.7066 - accuracy: 0.6920 - val_loss: 0.5632 - val_auc: 0.7625 - val_accuracy: 0.7748\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5864 - auc: 0.7090 - accuracy: 0.6929 - val_loss: 0.5577 - val_auc: 0.7668 - val_accuracy: 0.7840\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5860 - auc: 0.7082 - accuracy: 0.6965 - val_loss: 0.5558 - val_auc: 0.7696 - val_accuracy: 0.7856\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 20s 21ms/step - loss: 0.5852 - auc: 0.7084 - accuracy: 0.6966 - val_loss: 0.5543 - val_auc: 0.7665 - val_accuracy: 0.7817\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.5847 - auc: 0.7121 - accuracy: 0.6971 - val_loss: 0.5673 - val_auc: 0.7462 - val_accuracy: 0.77029 - auc: - ETA: 0s - loss: 0.5848 - \n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 21s 22ms/step - loss: 0.5832 - auc: 0.7122 - accuracy: 0.6989 - val_loss: 0.5625 - val_auc: 0.7607 - val_accuracy: 0.7777\n",
      "Epoch 22/100\n",
      "932/932 [==============================] - 20s 22ms/step - loss: 0.5826 - auc: 0.7133 - accuracy: 0.6979 - val_loss: 0.5556 - val_auc: 0.7686 - val_accuracy: 0.7792\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 6th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 20s 22ms/step - loss: 0.6896 - auc: 0.5795 - accuracy: 0.5765 - val_loss: 0.6809 - val_auc: 0.5477 - val_accuracy: 0.5440\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.6503 - auc: 0.6078 - accuracy: 0.6191 - val_loss: 0.6754 - val_auc: 0.5887 - val_accuracy: 0.5719\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.6343 - auc: 0.6425 - accuracy: 0.6347 - val_loss: 0.6869 - val_auc: 0.5932 - val_accuracy: 0.5796oss: 0\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.6267 - auc: 0.6547 - accuracy: 0.6428 - val_loss: 0.6706 - val_auc: 0.6216 - val_accuracy: 0.6100\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.6206 - auc: 0.6647 - accuracy: 0.6534 - val_loss: 0.6582 - val_auc: 0.6479 - val_accuracy: 0.6425\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.6150 - auc: 0.6720 - accuracy: 0.6600 - val_loss: 0.6506 - val_auc: 0.6597 - val_accuracy: 0.6631\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 19s 20ms/step - loss: 0.6136 - auc: 0.6735 - accuracy: 0.6636 - val_loss: 0.6346 - val_auc: 0.6791 - val_accuracy: 0.6940\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6121 - auc: 0.6731 - accuracy: 0.6658 - val_loss: 0.6301 - val_auc: 0.7011 - val_accuracy: 0.7096\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.6099 - auc: 0.6765 - accuracy: 0.6668 - val_loss: 0.6278 - val_auc: 0.7001 - val_accuracy: 0.7183\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.6077 - auc: 0.6772 - accuracy: 0.6718 - val_loss: 0.6495 - val_auc: 0.6722 - val_accuracy: 0.6773- ac\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6067 - auc: 0.6791 - accuracy: 0.6722 - val_loss: 0.6413 - val_auc: 0.6852 - val_accuracy: 0.6954\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6059 - auc: 0.6813 - accuracy: 0.6726 - val_loss: 0.6219 - val_auc: 0.7120 - val_accuracy: 0.7260\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.6047 - auc: 0.6814 - accuracy: 0.6752 - val_loss: 0.6489 - val_auc: 0.6744 - val_accuracy: 0.6796\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6026 - auc: 0.6827 - accuracy: 0.6758 - val_loss: 0.6256 - val_auc: 0.7059 - val_accuracy: 0.7250\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6009 - auc: 0.6853 - accuracy: 0.6781 - val_loss: 0.6289 - val_auc: 0.6979 - val_accuracy: 0.7146\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6014 - auc: 0.6857 - accuracy: 0.6799 - val_loss: 0.6195 - val_auc: 0.7083 - val_accuracy: 0.7377\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5996 - auc: 0.6840 - accuracy: 0.6799 - val_loss: 0.6180 - val_auc: 0.7046 - val_accuracy: 0.7387\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5976 - auc: 0.6866 - accuracy: 0.6797 - val_loss: 0.6274 - val_auc: 0.6927 - val_accuracy: 0.7171\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5978 - auc: 0.6844 - accuracy: 0.6806 - val_loss: 0.6274 - val_auc: 0.6925 - val_accuracy: 0.7244\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5958 - auc: 0.6880 - accuracy: 0.6865 - val_loss: 0.6012 - val_auc: 0.7169 - val_accuracy: 0.7640\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5953 - auc: 0.6865 - accuracy: 0.6832 - val_loss: 0.6581 - val_auc: 0.6587 - val_accuracy: 0.6779\n",
      "Epoch 22/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5953 - auc: 0.6868 - accuracy: 0.6843 - val_loss: 0.6036 - val_auc: 0.7148 - val_accuracy: 0.7490\n",
      "Epoch 23/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5935 - auc: 0.6898 - accuracy: 0.6847 - val_loss: 0.6000 - val_auc: 0.7217 - val_accuracy: 0.7625\n",
      "Epoch 24/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5940 - auc: 0.6890 - accuracy: 0.6843 - val_loss: 0.6057 - val_auc: 0.7173 - val_accuracy: 0.7546\n",
      "Epoch 25/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5939 - auc: 0.6899 - accuracy: 0.6844 - val_loss: 0.5964 - val_auc: 0.7272 - val_accuracy: 0.7604\n",
      "Epoch 26/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5922 - auc: 0.6927 - accuracy: 0.6880 - val_loss: 0.6240 - val_auc: 0.6920 - val_accuracy: 0.7223\n",
      "Epoch 27/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5918 - auc: 0.6936 - accuracy: 0.6897 - val_loss: 0.6068 - val_auc: 0.7027 - val_accuracy: 0.7460\n",
      "Epoch 28/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5909 - auc: 0.6912 - accuracy: 0.6888 - val_loss: 0.6208 - val_auc: 0.6840 - val_accuracy: 0.7312\n",
      "Epoch 29/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.5918 - auc: 0.6909 - accuracy: 0.6882 - val_loss: 0.6071 - val_auc: 0.7133 - val_accuracy: 0.7462\n",
      "Epoch 30/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.5913 - auc: 0.6930 - accuracy: 0.6875 - val_loss: 0.6242 - val_auc: 0.6875 - val_accuracy: 0.7269\n",
      "Epoch 31/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5935 - auc: 0.6907 - accuracy: 0.6885 - val_loss: 0.6062 - val_auc: 0.7095 - val_accuracy: 0.7487\n",
      "Epoch 32/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5912 - auc: 0.6936 - accuracy: 0.6887 - val_loss: 0.6193 - val_auc: 0.6973 - val_accuracy: 0.7298\n",
      "Epoch 33/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5899 - auc: 0.6949 - accuracy: 0.6891 - val_loss: 0.6130 - val_auc: 0.7067 - val_accuracy: 0.7377\n",
      "Epoch 34/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5904 - auc: 0.6953 - accuracy: 0.6908 - val_loss: 0.6069 - val_auc: 0.7119 - val_accuracy: 0.7498\n",
      "Epoch 35/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5905 - auc: 0.6949 - accuracy: 0.6905 - val_loss: 0.6167 - val_auc: 0.6923 - val_accuracy: 0.7325\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 7th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6862 - auc: 0.5495 - accuracy: 0.5645 - val_loss: 0.6401 - val_auc: 0.5794 - val_accuracy: 0.6658\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6378 - auc: 0.6066 - accuracy: 0.6333 - val_loss: 0.6306 - val_auc: 0.6513 - val_accuracy: 0.6998\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6250 - auc: 0.6369 - accuracy: 0.6514 - val_loss: 0.6209 - val_auc: 0.6852 - val_accuracy: 0.7194\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6177 - auc: 0.6466 - accuracy: 0.6565 - val_loss: 0.6071 - val_auc: 0.7152 - val_accuracy: 0.7527\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6149 - auc: 0.6479 - accuracy: 0.6604 - val_loss: 0.6050 - val_auc: 0.7204 - val_accuracy: 0.7552\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6123 - auc: 0.6481 - accuracy: 0.6645 - val_loss: 0.6069 - val_auc: 0.7140 - val_accuracy: 0.7525\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6097 - auc: 0.6496 - accuracy: 0.6630 - val_loss: 0.6042 - val_auc: 0.7202 - val_accuracy: 0.7635\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6095 - auc: 0.6499 - accuracy: 0.6675 - val_loss: 0.5940 - val_auc: 0.7317 - val_accuracy: 0.7783\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6070 - auc: 0.6495 - accuracy: 0.6695 - val_loss: 0.6018 - val_auc: 0.7185 - val_accuracy: 0.7629\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6052 - auc: 0.6497 - accuracy: 0.6699 - val_loss: 0.5831 - val_auc: 0.7382 - val_accuracy: 0.7952\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6029 - auc: 0.6531 - accuracy: 0.6726 - val_loss: 0.5761 - val_auc: 0.7459 - val_accuracy: 0.7954\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6035 - auc: 0.6509 - accuracy: 0.6697 - val_loss: 0.5870 - val_auc: 0.7301 - val_accuracy: 0.7821\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.6013 - auc: 0.6536 - accuracy: 0.6745 - val_loss: 0.5763 - val_auc: 0.7383 - val_accuracy: 0.7981 0 - ETA: 0s - loss: 0.6016 - auc: 0.6535 -  - ETA: 0s - loss: 0.6014 - auc: 0.6537 - accuracy: 0.67\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.5986 - auc: 0.6556 - accuracy: 0.6782 - val_loss: 0.5884 - val_auc: 0.7189 - val_accuracy: 0.7860\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5977 - auc: 0.6579 - accuracy: 0.6771 - val_loss: 0.5763 - val_auc: 0.7366 - val_accuracy: 0.8023\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5946 - auc: 0.6592 - accuracy: 0.6822 - val_loss: 0.5743 - val_auc: 0.7347 - val_accuracy: 0.8002\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5960 - auc: 0.6589 - accuracy: 0.6810 - val_loss: 0.5672 - val_auc: 0.7427 - val_accuracy: 0.8008\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5932 - auc: 0.6625 - accuracy: 0.6832 - val_loss: 0.5607 - val_auc: 0.7456 - val_accuracy: 0.8050\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5907 - auc: 0.6669 - accuracy: 0.6859 - val_loss: 0.5715 - val_auc: 0.7320 - val_accuracy: 0.7958\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5897 - auc: 0.6705 - accuracy: 0.6912 - val_loss: 0.5700 - val_auc: 0.7322 - val_accuracy: 0.7875\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5879 - auc: 0.6736 - accuracy: 0.6914 - val_loss: 0.5511 - val_auc: 0.7493 - val_accuracy: 0.8008\n",
      "Epoch 22/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5858 - auc: 0.6758 - accuracy: 0.6938 - val_loss: 0.5650 - val_auc: 0.7292 - val_accuracy: 0.7858\n",
      "Epoch 23/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5867 - auc: 0.6762 - accuracy: 0.6919 - val_loss: 0.5592 - val_auc: 0.7363 - val_accuracy: 0.7900\n",
      "Epoch 24/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5852 - auc: 0.6794 - accuracy: 0.6974 - val_loss: 0.5837 - val_auc: 0.7086 - val_accuracy: 0.7652.6793 - accu\n",
      "Epoch 25/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5843 - auc: 0.6828 - accuracy: 0.6974 - val_loss: 0.5586 - val_auc: 0.7359 - val_accuracy: 0.7848\n",
      "Epoch 26/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5832 - auc: 0.6854 - accuracy: 0.6979 - val_loss: 0.5434 - val_auc: 0.7535 - val_accuracy: 0.7885\n",
      "Epoch 27/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5820 - auc: 0.6892 - accuracy: 0.7005 - val_loss: 0.5679 - val_auc: 0.7250 - val_accuracy: 0.7710\n",
      "Epoch 28/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5812 - auc: 0.6923 - accuracy: 0.7014 - val_loss: 0.5448 - val_auc: 0.7483 - val_accuracy: 0.7885\n",
      "Epoch 29/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5804 - auc: 0.6938 - accuracy: 0.7020 - val_loss: 0.5385 - val_auc: 0.7590 - val_accuracy: 0.7921\n",
      "Epoch 30/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5804 - auc: 0.6942 - accuracy: 0.7023 - val_loss: 0.5877 - val_auc: 0.7008 - val_accuracy: 0.7452\n",
      "Epoch 31/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5794 - auc: 0.6963 - accuracy: 0.7005 - val_loss: 0.5740 - val_auc: 0.7193 - val_accuracy: 0.7715\n",
      "Epoch 32/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5778 - auc: 0.6992 - accuracy: 0.7040 - val_loss: 0.5587 - val_auc: 0.7352 - val_accuracy: 0.7783\n",
      "Epoch 33/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5777 - auc: 0.7000 - accuracy: 0.7040 - val_loss: 0.5516 - val_auc: 0.7420 - val_accuracy: 0.7792\n",
      "Epoch 34/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5784 - auc: 0.6993 - accuracy: 0.7052 - val_loss: 0.5636 - val_auc: 0.7285 - val_accuracy: 0.7740\n",
      "Epoch 35/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5778 - auc: 0.7021 - accuracy: 0.7039 - val_loss: 0.5749 - val_auc: 0.7202 - val_accuracy: 0.7660\n",
      "Epoch 36/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5771 - auc: 0.7025 - accuracy: 0.7034 - val_loss: 0.5666 - val_auc: 0.7255 - val_accuracy: 0.7710\n",
      "Epoch 37/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5775 - auc: 0.7039 - accuracy: 0.7035 - val_loss: 0.5586 - val_auc: 0.7320 - val_accuracy: 0.7740\n",
      "Epoch 38/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5753 - auc: 0.7067 - accuracy: 0.7061 - val_loss: 0.5476 - val_auc: 0.7454 - val_accuracy: 0.7788\n",
      "Epoch 39/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5765 - auc: 0.7079 - accuracy: 0.7048 - val_loss: 0.5499 - val_auc: 0.7451 - val_accuracy: 0.7773\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 8th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6713 - auc: 0.6031 - accuracy: 0.5926 - val_loss: 0.6701 - val_auc: 0.5997 - val_accuracy: 0.5756\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.6330 - auc: 0.6421 - accuracy: 0.6462 - val_loss: 0.6513 - val_auc: 0.6546 - val_accuracy: 0.6515\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 16s 18ms/step - loss: 0.6222 - auc: 0.6624 - accuracy: 0.6592 - val_loss: 0.6393 - val_auc: 0.6733 - val_accuracy: 0.6940 - ETA: 0s - loss: 0.6221 - auc: 0.6624 - accuracy\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 16s 18ms/step - loss: 0.6171 - auc: 0.6721 - accuracy: 0.6658 - val_loss: 0.6402 - val_auc: 0.6906 - val_accuracy: 0.6973\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6141 - auc: 0.6835 - accuracy: 0.6691 - val_loss: 0.6323 - val_auc: 0.7058 - val_accuracy: 0.7196\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6101 - auc: 0.6928 - accuracy: 0.6738 - val_loss: 0.6369 - val_auc: 0.6971 - val_accuracy: 0.7065\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 18s 19ms/step - loss: 0.6072 - auc: 0.6979 - accuracy: 0.6775 - val_loss: 0.6247 - val_auc: 0.7139 - val_accuracy: 0.7217\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6047 - auc: 0.7038 - accuracy: 0.6780 - val_loss: 0.6118 - val_auc: 0.7350 - val_accuracy: 0.7504\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6035 - auc: 0.7046 - accuracy: 0.6813 - val_loss: 0.6232 - val_auc: 0.7170 - val_accuracy: 0.7181\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6011 - auc: 0.7074 - accuracy: 0.6830 - val_loss: 0.6331 - val_auc: 0.7010 - val_accuracy: 0.7106\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 15s 17ms/step - loss: 0.5989 - auc: 0.7100 - accuracy: 0.6847 - val_loss: 0.5937 - val_auc: 0.7537 - val_accuracy: 0.7558s: 0.5988 - auc: 0.7100 - accuracy\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6000 - auc: 0.7103 - accuracy: 0.6853 - val_loss: 0.6223 - val_auc: 0.7147 - val_accuracy: 0.7302\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5962 - auc: 0.7124 - accuracy: 0.6895 - val_loss: 0.6205 - val_auc: 0.7114 - val_accuracy: 0.7154\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5970 - auc: 0.7130 - accuracy: 0.6896 - val_loss: 0.5971 - val_auc: 0.7398 - val_accuracy: 0.7462\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5949 - auc: 0.7120 - accuracy: 0.6911 - val_loss: 0.6160 - val_auc: 0.7185 - val_accuracy: 0.7323\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5935 - auc: 0.7168 - accuracy: 0.6918 - val_loss: 0.6110 - val_auc: 0.7198 - val_accuracy: 0.7342\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5937 - auc: 0.7161 - accuracy: 0.6923 - val_loss: 0.6154 - val_auc: 0.7156 - val_accuracy: 0.7294\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5919 - auc: 0.7188 - accuracy: 0.6924 - val_loss: 0.6154 - val_auc: 0.7176 - val_accuracy: 0.7323\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5934 - auc: 0.7161 - accuracy: 0.6904 - val_loss: 0.6043 - val_auc: 0.7287 - val_accuracy: 0.7365\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 15s 17ms/step - loss: 0.5920 - auc: 0.7166 - accuracy: 0.6929 - val_loss: 0.6264 - val_auc: 0.7042 - val_accuracy: 0.7144 loss: 0.5912 - auc: 0\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 15s 17ms/step - loss: 0.5906 - auc: 0.7164 - accuracy: 0.6926 - val_loss: 0.6182 - val_auc: 0.7085 - val_accuracy: 0.7206 loss: 0.5904 - auc:\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 9th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 17s 18ms/step - loss: 0.6622 - auc: 0.6141 - accuracy: 0.6033 - val_loss: 0.6272 - val_auc: 0.6530 - val_accuracy: 0.6940\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 16s 17ms/step - loss: 0.6168 - auc: 0.6473 - accuracy: 0.6603 - val_loss: 0.6132 - val_auc: 0.6960 - val_accuracy: 0.7385\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6091 - auc: 0.6529 - accuracy: 0.6682 - val_loss: 0.6003 - val_auc: 0.7184 - val_accuracy: 0.7675\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6039 - auc: 0.6659 - accuracy: 0.6744 - val_loss: 0.6025 - val_auc: 0.7141 - val_accuracy: 0.7508\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.6011 - auc: 0.6704 - accuracy: 0.6785 - val_loss: 0.5838 - val_auc: 0.7423 - val_accuracy: 0.7919\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5985 - auc: 0.6788 - accuracy: 0.6802 - val_loss: 0.5949 - val_auc: 0.7239 - val_accuracy: 0.7483\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5965 - auc: 0.6853 - accuracy: 0.6815 - val_loss: 0.5847 - val_auc: 0.7410 - val_accuracy: 0.7885\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5944 - auc: 0.6902 - accuracy: 0.6838 - val_loss: 0.5875 - val_auc: 0.7392 - val_accuracy: 0.7875\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5931 - auc: 0.6952 - accuracy: 0.6847 - val_loss: 0.5795 - val_auc: 0.7439 - val_accuracy: 0.7960\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5917 - auc: 0.6953 - accuracy: 0.6842 - val_loss: 0.5818 - val_auc: 0.7364 - val_accuracy: 0.7883\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5917 - auc: 0.6951 - accuracy: 0.6844 - val_loss: 0.5828 - val_auc: 0.7358 - val_accuracy: 0.7725\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5897 - auc: 0.6987 - accuracy: 0.6876 - val_loss: 0.5505 - val_auc: 0.7655 - val_accuracy: 0.8010\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5888 - auc: 0.7018 - accuracy: 0.6889 - val_loss: 0.5766 - val_auc: 0.7366 - val_accuracy: 0.7852\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5874 - auc: 0.7003 - accuracy: 0.6885 - val_loss: 0.5689 - val_auc: 0.7447 - val_accuracy: 0.7954\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5872 - auc: 0.7018 - accuracy: 0.6893 - val_loss: 0.5553 - val_auc: 0.7574 - val_accuracy: 0.7969\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5855 - auc: 0.7018 - accuracy: 0.6910 - val_loss: 0.5736 - val_auc: 0.7346 - val_accuracy: 0.7875\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 15s 17ms/step - loss: 0.5841 - auc: 0.7049 - accuracy: 0.6922 - val_loss: 0.5577 - val_auc: 0.7499 - val_accuracy: 0.7956\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5830 - auc: 0.7041 - accuracy: 0.6922 - val_loss: 0.5535 - val_auc: 0.7568 - val_accuracy: 0.7985\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5817 - auc: 0.7061 - accuracy: 0.6944 - val_loss: 0.5611 - val_auc: 0.7438 - val_accuracy: 0.7902\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 15s 17ms/step - loss: 0.5809 - auc: 0.7077 - accuracy: 0.6950 - val_loss: 0.5537 - val_auc: 0.7468 - val_accuracy: 0.7825\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5805 - auc: 0.7070 - accuracy: 0.6976 - val_loss: 0.5588 - val_auc: 0.7403 - val_accuracy: 0.7908\n",
      "Epoch 22/100\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 0.5795 - auc: 0.7081 - accuracy: 0.6963 - val_loss: 0.5424 - val_auc: 0.7552 - val_accuracy: 0.7948\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 각각의 모델로 각각의 표본 학습 \n",
    "\n",
    "epochs = 100\n",
    "plot_list = []\n",
    "model_list = []\n",
    "learning_rate = 0.00001\n",
    "list_index = 0\n",
    "\n",
    "for (j, sample) in enumerate(sampling_list_half):\n",
    "    \n",
    "    X_train_preprocessing = sample[0]\n",
    "    X_train_add_feature = sample[1]\n",
    "    y_train_preprocessing = sample[3]\n",
    "    \n",
    "    print(\"Train data shape: {} Val data shape: {}\".format(X_train_preprocessing.shape, X_val_preprocessing.shape))\n",
    "    print(\"Training the model with {}th sample\".format(j))\n",
    "    print(\"-----------------------------------------------\")\n",
    "    \n",
    "    model = RNN_Model(learning_rate)\n",
    "    epoch, hist = train_model(model, [X_train_preprocessing, X_train_add_feature], y_train_preprocessing, \n",
    "                              [X_val_preprocessing, X_val_add_feature], y_val_preprocessing, epochs = epochs, batch_size = 32, patience = 20)\n",
    "    model_list.append(model)\n",
    "    plot_list.append([epoch, hist])\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the 0th model\n",
      "0th model's \u001b[35m Precision \u001b[30m: 49.62 \u001b[35m Recall \u001b[30m: 49.39 \u001b[35m F1-score \u001b[30m: 0.50 \u001b[35m Accuracy\u001b[30m: 0.78 \n",
      "\n",
      "Predicting the 1th model\n",
      "1th model's \u001b[35m Precision \u001b[30m: 52.15 \u001b[35m Recall \u001b[30m: 49.86 \u001b[35m F1-score \u001b[30m: 0.51 \u001b[35m Accuracy\u001b[30m: 0.79 \n",
      "\n",
      "Predicting the 2th model\n",
      "2th model's \u001b[35m Precision \u001b[30m: 51.23 \u001b[35m Recall \u001b[30m: 52.66 \u001b[35m F1-score \u001b[30m: 0.52 \u001b[35m Accuracy\u001b[30m: 0.78 \n",
      "\n",
      "Predicting the 3th model\n",
      "3th model's \u001b[35m Precision \u001b[30m: 47.06 \u001b[35m Recall \u001b[30m: 56.77 \u001b[35m F1-score \u001b[30m: 0.51 \u001b[35m Accuracy\u001b[30m: 0.76 \n",
      "\n",
      "Predicting the 4th model\n",
      "4th model's \u001b[35m Precision \u001b[30m: 51.55 \u001b[35m Recall \u001b[30m: 49.77 \u001b[35m F1-score \u001b[30m: 0.51 \u001b[35m Accuracy\u001b[30m: 0.78 \n",
      "\n",
      "Predicting the 5th model\n",
      "5th model's \u001b[35m Precision \u001b[30m: 54.36 \u001b[35m Recall \u001b[30m: 49.49 \u001b[35m F1-score \u001b[30m: 0.52 \u001b[35m Accuracy\u001b[30m: 0.79 \n",
      "\n",
      "Predicting the 6th model\n",
      "6th model's \u001b[35m Precision \u001b[30m: 46.84 \u001b[35m Recall \u001b[30m: 54.62 \u001b[35m F1-score \u001b[30m: 0.50 \u001b[35m Accuracy\u001b[30m: 0.76 \n",
      "\n",
      "Predicting the 7th model\n",
      "7th model's \u001b[35m Precision \u001b[30m: 53.62 \u001b[35m Recall \u001b[30m: 50.51 \u001b[35m F1-score \u001b[30m: 0.52 \u001b[35m Accuracy\u001b[30m: 0.79 \n",
      "\n",
      "Predicting the 8th model\n",
      "8th model's \u001b[35m Precision \u001b[30m: 46.19 \u001b[35m Recall \u001b[30m: 57.14 \u001b[35m F1-score \u001b[30m: 0.51 \u001b[35m Accuracy\u001b[30m: 0.76 \n",
      "\n",
      "Predicting the 9th model\n",
      "9th model's \u001b[35m Precision \u001b[30m: 56.71 \u001b[35m Recall \u001b[30m: 45.75 \u001b[35m F1-score \u001b[30m: 0.51 \u001b[35m Accuracy\u001b[30m: 0.80 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# f1-score\n",
    "for (i, sample) in enumerate(sampling_list_half):\n",
    "    \n",
    "    print(\"Predicting the {}th model\".format(i))\n",
    "    \n",
    "    model = model_list[i]\n",
    "    y_proba = model.predict([X_val_preprocessing, X_val_add_feature])\n",
    "    y_pred = np.argmax(y_proba, axis = 1)\n",
    "    \n",
    "    precision, recall, f1, accuracy = f1_score(y_val, y_pred)\n",
    "    print(\"{}th model's \\033[35m Precision \\033[30m: {:.2f} \\033[35m Recall \\033[30m: {:.2f} \\033[35m F1-score \\033[30m: {:.2f} \\033[35m Accuracy\\033[30m: {:.2f} \\n\".format(i, precision * 100, recall * 100, f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_list = np.array([.0] * (len(X_test) * 2)).reshape(-1, 2)\n",
    "\n",
    "for (i, model) in enumerate(model_list):\n",
    "    \n",
    "    y_proba = model.predict([X_test_preprocessing, X_test_add_feature])\n",
    "    proba_list += y_proba\n",
    "    \n",
    "y_pred = np.argmax((proba_list / len(model_list)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mPrecision\u001b[30m: 0.55, \u001b[35mRecall\u001b[30m: 0.53, \u001b[35mF1-Score\u001b[30m: 0.54, \u001b[35mAccuracy\u001b[30m: 0.81\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, accuracy = f1_score(y_test, y_pred)\n",
    "print(\"\\033[35mPrecision\\033[30m: {:.2f}, \\033[35mRecall\\033[30m: {:.2f}, \\033[35mF1-Score\\033[30m: {:.2f}, \\033[35mAccuracy\\033[30m: {:.2f}\".format(precision, recall, f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 0th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.6719 - auc: 0.5497 - accuracy: 0.5984 - val_loss: 0.6562 - val_auc: 0.5751 - val_accuracy: 0.6371\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6303 - auc: 0.6169 - accuracy: 0.6509 - val_loss: 0.6510 - val_auc: 0.6114 - val_accuracy: 0.6648\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6159 - auc: 0.6491 - accuracy: 0.6659 - val_loss: 0.6363 - val_auc: 0.6391 - val_accuracy: 0.6931\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.6100 - auc: 0.6568 - accuracy: 0.6729 - val_loss: 0.6124 - val_auc: 0.6770 - val_accuracy: 0.7369\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.6042 - auc: 0.6690 - accuracy: 0.6756 - val_loss: 0.6288 - val_auc: 0.6581 - val_accuracy: 0.7106\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5981 - auc: 0.6789 - accuracy: 0.6842 - val_loss: 0.6026 - val_auc: 0.6983 - val_accuracy: 0.7460\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5979 - auc: 0.6870 - accuracy: 0.6839 - val_loss: 0.6180 - val_auc: 0.6871 - val_accuracy: 0.7337\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5932 - auc: 0.6997 - accuracy: 0.6897 - val_loss: 0.5950 - val_auc: 0.7099 - val_accuracy: 0.7556\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5925 - auc: 0.7046 - accuracy: 0.6914 - val_loss: 0.5817 - val_auc: 0.7310 - val_accuracy: 0.7644\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.5912 - auc: 0.7087 - accuracy: 0.6924 - val_loss: 0.5793 - val_auc: 0.7364 - val_accuracy: 0.7654\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5894 - auc: 0.7140 - accuracy: 0.6961 - val_loss: 0.5946 - val_auc: 0.7235 - val_accuracy: 0.7515\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5881 - auc: 0.7171 - accuracy: 0.6961 - val_loss: 0.6169 - val_auc: 0.6995 - val_accuracy: 0.7244\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5876 - auc: 0.7185 - accuracy: 0.6951 - val_loss: 0.6037 - val_auc: 0.7159 - val_accuracy: 0.7427\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5874 - auc: 0.7209 - accuracy: 0.6984 - val_loss: 0.5906 - val_auc: 0.7272 - val_accuracy: 0.7548\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5866 - auc: 0.7215 - accuracy: 0.6990 - val_loss: 0.6017 - val_auc: 0.7180 - val_accuracy: 0.7390\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5853 - auc: 0.7244 - accuracy: 0.6977 - val_loss: 0.5968 - val_auc: 0.7204 - val_accuracy: 0.7400\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5862 - auc: 0.7243 - accuracy: 0.6996 - val_loss: 0.5988 - val_auc: 0.7193 - val_accuracy: 0.7383\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5850 - auc: 0.7266 - accuracy: 0.7007 - val_loss: 0.5992 - val_auc: 0.7203 - val_accuracy: 0.7387\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.5856 - auc: 0.7262 - accuracy: 0.6986 - val_loss: 0.5977 - val_auc: 0.7227 - val_accuracy: 0.7460\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5841 - auc: 0.7290 - accuracy: 0.7005 - val_loss: 0.5838 - val_auc: 0.7384 - val_accuracy: 0.7583\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5845 - auc: 0.7296 - accuracy: 0.7002 - val_loss: 0.5781 - val_auc: 0.7444 - val_accuracy: 0.7617\n",
      "Epoch 22/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5837 - auc: 0.7289 - accuracy: 0.7007 - val_loss: 0.5996 - val_auc: 0.7200 - val_accuracy: 0.7373\n",
      "Epoch 23/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5830 - auc: 0.7278 - accuracy: 0.6998 - val_loss: 0.5955 - val_auc: 0.7272 - val_accuracy: 0.7452\n",
      "Epoch 24/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5828 - auc: 0.7294 - accuracy: 0.7020 - val_loss: 0.6051 - val_auc: 0.7102 - val_accuracy: 0.7390\n",
      "Epoch 25/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5821 - auc: 0.7309 - accuracy: 0.7013 - val_loss: 0.5982 - val_auc: 0.7262 - val_accuracy: 0.7446\n",
      "Epoch 26/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5824 - auc: 0.7307 - accuracy: 0.7001 - val_loss: 0.5777 - val_auc: 0.7466 - val_accuracy: 0.7594\n",
      "Epoch 27/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5805 - auc: 0.7316 - accuracy: 0.7032 - val_loss: 0.6094 - val_auc: 0.7073 - val_accuracy: 0.7312\n",
      "Epoch 28/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5817 - auc: 0.7312 - accuracy: 0.7041 - val_loss: 0.5743 - val_auc: 0.7505 - val_accuracy: 0.7600\n",
      "Epoch 29/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5820 - auc: 0.7313 - accuracy: 0.7020 - val_loss: 0.5974 - val_auc: 0.7265 - val_accuracy: 0.7390\n",
      "Epoch 30/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5806 - auc: 0.7335 - accuracy: 0.7043 - val_loss: 0.6148 - val_auc: 0.6993 - val_accuracy: 0.7190\n",
      "Epoch 31/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5790 - auc: 0.7336 - accuracy: 0.7030 - val_loss: 0.5814 - val_auc: 0.7391 - val_accuracy: 0.7546\n",
      "Epoch 32/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5793 - auc: 0.7327 - accuracy: 0.7043 - val_loss: 0.6075 - val_auc: 0.7124 - val_accuracy: 0.7329\n",
      "Epoch 33/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5791 - auc: 0.7323 - accuracy: 0.7074 - val_loss: 0.5879 - val_auc: 0.7332 - val_accuracy: 0.7450\n",
      "Epoch 34/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5798 - auc: 0.7309 - accuracy: 0.7032 - val_loss: 0.5830 - val_auc: 0.7394 - val_accuracy: 0.7554\n",
      "Epoch 35/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5798 - auc: 0.7330 - accuracy: 0.7032 - val_loss: 0.5737 - val_auc: 0.7473 - val_accuracy: 0.7598\n",
      "Epoch 36/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5801 - auc: 0.7319 - accuracy: 0.7048 - val_loss: 0.5966 - val_auc: 0.7219 - val_accuracy: 0.7429\n",
      "Epoch 37/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5798 - auc: 0.7322 - accuracy: 0.7054 - val_loss: 0.5762 - val_auc: 0.7483 - val_accuracy: 0.7567\n",
      "Epoch 38/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5797 - auc: 0.7318 - accuracy: 0.7028 - val_loss: 0.5854 - val_auc: 0.7365 - val_accuracy: 0.7517\n",
      "Epoch 39/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5781 - auc: 0.7315 - accuracy: 0.7055 - val_loss: 0.5865 - val_auc: 0.7376 - val_accuracy: 0.7410\n",
      "Epoch 40/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5784 - auc: 0.7324 - accuracy: 0.7032 - val_loss: 0.5895 - val_auc: 0.7250 - val_accuracy: 0.7433\n",
      "Epoch 41/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5787 - auc: 0.7302 - accuracy: 0.7046 - val_loss: 0.5825 - val_auc: 0.7392 - val_accuracy: 0.7521\n",
      "Epoch 42/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5778 - auc: 0.7319 - accuracy: 0.7039 - val_loss: 0.5767 - val_auc: 0.7487 - val_accuracy: 0.7592\n",
      "Epoch 43/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5767 - auc: 0.7323 - accuracy: 0.7061 - val_loss: 0.6095 - val_auc: 0.7064 - val_accuracy: 0.7304\n",
      "Epoch 44/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5780 - auc: 0.7289 - accuracy: 0.7040 - val_loss: 0.5940 - val_auc: 0.7192 - val_accuracy: 0.7410\n",
      "Epoch 45/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5775 - auc: 0.7315 - accuracy: 0.7038 - val_loss: 0.5909 - val_auc: 0.7306 - val_accuracy: 0.7412\n",
      "Epoch 46/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5780 - auc: 0.7306 - accuracy: 0.7039 - val_loss: 0.5971 - val_auc: 0.7169 - val_accuracy: 0.7408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5768 - auc: 0.7297 - accuracy: 0.7030 - val_loss: 0.5914 - val_auc: 0.7268 - val_accuracy: 0.7435\n",
      "Epoch 48/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5757 - auc: 0.7326 - accuracy: 0.7073 - val_loss: 0.5875 - val_auc: 0.7325 - val_accuracy: 0.7454\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 1th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 7s 7ms/step - loss: 0.6563 - auc: 0.6110 - accuracy: 0.6144 - val_loss: 0.6515 - val_auc: 0.6196 - val_accuracy: 0.6173\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6280 - auc: 0.6422 - accuracy: 0.6439 - val_loss: 0.6255 - val_auc: 0.6829 - val_accuracy: 0.6796\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6207 - auc: 0.6454 - accuracy: 0.6525 - val_loss: 0.6405 - val_auc: 0.6641 - val_accuracy: 0.6642\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6167 - auc: 0.6436 - accuracy: 0.6597 - val_loss: 0.6322 - val_auc: 0.6800 - val_accuracy: 0.6971\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6144 - auc: 0.6415 - accuracy: 0.6658 - val_loss: 0.6204 - val_auc: 0.6905 - val_accuracy: 0.7146\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6114 - auc: 0.6423 - accuracy: 0.6677 - val_loss: 0.6170 - val_auc: 0.7054 - val_accuracy: 0.7340\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6093 - auc: 0.6425 - accuracy: 0.6710 - val_loss: 0.6067 - val_auc: 0.7139 - val_accuracy: 0.7527\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6072 - auc: 0.6419 - accuracy: 0.6740 - val_loss: 0.6137 - val_auc: 0.7000 - val_accuracy: 0.7337\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6062 - auc: 0.6402 - accuracy: 0.6782 - val_loss: 0.5981 - val_auc: 0.7230 - val_accuracy: 0.7556\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6064 - auc: 0.6385 - accuracy: 0.6758 - val_loss: 0.5960 - val_auc: 0.7217 - val_accuracy: 0.7752\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6042 - auc: 0.6399 - accuracy: 0.6746 - val_loss: 0.6099 - val_auc: 0.7078 - val_accuracy: 0.7437\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6034 - auc: 0.6409 - accuracy: 0.6773 - val_loss: 0.6007 - val_auc: 0.7141 - val_accuracy: 0.7742\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6027 - auc: 0.6418 - accuracy: 0.6772 - val_loss: 0.6032 - val_auc: 0.7107 - val_accuracy: 0.7579\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.6019 - auc: 0.6384 - accuracy: 0.6793 - val_loss: 0.5950 - val_auc: 0.7138 - val_accuracy: 0.7815\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6000 - auc: 0.6432 - accuracy: 0.6787 - val_loss: 0.5927 - val_auc: 0.7235 - val_accuracy: 0.7748\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5983 - auc: 0.6418 - accuracy: 0.6810 - val_loss: 0.5808 - val_auc: 0.7323 - val_accuracy: 0.7904\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5967 - auc: 0.6424 - accuracy: 0.6816 - val_loss: 0.5945 - val_auc: 0.7149 - val_accuracy: 0.7775\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5977 - auc: 0.6420 - accuracy: 0.6811 - val_loss: 0.5805 - val_auc: 0.7244 - val_accuracy: 0.7908\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5969 - auc: 0.6416 - accuracy: 0.6826 - val_loss: 0.5831 - val_auc: 0.7236 - val_accuracy: 0.7875\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5952 - auc: 0.6415 - accuracy: 0.6834 - val_loss: 0.5970 - val_auc: 0.7035 - val_accuracy: 0.7583\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5951 - auc: 0.6423 - accuracy: 0.6823 - val_loss: 0.5801 - val_auc: 0.7267 - val_accuracy: 0.7881\n",
      "Epoch 22/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5942 - auc: 0.6428 - accuracy: 0.6848 - val_loss: 0.5728 - val_auc: 0.7331 - val_accuracy: 0.7906\n",
      "Epoch 23/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5947 - auc: 0.6430 - accuracy: 0.6820 - val_loss: 0.5926 - val_auc: 0.7104 - val_accuracy: 0.7744\n",
      "Epoch 24/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5936 - auc: 0.6432 - accuracy: 0.6838 - val_loss: 0.5772 - val_auc: 0.7188 - val_accuracy: 0.7962\n",
      "Epoch 25/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5930 - auc: 0.6425 - accuracy: 0.6842 - val_loss: 0.5857 - val_auc: 0.7124 - val_accuracy: 0.7794\n",
      "Epoch 26/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5924 - auc: 0.6453 - accuracy: 0.6834 - val_loss: 0.5828 - val_auc: 0.7154 - val_accuracy: 0.7844\n",
      "Epoch 27/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5920 - auc: 0.6436 - accuracy: 0.6845 - val_loss: 0.5669 - val_auc: 0.7375 - val_accuracy: 0.7981\n",
      "Epoch 28/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5908 - auc: 0.6469 - accuracy: 0.6853 - val_loss: 0.5711 - val_auc: 0.7304 - val_accuracy: 0.7973\n",
      "Epoch 29/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5914 - auc: 0.6443 - accuracy: 0.6859 - val_loss: 0.5908 - val_auc: 0.7047 - val_accuracy: 0.7740\n",
      "Epoch 30/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5902 - auc: 0.6453 - accuracy: 0.6867 - val_loss: 0.5724 - val_auc: 0.7295 - val_accuracy: 0.7906\n",
      "Epoch 31/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5902 - auc: 0.6502 - accuracy: 0.6866 - val_loss: 0.5653 - val_auc: 0.7383 - val_accuracy: 0.8021\n",
      "Epoch 32/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5893 - auc: 0.6502 - accuracy: 0.6860 - val_loss: 0.5859 - val_auc: 0.7185 - val_accuracy: 0.7808\n",
      "Epoch 33/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5885 - auc: 0.6533 - accuracy: 0.6882 - val_loss: 0.5807 - val_auc: 0.7182 - val_accuracy: 0.7752\n",
      "Epoch 34/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5886 - auc: 0.6525 - accuracy: 0.6883 - val_loss: 0.5845 - val_auc: 0.7124 - val_accuracy: 0.7654\n",
      "Epoch 35/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5880 - auc: 0.6529 - accuracy: 0.6890 - val_loss: 0.5623 - val_auc: 0.7427 - val_accuracy: 0.7990\n",
      "Epoch 36/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5876 - auc: 0.6537 - accuracy: 0.6887 - val_loss: 0.5904 - val_auc: 0.7106 - val_accuracy: 0.7685\n",
      "Epoch 37/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5871 - auc: 0.6575 - accuracy: 0.6899 - val_loss: 0.5794 - val_auc: 0.7221 - val_accuracy: 0.7850\n",
      "Epoch 38/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5871 - auc: 0.6570 - accuracy: 0.6901 - val_loss: 0.5626 - val_auc: 0.7407 - val_accuracy: 0.7962\n",
      "Epoch 39/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5851 - auc: 0.6586 - accuracy: 0.6918 - val_loss: 0.5751 - val_auc: 0.7263 - val_accuracy: 0.7833\n",
      "Epoch 40/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5860 - auc: 0.6582 - accuracy: 0.6918 - val_loss: 0.5697 - val_auc: 0.7289 - val_accuracy: 0.7873\n",
      "Epoch 41/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5844 - auc: 0.6615 - accuracy: 0.6934 - val_loss: 0.5646 - val_auc: 0.7420 - val_accuracy: 0.7896\n",
      "Epoch 42/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5851 - auc: 0.6643 - accuracy: 0.6932 - val_loss: 0.5794 - val_auc: 0.7207 - val_accuracy: 0.7744\n",
      "Epoch 43/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5834 - auc: 0.6642 - accuracy: 0.6943 - val_loss: 0.5695 - val_auc: 0.7308 - val_accuracy: 0.7810\n",
      "Epoch 44/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5842 - auc: 0.6669 - accuracy: 0.6931 - val_loss: 0.5632 - val_auc: 0.7394 - val_accuracy: 0.7858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5830 - auc: 0.6667 - accuracy: 0.6973 - val_loss: 0.5720 - val_auc: 0.7297 - val_accuracy: 0.7765\n",
      "Epoch 46/100\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 0.5817 - auc: 0.6697 - accuracy: 0.6958 - val_loss: 0.5573 - val_auc: 0.7475 - val_accuracy: 0.7879\n",
      "Epoch 47/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5820 - auc: 0.6705 - accuracy: 0.6964 - val_loss: 0.5549 - val_auc: 0.7462 - val_accuracy: 0.7858\n",
      "Epoch 48/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5830 - auc: 0.6702 - accuracy: 0.6964 - val_loss: 0.5909 - val_auc: 0.7076 - val_accuracy: 0.7506\n",
      "Epoch 49/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5819 - auc: 0.6690 - accuracy: 0.6963 - val_loss: 0.5957 - val_auc: 0.6992 - val_accuracy: 0.7410\n",
      "Epoch 50/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5817 - auc: 0.6716 - accuracy: 0.6983 - val_loss: 0.5794 - val_auc: 0.7201 - val_accuracy: 0.7602\n",
      "Epoch 51/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5819 - auc: 0.6730 - accuracy: 0.6973 - val_loss: 0.5815 - val_auc: 0.7205 - val_accuracy: 0.7669\n",
      "Epoch 52/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5811 - auc: 0.6742 - accuracy: 0.6990 - val_loss: 0.5818 - val_auc: 0.7195 - val_accuracy: 0.7621\n",
      "Epoch 53/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5793 - auc: 0.6769 - accuracy: 0.7005 - val_loss: 0.5932 - val_auc: 0.7046 - val_accuracy: 0.7529\n",
      "Epoch 54/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5796 - auc: 0.6776 - accuracy: 0.7004 - val_loss: 0.5805 - val_auc: 0.7194 - val_accuracy: 0.7602\n",
      "Epoch 55/100\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 0.5797 - auc: 0.6758 - accuracy: 0.7001 - val_loss: 0.5742 - val_auc: 0.7338 - val_accuracy: 0.7742\n",
      "Epoch 56/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5799 - auc: 0.6780 - accuracy: 0.7012 - val_loss: 0.5707 - val_auc: 0.7351 - val_accuracy: 0.7746\n",
      "Epoch 57/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5782 - auc: 0.6787 - accuracy: 0.6995 - val_loss: 0.5732 - val_auc: 0.7288 - val_accuracy: 0.7704\n",
      "Epoch 58/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5790 - auc: 0.6797 - accuracy: 0.7006 - val_loss: 0.5772 - val_auc: 0.7259 - val_accuracy: 0.7694\n",
      "Epoch 59/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5778 - auc: 0.6799 - accuracy: 0.7012 - val_loss: 0.5809 - val_auc: 0.7135 - val_accuracy: 0.7560\n",
      "Epoch 60/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5784 - auc: 0.6779 - accuracy: 0.7014 - val_loss: 0.5679 - val_auc: 0.7315 - val_accuracy: 0.7690\n",
      "Epoch 61/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5787 - auc: 0.6778 - accuracy: 0.7005 - val_loss: 0.5821 - val_auc: 0.7161 - val_accuracy: 0.7583\n",
      "Epoch 62/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5787 - auc: 0.6767 - accuracy: 0.7010 - val_loss: 0.5868 - val_auc: 0.7040 - val_accuracy: 0.7473\n",
      "Epoch 63/100\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 0.5784 - auc: 0.6783 - accuracy: 0.7008 - val_loss: 0.5686 - val_auc: 0.7298 - val_accuracy: 0.7704\n",
      "Epoch 64/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5779 - auc: 0.6811 - accuracy: 0.7010 - val_loss: 0.5906 - val_auc: 0.7063 - val_accuracy: 0.7396\n",
      "Epoch 65/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5761 - auc: 0.6798 - accuracy: 0.7014 - val_loss: 0.5534 - val_auc: 0.7454 - val_accuracy: 0.7796\n",
      "Epoch 66/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5775 - auc: 0.6817 - accuracy: 0.7019 - val_loss: 0.5793 - val_auc: 0.7150 - val_accuracy: 0.7594\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 2th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.6672 - auc: 0.5936 - accuracy: 0.5882 - val_loss: 0.6840 - val_auc: 0.5590 - val_accuracy: 0.5437\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6447 - auc: 0.6072 - accuracy: 0.6214 - val_loss: 0.6616 - val_auc: 0.6037 - val_accuracy: 0.6090\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6333 - auc: 0.6210 - accuracy: 0.6370 - val_loss: 0.6664 - val_auc: 0.6046 - val_accuracy: 0.6100\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6257 - auc: 0.6258 - accuracy: 0.6486 - val_loss: 0.6267 - val_auc: 0.6561 - val_accuracy: 0.6990\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6217 - auc: 0.6325 - accuracy: 0.6540 - val_loss: 0.6257 - val_auc: 0.6612 - val_accuracy: 0.7069\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6165 - auc: 0.6385 - accuracy: 0.6612 - val_loss: 0.6169 - val_auc: 0.6762 - val_accuracy: 0.7300\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6109 - auc: 0.6452 - accuracy: 0.6668 - val_loss: 0.6102 - val_auc: 0.6923 - val_accuracy: 0.7385\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6095 - auc: 0.6509 - accuracy: 0.6694 - val_loss: 0.6093 - val_auc: 0.6895 - val_accuracy: 0.7521\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6062 - auc: 0.6515 - accuracy: 0.6735 - val_loss: 0.6099 - val_auc: 0.6909 - val_accuracy: 0.7540\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6053 - auc: 0.6513 - accuracy: 0.6751 - val_loss: 0.6287 - val_auc: 0.6631 - val_accuracy: 0.7098\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6016 - auc: 0.6559 - accuracy: 0.6787 - val_loss: 0.6084 - val_auc: 0.6923 - val_accuracy: 0.7504\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6006 - auc: 0.6575 - accuracy: 0.6799 - val_loss: 0.5844 - val_auc: 0.7221 - val_accuracy: 0.7854\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5985 - auc: 0.6611 - accuracy: 0.6821 - val_loss: 0.5887 - val_auc: 0.7163 - val_accuracy: 0.7823\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5974 - auc: 0.6618 - accuracy: 0.6845 - val_loss: 0.5983 - val_auc: 0.7066 - val_accuracy: 0.7627\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5967 - auc: 0.6622 - accuracy: 0.6839 - val_loss: 0.6005 - val_auc: 0.6964 - val_accuracy: 0.7665\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5955 - auc: 0.6617 - accuracy: 0.6843 - val_loss: 0.5768 - val_auc: 0.7256 - val_accuracy: 0.7879\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5946 - auc: 0.6652 - accuracy: 0.6855 - val_loss: 0.5878 - val_auc: 0.7131 - val_accuracy: 0.7756\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5925 - auc: 0.6697 - accuracy: 0.6871 - val_loss: 0.5832 - val_auc: 0.7216 - val_accuracy: 0.7846\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5923 - auc: 0.6687 - accuracy: 0.6890 - val_loss: 0.5777 - val_auc: 0.7241 - val_accuracy: 0.7823\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5907 - auc: 0.6700 - accuracy: 0.6884 - val_loss: 0.6063 - val_auc: 0.6897 - val_accuracy: 0.7519\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5901 - auc: 0.6711 - accuracy: 0.6909 - val_loss: 0.5784 - val_auc: 0.7245 - val_accuracy: 0.7821\n",
      "Epoch 22/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5890 - auc: 0.6746 - accuracy: 0.6910 - val_loss: 0.5828 - val_auc: 0.7162 - val_accuracy: 0.7763\n",
      "Epoch 23/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5898 - auc: 0.6753 - accuracy: 0.6924 - val_loss: 0.5879 - val_auc: 0.7059 - val_accuracy: 0.7663\n",
      "Epoch 24/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5886 - auc: 0.6776 - accuracy: 0.6909 - val_loss: 0.5747 - val_auc: 0.7253 - val_accuracy: 0.7729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5875 - auc: 0.6787 - accuracy: 0.6928 - val_loss: 0.5951 - val_auc: 0.6945 - val_accuracy: 0.7579\n",
      "Epoch 26/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5872 - auc: 0.6809 - accuracy: 0.6917 - val_loss: 0.5929 - val_auc: 0.7034 - val_accuracy: 0.7548\n",
      "Epoch 27/100\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 0.5871 - auc: 0.6825 - accuracy: 0.6917 - val_loss: 0.5736 - val_auc: 0.7272 - val_accuracy: 0.7715\n",
      "Epoch 28/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5844 - auc: 0.6861 - accuracy: 0.6946 - val_loss: 0.5872 - val_auc: 0.7109 - val_accuracy: 0.7660\n",
      "Epoch 29/100\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 0.5845 - auc: 0.6855 - accuracy: 0.6960 - val_loss: 0.5804 - val_auc: 0.7179 - val_accuracy: 0.7679\n",
      "Epoch 30/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5847 - auc: 0.6865 - accuracy: 0.6942 - val_loss: 0.5833 - val_auc: 0.7120 - val_accuracy: 0.7638\n",
      "Epoch 31/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5833 - auc: 0.6888 - accuracy: 0.6975 - val_loss: 0.5729 - val_auc: 0.7260 - val_accuracy: 0.7765\n",
      "Epoch 32/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5827 - auc: 0.6896 - accuracy: 0.6993 - val_loss: 0.5768 - val_auc: 0.7220 - val_accuracy: 0.7700\n",
      "Epoch 33/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5823 - auc: 0.6921 - accuracy: 0.6957 - val_loss: 0.5806 - val_auc: 0.7148 - val_accuracy: 0.7656\n",
      "Epoch 34/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5805 - auc: 0.6945 - accuracy: 0.7003 - val_loss: 0.5739 - val_auc: 0.7270 - val_accuracy: 0.7704\n",
      "Epoch 35/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5810 - auc: 0.6938 - accuracy: 0.6977 - val_loss: 0.5766 - val_auc: 0.7242 - val_accuracy: 0.7623\n",
      "Epoch 36/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5805 - auc: 0.6959 - accuracy: 0.7001 - val_loss: 0.5827 - val_auc: 0.7155 - val_accuracy: 0.7596\n",
      "Epoch 37/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5809 - auc: 0.6934 - accuracy: 0.6993 - val_loss: 0.5827 - val_auc: 0.7153 - val_accuracy: 0.7598\n",
      "Epoch 38/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5809 - auc: 0.6961 - accuracy: 0.7007 - val_loss: 0.5712 - val_auc: 0.7291 - val_accuracy: 0.7658\n",
      "Epoch 39/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5801 - auc: 0.6967 - accuracy: 0.6990 - val_loss: 0.5713 - val_auc: 0.7313 - val_accuracy: 0.7644\n",
      "Epoch 40/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5791 - auc: 0.6991 - accuracy: 0.6987 - val_loss: 0.5854 - val_auc: 0.7144 - val_accuracy: 0.7538\n",
      "Epoch 41/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5792 - auc: 0.6996 - accuracy: 0.6991 - val_loss: 0.5796 - val_auc: 0.7195 - val_accuracy: 0.7563\n",
      "Epoch 42/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5795 - auc: 0.6994 - accuracy: 0.7002 - val_loss: 0.5953 - val_auc: 0.7039 - val_accuracy: 0.7365\n",
      "Epoch 43/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5794 - auc: 0.7003 - accuracy: 0.7009 - val_loss: 0.5753 - val_auc: 0.7251 - val_accuracy: 0.7625\n",
      "Epoch 44/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5782 - auc: 0.7035 - accuracy: 0.7017 - val_loss: 0.5877 - val_auc: 0.7116 - val_accuracy: 0.7504\n",
      "Epoch 45/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5786 - auc: 0.7035 - accuracy: 0.7013 - val_loss: 0.5710 - val_auc: 0.7320 - val_accuracy: 0.7604\n",
      "Epoch 46/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5760 - auc: 0.7056 - accuracy: 0.7018 - val_loss: 0.5866 - val_auc: 0.7133 - val_accuracy: 0.7452\n",
      "Epoch 47/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5773 - auc: 0.7069 - accuracy: 0.7027 - val_loss: 0.5756 - val_auc: 0.7267 - val_accuracy: 0.7540\n",
      "Epoch 48/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5780 - auc: 0.7057 - accuracy: 0.7025 - val_loss: 0.5794 - val_auc: 0.7229 - val_accuracy: 0.7529\n",
      "Epoch 49/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5767 - auc: 0.7072 - accuracy: 0.7033 - val_loss: 0.5961 - val_auc: 0.7055 - val_accuracy: 0.7346\n",
      "Epoch 50/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5757 - auc: 0.7075 - accuracy: 0.7032 - val_loss: 0.5821 - val_auc: 0.7196 - val_accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5762 - auc: 0.7068 - accuracy: 0.7022 - val_loss: 0.5927 - val_auc: 0.7059 - val_accuracy: 0.7425\n",
      "Epoch 52/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5769 - auc: 0.7062 - accuracy: 0.7031 - val_loss: 0.5582 - val_auc: 0.7472 - val_accuracy: 0.7677\n",
      "Epoch 53/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5768 - auc: 0.7073 - accuracy: 0.7031 - val_loss: 0.5749 - val_auc: 0.7268 - val_accuracy: 0.7535\n",
      "Epoch 54/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5750 - auc: 0.7092 - accuracy: 0.7030 - val_loss: 0.5859 - val_auc: 0.7148 - val_accuracy: 0.7450\n",
      "Epoch 55/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5746 - auc: 0.7115 - accuracy: 0.7038 - val_loss: 0.5888 - val_auc: 0.7139 - val_accuracy: 0.7381\n",
      "Epoch 56/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5755 - auc: 0.7105 - accuracy: 0.7034 - val_loss: 0.5913 - val_auc: 0.7070 - val_accuracy: 0.7346\n",
      "Epoch 57/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5762 - auc: 0.7087 - accuracy: 0.7037 - val_loss: 0.5697 - val_auc: 0.7328 - val_accuracy: 0.7571\n",
      "Epoch 58/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5741 - auc: 0.7109 - accuracy: 0.7043 - val_loss: 0.5809 - val_auc: 0.7220 - val_accuracy: 0.7513\n",
      "Epoch 59/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5745 - auc: 0.7117 - accuracy: 0.7039 - val_loss: 0.6099 - val_auc: 0.6846 - val_accuracy: 0.7160\n",
      "Epoch 60/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5747 - auc: 0.7100 - accuracy: 0.7042 - val_loss: 0.5846 - val_auc: 0.7129 - val_accuracy: 0.7475\n",
      "Epoch 61/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5739 - auc: 0.7107 - accuracy: 0.7064 - val_loss: 0.5752 - val_auc: 0.7249 - val_accuracy: 0.7498\n",
      "Epoch 62/100\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 0.5740 - auc: 0.7110 - accuracy: 0.7027 - val_loss: 0.5990 - val_auc: 0.6935 - val_accuracy: 0.7321\n",
      "Epoch 63/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5727 - auc: 0.7104 - accuracy: 0.7043 - val_loss: 0.5627 - val_auc: 0.7382 - val_accuracy: 0.7635\n",
      "Epoch 64/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5736 - auc: 0.7115 - accuracy: 0.7051 - val_loss: 0.5770 - val_auc: 0.7234 - val_accuracy: 0.7442\n",
      "Epoch 65/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5728 - auc: 0.7132 - accuracy: 0.7048 - val_loss: 0.5755 - val_auc: 0.7272 - val_accuracy: 0.7485\n",
      "Epoch 66/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5724 - auc: 0.7133 - accuracy: 0.7048 - val_loss: 0.5919 - val_auc: 0.7049 - val_accuracy: 0.7344\n",
      "Epoch 67/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5723 - auc: 0.7132 - accuracy: 0.7049 - val_loss: 0.5932 - val_auc: 0.7020 - val_accuracy: 0.7346\n",
      "Epoch 68/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5717 - auc: 0.7115 - accuracy: 0.7042 - val_loss: 0.5705 - val_auc: 0.7278 - val_accuracy: 0.7510\n",
      "Epoch 69/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5719 - auc: 0.7134 - accuracy: 0.7061 - val_loss: 0.5877 - val_auc: 0.7103 - val_accuracy: 0.7356\n",
      "Epoch 70/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5716 - auc: 0.7149 - accuracy: 0.7059 - val_loss: 0.5891 - val_auc: 0.7084 - val_accuracy: 0.7354\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5715 - auc: 0.7139 - accuracy: 0.7062 - val_loss: 0.5830 - val_auc: 0.7171 - val_accuracy: 0.7448\n",
      "Epoch 72/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5724 - auc: 0.7139 - accuracy: 0.7057 - val_loss: 0.5822 - val_auc: 0.7144 - val_accuracy: 0.7440\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 3th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.6631 - auc: 0.6119 - accuracy: 0.6156 - val_loss: 0.6242 - val_auc: 0.6904 - val_accuracy: 0.7025\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6109 - auc: 0.7019 - accuracy: 0.6739 - val_loss: 0.5950 - val_auc: 0.7785 - val_accuracy: 0.7688\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6023 - auc: 0.7155 - accuracy: 0.6846 - val_loss: 0.5954 - val_auc: 0.7691 - val_accuracy: 0.7569\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5966 - auc: 0.7207 - accuracy: 0.6888 - val_loss: 0.6050 - val_auc: 0.7461 - val_accuracy: 0.7415\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5952 - auc: 0.7198 - accuracy: 0.6877 - val_loss: 0.5836 - val_auc: 0.7849 - val_accuracy: 0.7729\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5901 - auc: 0.7283 - accuracy: 0.6938 - val_loss: 0.5961 - val_auc: 0.7679 - val_accuracy: 0.7590\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5894 - auc: 0.7291 - accuracy: 0.6970 - val_loss: 0.5983 - val_auc: 0.7577 - val_accuracy: 0.7496\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 0.5898 - auc: 0.7291 - accuracy: 0.6958 - val_loss: 0.5911 - val_auc: 0.7665 - val_accuracy: 0.7552\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5871 - auc: 0.7321 - accuracy: 0.6987 - val_loss: 0.5815 - val_auc: 0.7750 - val_accuracy: 0.7633\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5859 - auc: 0.7332 - accuracy: 0.7004 - val_loss: 0.5922 - val_auc: 0.7598 - val_accuracy: 0.7498\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5845 - auc: 0.7353 - accuracy: 0.7021 - val_loss: 0.5815 - val_auc: 0.7714 - val_accuracy: 0.7613\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5839 - auc: 0.7341 - accuracy: 0.7006 - val_loss: 0.5914 - val_auc: 0.7589 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5836 - auc: 0.7340 - accuracy: 0.7024 - val_loss: 0.5812 - val_auc: 0.7673 - val_accuracy: 0.7621\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5832 - auc: 0.7333 - accuracy: 0.7010 - val_loss: 0.5881 - val_auc: 0.7597 - val_accuracy: 0.7554\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5816 - auc: 0.7349 - accuracy: 0.7024 - val_loss: 0.5837 - val_auc: 0.7644 - val_accuracy: 0.7563\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5819 - auc: 0.7344 - accuracy: 0.7036 - val_loss: 0.5979 - val_auc: 0.7491 - val_accuracy: 0.7498\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5829 - auc: 0.7330 - accuracy: 0.7015 - val_loss: 0.5720 - val_auc: 0.7760 - val_accuracy: 0.7615\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5816 - auc: 0.7325 - accuracy: 0.7032 - val_loss: 0.6064 - val_auc: 0.7357 - val_accuracy: 0.7423\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5815 - auc: 0.7340 - accuracy: 0.7041 - val_loss: 0.5899 - val_auc: 0.7525 - val_accuracy: 0.7519\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5816 - auc: 0.7330 - accuracy: 0.7043 - val_loss: 0.5856 - val_auc: 0.7533 - val_accuracy: 0.7527\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5811 - auc: 0.7324 - accuracy: 0.7037 - val_loss: 0.5866 - val_auc: 0.7571 - val_accuracy: 0.7550\n",
      "Epoch 22/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5816 - auc: 0.7321 - accuracy: 0.7042 - val_loss: 0.6016 - val_auc: 0.7407 - val_accuracy: 0.7381\n",
      "Epoch 23/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.5793 - auc: 0.7342 - accuracy: 0.7054 - val_loss: 0.5833 - val_auc: 0.7540 - val_accuracy: 0.7548\n",
      "Epoch 24/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5788 - auc: 0.7338 - accuracy: 0.7059 - val_loss: 0.5977 - val_auc: 0.7421 - val_accuracy: 0.7398\n",
      "Epoch 25/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5796 - auc: 0.7321 - accuracy: 0.7041 - val_loss: 0.5699 - val_auc: 0.7727 - val_accuracy: 0.7617\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 4th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.6429 - auc: 0.6248 - accuracy: 0.6284 - val_loss: 0.5925 - val_auc: 0.7301 - val_accuracy: 0.7806\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6027 - auc: 0.6807 - accuracy: 0.6788 - val_loss: 0.5893 - val_auc: 0.7571 - val_accuracy: 0.7879\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5946 - auc: 0.6966 - accuracy: 0.6842 - val_loss: 0.5725 - val_auc: 0.7760 - val_accuracy: 0.7965\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5922 - auc: 0.7052 - accuracy: 0.6871 - val_loss: 0.5678 - val_auc: 0.7728 - val_accuracy: 0.7946\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5884 - auc: 0.7109 - accuracy: 0.6915 - val_loss: 0.5649 - val_auc: 0.7707 - val_accuracy: 0.7877\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5848 - auc: 0.7172 - accuracy: 0.6929 - val_loss: 0.5760 - val_auc: 0.7574 - val_accuracy: 0.7812\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5845 - auc: 0.7164 - accuracy: 0.6948 - val_loss: 0.5681 - val_auc: 0.7733 - val_accuracy: 0.7825\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.5841 - auc: 0.7180 - accuracy: 0.6964 - val_loss: 0.5749 - val_auc: 0.7547 - val_accuracy: 0.7767\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5819 - auc: 0.7228 - accuracy: 0.7004 - val_loss: 0.5652 - val_auc: 0.7703 - val_accuracy: 0.7792\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5816 - auc: 0.7242 - accuracy: 0.6975 - val_loss: 0.5637 - val_auc: 0.7757 - val_accuracy: 0.7773\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5792 - auc: 0.7285 - accuracy: 0.7017 - val_loss: 0.5527 - val_auc: 0.7735 - val_accuracy: 0.7827\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5784 - auc: 0.7285 - accuracy: 0.7001 - val_loss: 0.5578 - val_auc: 0.7707 - val_accuracy: 0.7752\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5776 - auc: 0.7313 - accuracy: 0.7031 - val_loss: 0.5538 - val_auc: 0.7793 - val_accuracy: 0.7796\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5772 - auc: 0.7334 - accuracy: 0.7029 - val_loss: 0.5698 - val_auc: 0.7632 - val_accuracy: 0.7719\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5763 - auc: 0.7333 - accuracy: 0.7024 - val_loss: 0.5457 - val_auc: 0.7874 - val_accuracy: 0.7812\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5762 - auc: 0.7333 - accuracy: 0.7034 - val_loss: 0.5579 - val_auc: 0.7726 - val_accuracy: 0.7735\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5766 - auc: 0.7326 - accuracy: 0.7046 - val_loss: 0.5728 - val_auc: 0.7585 - val_accuracy: 0.7648\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5757 - auc: 0.7352 - accuracy: 0.7050 - val_loss: 0.5487 - val_auc: 0.7831 - val_accuracy: 0.7773\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5749 - auc: 0.7362 - accuracy: 0.7045 - val_loss: 0.5713 - val_auc: 0.7578 - val_accuracy: 0.7673\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5741 - auc: 0.7363 - accuracy: 0.7060 - val_loss: 0.5588 - val_auc: 0.7737 - val_accuracy: 0.7725\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5739 - auc: 0.7374 - accuracy: 0.7061 - val_loss: 0.5746 - val_auc: 0.7531 - val_accuracy: 0.7658\n",
      "Epoch 22/100\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 0.5732 - auc: 0.7358 - accuracy: 0.7035 - val_loss: 0.5493 - val_auc: 0.7786 - val_accuracy: 0.7763\n",
      "Epoch 23/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5726 - auc: 0.7361 - accuracy: 0.7045 - val_loss: 0.5536 - val_auc: 0.7719 - val_accuracy: 0.7735\n",
      "Epoch 24/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5728 - auc: 0.7344 - accuracy: 0.7045 - val_loss: 0.5620 - val_auc: 0.7681 - val_accuracy: 0.7723\n",
      "Epoch 25/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5730 - auc: 0.7350 - accuracy: 0.7058 - val_loss: 0.5578 - val_auc: 0.7665 - val_accuracy: 0.7698\n",
      "Epoch 26/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5727 - auc: 0.7352 - accuracy: 0.7051 - val_loss: 0.5721 - val_auc: 0.7559 - val_accuracy: 0.7652\n",
      "Epoch 27/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5727 - auc: 0.7345 - accuracy: 0.7061 - val_loss: 0.5523 - val_auc: 0.7712 - val_accuracy: 0.7731\n",
      "Epoch 28/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5723 - auc: 0.7352 - accuracy: 0.7047 - val_loss: 0.5443 - val_auc: 0.7801 - val_accuracy: 0.7777\n",
      "Epoch 29/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5716 - auc: 0.7349 - accuracy: 0.7057 - val_loss: 0.5593 - val_auc: 0.7571 - val_accuracy: 0.7660\n",
      "Epoch 30/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5725 - auc: 0.7317 - accuracy: 0.7055 - val_loss: 0.5569 - val_auc: 0.7678 - val_accuracy: 0.7725\n",
      "Epoch 31/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5722 - auc: 0.7319 - accuracy: 0.7052 - val_loss: 0.5486 - val_auc: 0.7766 - val_accuracy: 0.7748\n",
      "Epoch 32/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5715 - auc: 0.7321 - accuracy: 0.7081 - val_loss: 0.5524 - val_auc: 0.7710 - val_accuracy: 0.7731\n",
      "Epoch 33/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5705 - auc: 0.7313 - accuracy: 0.7070 - val_loss: 0.5488 - val_auc: 0.7701 - val_accuracy: 0.7723\n",
      "Epoch 34/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5709 - auc: 0.7315 - accuracy: 0.7080 - val_loss: 0.5560 - val_auc: 0.7679 - val_accuracy: 0.7700\n",
      "Epoch 35/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5709 - auc: 0.7312 - accuracy: 0.7071 - val_loss: 0.5501 - val_auc: 0.7734 - val_accuracy: 0.7738\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 5th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.6853 - auc: 0.6085 - accuracy: 0.5907 - val_loss: 0.6074 - val_auc: 0.6970 - val_accuracy: 0.7554\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6223 - auc: 0.6639 - accuracy: 0.6576 - val_loss: 0.5975 - val_auc: 0.7172 - val_accuracy: 0.7577\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6124 - auc: 0.6772 - accuracy: 0.6686 - val_loss: 0.6004 - val_auc: 0.7178 - val_accuracy: 0.7617\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6094 - auc: 0.6847 - accuracy: 0.6703 - val_loss: 0.6036 - val_auc: 0.7220 - val_accuracy: 0.7540\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6054 - auc: 0.6931 - accuracy: 0.6769 - val_loss: 0.6043 - val_auc: 0.7264 - val_accuracy: 0.7608\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6040 - auc: 0.6999 - accuracy: 0.6796 - val_loss: 0.5866 - val_auc: 0.7523 - val_accuracy: 0.7767\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6021 - auc: 0.7032 - accuracy: 0.6808 - val_loss: 0.5988 - val_auc: 0.7390 - val_accuracy: 0.7556\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6001 - auc: 0.7091 - accuracy: 0.6841 - val_loss: 0.5852 - val_auc: 0.7558 - val_accuracy: 0.7763\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5966 - auc: 0.7151 - accuracy: 0.6853 - val_loss: 0.5764 - val_auc: 0.7554 - val_accuracy: 0.7817\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5961 - auc: 0.7167 - accuracy: 0.6885 - val_loss: 0.5952 - val_auc: 0.7409 - val_accuracy: 0.7606\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5953 - auc: 0.7181 - accuracy: 0.6871 - val_loss: 0.5661 - val_auc: 0.7812 - val_accuracy: 0.7804\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5957 - auc: 0.7202 - accuracy: 0.6870 - val_loss: 0.5896 - val_auc: 0.7491 - val_accuracy: 0.7542\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5936 - auc: 0.7231 - accuracy: 0.6892 - val_loss: 0.5775 - val_auc: 0.7596 - val_accuracy: 0.7717\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5939 - auc: 0.7224 - accuracy: 0.6897 - val_loss: 0.5775 - val_auc: 0.7566 - val_accuracy: 0.7688\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5917 - auc: 0.7236 - accuracy: 0.6913 - val_loss: 0.5695 - val_auc: 0.7711 - val_accuracy: 0.7746\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5923 - auc: 0.7254 - accuracy: 0.6937 - val_loss: 0.5609 - val_auc: 0.7788 - val_accuracy: 0.7767\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5905 - auc: 0.7288 - accuracy: 0.6912 - val_loss: 0.5710 - val_auc: 0.7660 - val_accuracy: 0.7623\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5908 - auc: 0.7263 - accuracy: 0.6892 - val_loss: 0.5822 - val_auc: 0.7575 - val_accuracy: 0.7650\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5901 - auc: 0.7260 - accuracy: 0.6920 - val_loss: 0.5628 - val_auc: 0.7710 - val_accuracy: 0.7746\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5906 - auc: 0.7254 - accuracy: 0.6919 - val_loss: 0.5533 - val_auc: 0.7838 - val_accuracy: 0.7788\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5886 - auc: 0.7278 - accuracy: 0.6936 - val_loss: 0.5583 - val_auc: 0.7847 - val_accuracy: 0.7746\n",
      "Epoch 22/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5901 - auc: 0.7271 - accuracy: 0.6940 - val_loss: 0.5670 - val_auc: 0.7703 - val_accuracy: 0.7671\n",
      "Epoch 23/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5894 - auc: 0.7291 - accuracy: 0.6923 - val_loss: 0.5740 - val_auc: 0.7590 - val_accuracy: 0.7627\n",
      "Epoch 24/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5876 - auc: 0.7320 - accuracy: 0.6967 - val_loss: 0.5497 - val_auc: 0.7897 - val_accuracy: 0.7794\n",
      "Epoch 25/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5883 - auc: 0.7287 - accuracy: 0.6933 - val_loss: 0.5478 - val_auc: 0.7881 - val_accuracy: 0.7752\n",
      "Epoch 26/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5873 - auc: 0.7306 - accuracy: 0.6952 - val_loss: 0.5540 - val_auc: 0.7819 - val_accuracy: 0.7696\n",
      "Epoch 27/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5865 - auc: 0.7315 - accuracy: 0.6947 - val_loss: 0.5680 - val_auc: 0.7718 - val_accuracy: 0.7669\n",
      "Epoch 28/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5870 - auc: 0.7299 - accuracy: 0.6943 - val_loss: 0.5729 - val_auc: 0.7604 - val_accuracy: 0.7677\n",
      "Epoch 29/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5862 - auc: 0.7308 - accuracy: 0.6950 - val_loss: 0.5493 - val_auc: 0.7833 - val_accuracy: 0.7752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5854 - auc: 0.7326 - accuracy: 0.6958 - val_loss: 0.5556 - val_auc: 0.7783 - val_accuracy: 0.7708\n",
      "Epoch 31/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5847 - auc: 0.7332 - accuracy: 0.6973 - val_loss: 0.5641 - val_auc: 0.7725 - val_accuracy: 0.7738\n",
      "Epoch 32/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5840 - auc: 0.7336 - accuracy: 0.6972 - val_loss: 0.5658 - val_auc: 0.7640 - val_accuracy: 0.7671\n",
      "Epoch 33/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5839 - auc: 0.7331 - accuracy: 0.6944 - val_loss: 0.5687 - val_auc: 0.7630 - val_accuracy: 0.7663\n",
      "Epoch 34/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5850 - auc: 0.7331 - accuracy: 0.6949 - val_loss: 0.5651 - val_auc: 0.7706 - val_accuracy: 0.7656\n",
      "Epoch 35/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5851 - auc: 0.7341 - accuracy: 0.6970 - val_loss: 0.5653 - val_auc: 0.7639 - val_accuracy: 0.7610\n",
      "Epoch 36/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5851 - auc: 0.7331 - accuracy: 0.6950 - val_loss: 0.5576 - val_auc: 0.7776 - val_accuracy: 0.7706\n",
      "Epoch 37/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5829 - auc: 0.7357 - accuracy: 0.6972 - val_loss: 0.5760 - val_auc: 0.7595 - val_accuracy: 0.7567\n",
      "Epoch 38/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5831 - auc: 0.7360 - accuracy: 0.6946 - val_loss: 0.5595 - val_auc: 0.7740 - val_accuracy: 0.7681\n",
      "Epoch 39/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5835 - auc: 0.7350 - accuracy: 0.6974 - val_loss: 0.5598 - val_auc: 0.7755 - val_accuracy: 0.7640\n",
      "Epoch 40/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5829 - auc: 0.7357 - accuracy: 0.6970 - val_loss: 0.5576 - val_auc: 0.7754 - val_accuracy: 0.7721\n",
      "Epoch 41/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5816 - auc: 0.7348 - accuracy: 0.6989 - val_loss: 0.5642 - val_auc: 0.7678 - val_accuracy: 0.7598\n",
      "Epoch 42/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5817 - auc: 0.7373 - accuracy: 0.6963 - val_loss: 0.5674 - val_auc: 0.7631 - val_accuracy: 0.7610\n",
      "Epoch 43/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5811 - auc: 0.7373 - accuracy: 0.6989 - val_loss: 0.5930 - val_auc: 0.7344 - val_accuracy: 0.7248\n",
      "Epoch 44/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5816 - auc: 0.7364 - accuracy: 0.6988 - val_loss: 0.5578 - val_auc: 0.7779 - val_accuracy: 0.7663\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 6th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.6751 - auc: 0.5778 - accuracy: 0.6084 - val_loss: 0.6293 - val_auc: 0.5999 - val_accuracy: 0.7104\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6254 - auc: 0.6018 - accuracy: 0.6553 - val_loss: 0.6253 - val_auc: 0.6323 - val_accuracy: 0.7240\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6192 - auc: 0.6188 - accuracy: 0.6632 - val_loss: 0.6209 - val_auc: 0.6360 - val_accuracy: 0.7248\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6162 - auc: 0.6236 - accuracy: 0.6645 - val_loss: 0.6144 - val_auc: 0.6653 - val_accuracy: 0.7465\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6142 - auc: 0.6352 - accuracy: 0.6663 - val_loss: 0.6181 - val_auc: 0.6629 - val_accuracy: 0.7275\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6125 - auc: 0.6410 - accuracy: 0.6701 - val_loss: 0.6129 - val_auc: 0.6879 - val_accuracy: 0.7448\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6100 - auc: 0.6455 - accuracy: 0.6705 - val_loss: 0.5956 - val_auc: 0.7031 - val_accuracy: 0.7698\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6090 - auc: 0.6448 - accuracy: 0.6710 - val_loss: 0.6009 - val_auc: 0.7121 - val_accuracy: 0.7648\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6071 - auc: 0.6513 - accuracy: 0.6752 - val_loss: 0.6047 - val_auc: 0.7111 - val_accuracy: 0.7679\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6042 - auc: 0.6574 - accuracy: 0.6768 - val_loss: 0.6071 - val_auc: 0.7037 - val_accuracy: 0.7498\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6033 - auc: 0.6631 - accuracy: 0.6778 - val_loss: 0.6037 - val_auc: 0.7194 - val_accuracy: 0.7579\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6011 - auc: 0.6694 - accuracy: 0.6793 - val_loss: 0.6055 - val_auc: 0.7190 - val_accuracy: 0.7556\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5990 - auc: 0.6751 - accuracy: 0.6814 - val_loss: 0.5856 - val_auc: 0.7386 - val_accuracy: 0.7715\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5973 - auc: 0.6855 - accuracy: 0.6848 - val_loss: 0.5999 - val_auc: 0.7357 - val_accuracy: 0.7521\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.5965 - auc: 0.6892 - accuracy: 0.6831 - val_loss: 0.5776 - val_auc: 0.7663 - val_accuracy: 0.7829\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5946 - auc: 0.6943 - accuracy: 0.6856 - val_loss: 0.5816 - val_auc: 0.7589 - val_accuracy: 0.7698\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5935 - auc: 0.7000 - accuracy: 0.6865 - val_loss: 0.5884 - val_auc: 0.7599 - val_accuracy: 0.7700\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5920 - auc: 0.7027 - accuracy: 0.6884 - val_loss: 0.5611 - val_auc: 0.7822 - val_accuracy: 0.7850\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5904 - auc: 0.7075 - accuracy: 0.6934 - val_loss: 0.5741 - val_auc: 0.7708 - val_accuracy: 0.7779\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5878 - auc: 0.7140 - accuracy: 0.6935 - val_loss: 0.5689 - val_auc: 0.7723 - val_accuracy: 0.7798\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5874 - auc: 0.7134 - accuracy: 0.6962 - val_loss: 0.5709 - val_auc: 0.7684 - val_accuracy: 0.7688\n",
      "Epoch 22/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5866 - auc: 0.7163 - accuracy: 0.6982 - val_loss: 0.5674 - val_auc: 0.7720 - val_accuracy: 0.7742\n",
      "Epoch 23/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5851 - auc: 0.7169 - accuracy: 0.7001 - val_loss: 0.5557 - val_auc: 0.7821 - val_accuracy: 0.7806\n",
      "Epoch 24/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5864 - auc: 0.7151 - accuracy: 0.6978 - val_loss: 0.5612 - val_auc: 0.7751 - val_accuracy: 0.7735\n",
      "Epoch 25/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5839 - auc: 0.7187 - accuracy: 0.6980 - val_loss: 0.5908 - val_auc: 0.7395 - val_accuracy: 0.7425\n",
      "Epoch 26/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5831 - auc: 0.7175 - accuracy: 0.7004 - val_loss: 0.5837 - val_auc: 0.7497 - val_accuracy: 0.7617\n",
      "Epoch 27/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5819 - auc: 0.7175 - accuracy: 0.7005 - val_loss: 0.5633 - val_auc: 0.7672 - val_accuracy: 0.7683\n",
      "Epoch 28/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5831 - auc: 0.7182 - accuracy: 0.6998 - val_loss: 0.5607 - val_auc: 0.7692 - val_accuracy: 0.7688\n",
      "Epoch 29/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5815 - auc: 0.7200 - accuracy: 0.7006 - val_loss: 0.5566 - val_auc: 0.7742 - val_accuracy: 0.7685\n",
      "Epoch 30/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5817 - auc: 0.7198 - accuracy: 0.7009 - val_loss: 0.5631 - val_auc: 0.7658 - val_accuracy: 0.7667\n",
      "Epoch 31/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5802 - auc: 0.7198 - accuracy: 0.7025 - val_loss: 0.5613 - val_auc: 0.7629 - val_accuracy: 0.7673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5804 - auc: 0.7198 - accuracy: 0.7015 - val_loss: 0.5543 - val_auc: 0.7727 - val_accuracy: 0.7710\n",
      "Epoch 33/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5803 - auc: 0.7188 - accuracy: 0.7029 - val_loss: 0.5821 - val_auc: 0.7397 - val_accuracy: 0.7481\n",
      "Epoch 34/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5787 - auc: 0.7214 - accuracy: 0.7039 - val_loss: 0.5721 - val_auc: 0.7539 - val_accuracy: 0.7635\n",
      "Epoch 35/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5799 - auc: 0.7201 - accuracy: 0.7024 - val_loss: 0.5724 - val_auc: 0.7514 - val_accuracy: 0.7552\n",
      "Epoch 36/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5779 - auc: 0.7199 - accuracy: 0.7047 - val_loss: 0.5535 - val_auc: 0.7704 - val_accuracy: 0.7700\n",
      "Epoch 37/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5790 - auc: 0.7192 - accuracy: 0.7031 - val_loss: 0.5515 - val_auc: 0.7720 - val_accuracy: 0.7723\n",
      "Epoch 38/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5781 - auc: 0.7195 - accuracy: 0.7031 - val_loss: 0.5452 - val_auc: 0.7777 - val_accuracy: 0.7740\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 7th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.6764 - auc: 0.5790 - accuracy: 0.5850 - val_loss: 0.6735 - val_auc: 0.5823 - val_accuracy: 0.5587\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6342 - auc: 0.6299 - accuracy: 0.6390 - val_loss: 0.6731 - val_auc: 0.6075 - val_accuracy: 0.6008\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6231 - auc: 0.6441 - accuracy: 0.6549 - val_loss: 0.6475 - val_auc: 0.6508 - val_accuracy: 0.6769\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6187 - auc: 0.6438 - accuracy: 0.6613 - val_loss: 0.6458 - val_auc: 0.6621 - val_accuracy: 0.6965\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6150 - auc: 0.6441 - accuracy: 0.6667 - val_loss: 0.6336 - val_auc: 0.6837 - val_accuracy: 0.7227\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6132 - auc: 0.6422 - accuracy: 0.6696 - val_loss: 0.6253 - val_auc: 0.6960 - val_accuracy: 0.7371\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6108 - auc: 0.6390 - accuracy: 0.6719 - val_loss: 0.6182 - val_auc: 0.6962 - val_accuracy: 0.7392\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6102 - auc: 0.6393 - accuracy: 0.6729 - val_loss: 0.6291 - val_auc: 0.6795 - val_accuracy: 0.7298\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6076 - auc: 0.6382 - accuracy: 0.6750 - val_loss: 0.5892 - val_auc: 0.7217 - val_accuracy: 0.7875\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6081 - auc: 0.6353 - accuracy: 0.6738 - val_loss: 0.6300 - val_auc: 0.6753 - val_accuracy: 0.7362\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6066 - auc: 0.6386 - accuracy: 0.6771 - val_loss: 0.5983 - val_auc: 0.7151 - val_accuracy: 0.7781\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6057 - auc: 0.6379 - accuracy: 0.6756 - val_loss: 0.6130 - val_auc: 0.7013 - val_accuracy: 0.7523\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6051 - auc: 0.6367 - accuracy: 0.6784 - val_loss: 0.6047 - val_auc: 0.7082 - val_accuracy: 0.7475\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6038 - auc: 0.6395 - accuracy: 0.6792 - val_loss: 0.5965 - val_auc: 0.7125 - val_accuracy: 0.7621\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6027 - auc: 0.6390 - accuracy: 0.6818 - val_loss: 0.6000 - val_auc: 0.7161 - val_accuracy: 0.7658\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6023 - auc: 0.6400 - accuracy: 0.6815 - val_loss: 0.5936 - val_auc: 0.7163 - val_accuracy: 0.7785\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6001 - auc: 0.6385 - accuracy: 0.6838 - val_loss: 0.6054 - val_auc: 0.7080 - val_accuracy: 0.7696\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6008 - auc: 0.6396 - accuracy: 0.6827 - val_loss: 0.5850 - val_auc: 0.7204 - val_accuracy: 0.7771\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5999 - auc: 0.6381 - accuracy: 0.6846 - val_loss: 0.5936 - val_auc: 0.7119 - val_accuracy: 0.7756\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5992 - auc: 0.6385 - accuracy: 0.6826 - val_loss: 0.5882 - val_auc: 0.7195 - val_accuracy: 0.7735\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5980 - auc: 0.6416 - accuracy: 0.6864 - val_loss: 0.5819 - val_auc: 0.7252 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5980 - auc: 0.6410 - accuracy: 0.6863 - val_loss: 0.5801 - val_auc: 0.7249 - val_accuracy: 0.7796\n",
      "Epoch 23/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5964 - auc: 0.6406 - accuracy: 0.6844 - val_loss: 0.5885 - val_auc: 0.7168 - val_accuracy: 0.7679\n",
      "Epoch 24/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5962 - auc: 0.6418 - accuracy: 0.6871 - val_loss: 0.5838 - val_auc: 0.7185 - val_accuracy: 0.7856\n",
      "Epoch 25/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5946 - auc: 0.6453 - accuracy: 0.6863 - val_loss: 0.5745 - val_auc: 0.7262 - val_accuracy: 0.7860\n",
      "Epoch 26/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5935 - auc: 0.6457 - accuracy: 0.6872 - val_loss: 0.5718 - val_auc: 0.7283 - val_accuracy: 0.7883\n",
      "Epoch 27/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5927 - auc: 0.6463 - accuracy: 0.6897 - val_loss: 0.5928 - val_auc: 0.7074 - val_accuracy: 0.7675\n",
      "Epoch 28/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5926 - auc: 0.6473 - accuracy: 0.6888 - val_loss: 0.5801 - val_auc: 0.7189 - val_accuracy: 0.7831\n",
      "Epoch 29/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5928 - auc: 0.6467 - accuracy: 0.6880 - val_loss: 0.5740 - val_auc: 0.7274 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5910 - auc: 0.6484 - accuracy: 0.6893 - val_loss: 0.5623 - val_auc: 0.7373 - val_accuracy: 0.7933\n",
      "Epoch 31/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5903 - auc: 0.6517 - accuracy: 0.6917 - val_loss: 0.5611 - val_auc: 0.7383 - val_accuracy: 0.7917\n",
      "Epoch 32/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5902 - auc: 0.6503 - accuracy: 0.6896 - val_loss: 0.5791 - val_auc: 0.7125 - val_accuracy: 0.7781\n",
      "Epoch 33/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5885 - auc: 0.6538 - accuracy: 0.6900 - val_loss: 0.5713 - val_auc: 0.7274 - val_accuracy: 0.7881\n",
      "Epoch 34/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5883 - auc: 0.6564 - accuracy: 0.6931 - val_loss: 0.5484 - val_auc: 0.7457 - val_accuracy: 0.7931\n",
      "Epoch 35/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5868 - auc: 0.6586 - accuracy: 0.6927 - val_loss: 0.5744 - val_auc: 0.7187 - val_accuracy: 0.7756\n",
      "Epoch 36/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5872 - auc: 0.6595 - accuracy: 0.6929 - val_loss: 0.5581 - val_auc: 0.7333 - val_accuracy: 0.7948\n",
      "Epoch 37/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5853 - auc: 0.6620 - accuracy: 0.6946 - val_loss: 0.5565 - val_auc: 0.7379 - val_accuracy: 0.7933\n",
      "Epoch 38/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5850 - auc: 0.6636 - accuracy: 0.6954 - val_loss: 0.5536 - val_auc: 0.7382 - val_accuracy: 0.7940\n",
      "Epoch 39/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5833 - auc: 0.6688 - accuracy: 0.6961 - val_loss: 0.5569 - val_auc: 0.7398 - val_accuracy: 0.7900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5832 - auc: 0.6685 - accuracy: 0.6963 - val_loss: 0.5433 - val_auc: 0.7497 - val_accuracy: 0.7969\n",
      "Epoch 41/100\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 0.5810 - auc: 0.6703 - accuracy: 0.6983 - val_loss: 0.5516 - val_auc: 0.7445 - val_accuracy: 0.7906\n",
      "Epoch 42/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5833 - auc: 0.6698 - accuracy: 0.6963 - val_loss: 0.5402 - val_auc: 0.7489 - val_accuracy: 0.7940\n",
      "Epoch 43/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5812 - auc: 0.6740 - accuracy: 0.7001 - val_loss: 0.5400 - val_auc: 0.7562 - val_accuracy: 0.7940\n",
      "Epoch 44/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5813 - auc: 0.6757 - accuracy: 0.6994 - val_loss: 0.5393 - val_auc: 0.7531 - val_accuracy: 0.7900\n",
      "Epoch 45/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5796 - auc: 0.6770 - accuracy: 0.7011 - val_loss: 0.5664 - val_auc: 0.7290 - val_accuracy: 0.7706\n",
      "Epoch 46/100\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 0.5788 - auc: 0.6810 - accuracy: 0.7023 - val_loss: 0.5393 - val_auc: 0.7546 - val_accuracy: 0.7892\n",
      "Epoch 47/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5797 - auc: 0.6831 - accuracy: 0.7030 - val_loss: 0.5470 - val_auc: 0.7465 - val_accuracy: 0.7852\n",
      "Epoch 48/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5788 - auc: 0.6846 - accuracy: 0.7024 - val_loss: 0.5555 - val_auc: 0.7421 - val_accuracy: 0.7823\n",
      "Epoch 49/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5776 - auc: 0.6852 - accuracy: 0.7033 - val_loss: 0.5378 - val_auc: 0.7551 - val_accuracy: 0.7854\n",
      "Epoch 50/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5767 - auc: 0.6863 - accuracy: 0.7057 - val_loss: 0.5438 - val_auc: 0.7526 - val_accuracy: 0.7852\n",
      "Epoch 51/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5773 - auc: 0.6869 - accuracy: 0.7041 - val_loss: 0.5679 - val_auc: 0.7267 - val_accuracy: 0.7660\n",
      "Epoch 52/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5766 - auc: 0.6880 - accuracy: 0.7038 - val_loss: 0.5484 - val_auc: 0.7458 - val_accuracy: 0.7806\n",
      "Epoch 53/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5772 - auc: 0.6900 - accuracy: 0.7046 - val_loss: 0.5343 - val_auc: 0.7562 - val_accuracy: 0.7835\n",
      "Epoch 54/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5768 - auc: 0.6891 - accuracy: 0.7037 - val_loss: 0.5571 - val_auc: 0.7428 - val_accuracy: 0.7738\n",
      "Epoch 55/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5743 - auc: 0.6943 - accuracy: 0.7061 - val_loss: 0.5528 - val_auc: 0.7426 - val_accuracy: 0.7738\n",
      "Epoch 56/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5757 - auc: 0.6945 - accuracy: 0.7077 - val_loss: 0.5330 - val_auc: 0.7601 - val_accuracy: 0.7825\n",
      "Epoch 57/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5755 - auc: 0.6940 - accuracy: 0.7058 - val_loss: 0.5598 - val_auc: 0.7403 - val_accuracy: 0.7723\n",
      "Epoch 58/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5745 - auc: 0.6954 - accuracy: 0.7058 - val_loss: 0.5532 - val_auc: 0.7424 - val_accuracy: 0.7758\n",
      "Epoch 59/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5743 - auc: 0.6961 - accuracy: 0.7061 - val_loss: 0.5575 - val_auc: 0.7375 - val_accuracy: 0.7719\n",
      "Epoch 60/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5746 - auc: 0.6955 - accuracy: 0.7069 - val_loss: 0.5626 - val_auc: 0.7356 - val_accuracy: 0.7671\n",
      "Epoch 61/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5753 - auc: 0.6945 - accuracy: 0.7042 - val_loss: 0.5304 - val_auc: 0.7651 - val_accuracy: 0.7837\n",
      "Epoch 62/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5742 - auc: 0.6969 - accuracy: 0.7074 - val_loss: 0.5445 - val_auc: 0.7520 - val_accuracy: 0.7783\n",
      "Epoch 63/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5733 - auc: 0.6970 - accuracy: 0.7070 - val_loss: 0.5326 - val_auc: 0.7614 - val_accuracy: 0.7812\n",
      "Epoch 64/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5736 - auc: 0.6966 - accuracy: 0.7072 - val_loss: 0.5335 - val_auc: 0.7596 - val_accuracy: 0.7812\n",
      "Epoch 65/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5741 - auc: 0.6980 - accuracy: 0.7056 - val_loss: 0.5471 - val_auc: 0.7483 - val_accuracy: 0.7748\n",
      "Epoch 66/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5727 - auc: 0.6986 - accuracy: 0.7062 - val_loss: 0.5342 - val_auc: 0.7635 - val_accuracy: 0.7819\n",
      "Epoch 67/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5738 - auc: 0.6976 - accuracy: 0.7073 - val_loss: 0.5407 - val_auc: 0.7576 - val_accuracy: 0.7775\n",
      "Epoch 68/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5731 - auc: 0.6990 - accuracy: 0.7076 - val_loss: 0.5455 - val_auc: 0.7470 - val_accuracy: 0.7750\n",
      "Epoch 69/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5726 - auc: 0.7001 - accuracy: 0.7076 - val_loss: 0.5394 - val_auc: 0.7574 - val_accuracy: 0.7756\n",
      "Epoch 70/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5725 - auc: 0.7019 - accuracy: 0.7063 - val_loss: 0.5269 - val_auc: 0.7637 - val_accuracy: 0.7806\n",
      "Epoch 71/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5723 - auc: 0.6985 - accuracy: 0.7076 - val_loss: 0.5403 - val_auc: 0.7556 - val_accuracy: 0.7773\n",
      "Epoch 72/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5710 - auc: 0.7006 - accuracy: 0.7068 - val_loss: 0.5363 - val_auc: 0.7589 - val_accuracy: 0.7775\n",
      "Epoch 73/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5722 - auc: 0.7013 - accuracy: 0.7077 - val_loss: 0.5578 - val_auc: 0.7378 - val_accuracy: 0.7688\n",
      "Epoch 74/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5715 - auc: 0.7035 - accuracy: 0.7066 - val_loss: 0.5427 - val_auc: 0.7484 - val_accuracy: 0.7725\n",
      "Epoch 75/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5716 - auc: 0.7011 - accuracy: 0.7093 - val_loss: 0.5291 - val_auc: 0.7628 - val_accuracy: 0.7825\n",
      "Epoch 76/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5716 - auc: 0.7000 - accuracy: 0.7061 - val_loss: 0.5541 - val_auc: 0.7393 - val_accuracy: 0.7710\n",
      "Epoch 77/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5716 - auc: 0.7000 - accuracy: 0.7065 - val_loss: 0.5527 - val_auc: 0.7405 - val_accuracy: 0.7688\n",
      "Epoch 78/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5703 - auc: 0.7025 - accuracy: 0.7073 - val_loss: 0.5548 - val_auc: 0.7378 - val_accuracy: 0.7721\n",
      "Epoch 79/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5716 - auc: 0.6994 - accuracy: 0.7083 - val_loss: 0.5351 - val_auc: 0.7560 - val_accuracy: 0.7763\n",
      "Epoch 80/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5703 - auc: 0.6980 - accuracy: 0.7086 - val_loss: 0.5358 - val_auc: 0.7551 - val_accuracy: 0.7754\n",
      "Epoch 81/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5699 - auc: 0.7003 - accuracy: 0.7080 - val_loss: 0.5518 - val_auc: 0.7445 - val_accuracy: 0.7675\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 8th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.6499 - auc: 0.6404 - accuracy: 0.6193 - val_loss: 0.6024 - val_auc: 0.7321 - val_accuracy: 0.7435\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6100 - auc: 0.6750 - accuracy: 0.6743 - val_loss: 0.6039 - val_auc: 0.7496 - val_accuracy: 0.7756\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6018 - auc: 0.6824 - accuracy: 0.6820 - val_loss: 0.6035 - val_auc: 0.7472 - val_accuracy: 0.7588\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5997 - auc: 0.6810 - accuracy: 0.6844 - val_loss: 0.5971 - val_auc: 0.7606 - val_accuracy: 0.7710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5962 - auc: 0.6866 - accuracy: 0.6867 - val_loss: 0.5859 - val_auc: 0.7692 - val_accuracy: 0.7829\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5952 - auc: 0.6873 - accuracy: 0.6875 - val_loss: 0.5745 - val_auc: 0.7784 - val_accuracy: 0.7887\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5936 - auc: 0.6900 - accuracy: 0.6890 - val_loss: 0.5837 - val_auc: 0.7628 - val_accuracy: 0.7875\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5919 - auc: 0.6896 - accuracy: 0.6897 - val_loss: 0.5849 - val_auc: 0.7684 - val_accuracy: 0.7819\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5901 - auc: 0.6955 - accuracy: 0.6897 - val_loss: 0.5778 - val_auc: 0.7670 - val_accuracy: 0.7856\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5904 - auc: 0.6952 - accuracy: 0.6907 - val_loss: 0.5937 - val_auc: 0.7518 - val_accuracy: 0.7669\n",
      "Epoch 11/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5888 - auc: 0.6970 - accuracy: 0.6893 - val_loss: 0.5763 - val_auc: 0.7638 - val_accuracy: 0.7788\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5868 - auc: 0.7008 - accuracy: 0.6931 - val_loss: 0.5702 - val_auc: 0.7700 - val_accuracy: 0.7900\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 0.5861 - auc: 0.7001 - accuracy: 0.6935 - val_loss: 0.5574 - val_auc: 0.7789 - val_accuracy: 0.7940\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5845 - auc: 0.7042 - accuracy: 0.6949 - val_loss: 0.5538 - val_auc: 0.7875 - val_accuracy: 0.7965\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5863 - auc: 0.7030 - accuracy: 0.6945 - val_loss: 0.5674 - val_auc: 0.7683 - val_accuracy: 0.7856\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5830 - auc: 0.7075 - accuracy: 0.6973 - val_loss: 0.5594 - val_auc: 0.7735 - val_accuracy: 0.7883\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5823 - auc: 0.7089 - accuracy: 0.6972 - val_loss: 0.5773 - val_auc: 0.7558 - val_accuracy: 0.7698\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5808 - auc: 0.7105 - accuracy: 0.6981 - val_loss: 0.5545 - val_auc: 0.7821 - val_accuracy: 0.7942\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5798 - auc: 0.7124 - accuracy: 0.6994 - val_loss: 0.5559 - val_auc: 0.7797 - val_accuracy: 0.7900\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5811 - auc: 0.7109 - accuracy: 0.6990 - val_loss: 0.5476 - val_auc: 0.7903 - val_accuracy: 0.7906\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5785 - auc: 0.7142 - accuracy: 0.7011 - val_loss: 0.5522 - val_auc: 0.7849 - val_accuracy: 0.7890\n",
      "Epoch 22/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5784 - auc: 0.7145 - accuracy: 0.7004 - val_loss: 0.5539 - val_auc: 0.7807 - val_accuracy: 0.7858\n",
      "Epoch 23/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5776 - auc: 0.7154 - accuracy: 0.7032 - val_loss: 0.5580 - val_auc: 0.7754 - val_accuracy: 0.7823\n",
      "Epoch 24/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5781 - auc: 0.7157 - accuracy: 0.7019 - val_loss: 0.5632 - val_auc: 0.7693 - val_accuracy: 0.7775\n",
      "Epoch 25/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5773 - auc: 0.7167 - accuracy: 0.7019 - val_loss: 0.5598 - val_auc: 0.7687 - val_accuracy: 0.7773\n",
      "Epoch 26/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5764 - auc: 0.7189 - accuracy: 0.7030 - val_loss: 0.5526 - val_auc: 0.7819 - val_accuracy: 0.7823\n",
      "Epoch 27/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5758 - auc: 0.7201 - accuracy: 0.7040 - val_loss: 0.5512 - val_auc: 0.7773 - val_accuracy: 0.7806\n",
      "Epoch 28/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5753 - auc: 0.7182 - accuracy: 0.7045 - val_loss: 0.5555 - val_auc: 0.7733 - val_accuracy: 0.7779\n",
      "Epoch 29/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5750 - auc: 0.7211 - accuracy: 0.7050 - val_loss: 0.5609 - val_auc: 0.7672 - val_accuracy: 0.7715\n",
      "Epoch 30/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5755 - auc: 0.7189 - accuracy: 0.7047 - val_loss: 0.5552 - val_auc: 0.7718 - val_accuracy: 0.7746\n",
      "Epoch 31/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5745 - auc: 0.7211 - accuracy: 0.7065 - val_loss: 0.5821 - val_auc: 0.7413 - val_accuracy: 0.7465\n",
      "Epoch 32/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5747 - auc: 0.7198 - accuracy: 0.7045 - val_loss: 0.5681 - val_auc: 0.7567 - val_accuracy: 0.7708\n",
      "Epoch 33/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5733 - auc: 0.7222 - accuracy: 0.7060 - val_loss: 0.5551 - val_auc: 0.7701 - val_accuracy: 0.7756\n",
      "Epoch 34/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5748 - auc: 0.7184 - accuracy: 0.7035 - val_loss: 0.5384 - val_auc: 0.7875 - val_accuracy: 0.7804\n",
      "Epoch 35/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5729 - auc: 0.7204 - accuracy: 0.7059 - val_loss: 0.5515 - val_auc: 0.7738 - val_accuracy: 0.7779\n",
      "Epoch 36/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5723 - auc: 0.7209 - accuracy: 0.7054 - val_loss: 0.5718 - val_auc: 0.7505 - val_accuracy: 0.7631\n",
      "Epoch 37/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5718 - auc: 0.7220 - accuracy: 0.7071 - val_loss: 0.5662 - val_auc: 0.7592 - val_accuracy: 0.7698\n",
      "Epoch 38/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5734 - auc: 0.7206 - accuracy: 0.7043 - val_loss: 0.5457 - val_auc: 0.7813 - val_accuracy: 0.7775\n",
      "Epoch 39/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5715 - auc: 0.7219 - accuracy: 0.7058 - val_loss: 0.5525 - val_auc: 0.7710 - val_accuracy: 0.7738\n",
      "Epoch 40/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5726 - auc: 0.7215 - accuracy: 0.7049 - val_loss: 0.5413 - val_auc: 0.7861 - val_accuracy: 0.7790\n",
      "\n",
      "\n",
      "Train data shape: (29822, 6, 3) Val data shape: (4800, 6, 3)\n",
      "Training the model with 9th sample\n",
      "-----------------------------------------------\n",
      "Epoch 1/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.6710 - auc: 0.5885 - accuracy: 0.5941 - val_loss: 0.6358 - val_auc: 0.6394 - val_accuracy: 0.6862\n",
      "Epoch 2/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6185 - auc: 0.6293 - accuracy: 0.6614 - val_loss: 0.6221 - val_auc: 0.6656 - val_accuracy: 0.7419\n",
      "Epoch 3/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6091 - auc: 0.6384 - accuracy: 0.6734 - val_loss: 0.6096 - val_auc: 0.6980 - val_accuracy: 0.7796\n",
      "Epoch 4/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.6023 - auc: 0.6483 - accuracy: 0.6785 - val_loss: 0.6046 - val_auc: 0.7006 - val_accuracy: 0.7837\n",
      "Epoch 5/100\n",
      "932/932 [==============================] - 7s 8ms/step - loss: 0.5999 - auc: 0.6564 - accuracy: 0.6803 - val_loss: 0.5843 - val_auc: 0.7314 - val_accuracy: 0.7915\n",
      "Epoch 6/100\n",
      "932/932 [==============================] - 7s 7ms/step - loss: 0.5998 - auc: 0.6581 - accuracy: 0.6802 - val_loss: 0.5944 - val_auc: 0.7137 - val_accuracy: 0.7908\n",
      "Epoch 7/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.5986 - auc: 0.6605 - accuracy: 0.6825 - val_loss: 0.6060 - val_auc: 0.6910 - val_accuracy: 0.7794\n",
      "Epoch 8/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.5957 - auc: 0.6647 - accuracy: 0.6830 - val_loss: 0.5960 - val_auc: 0.7111 - val_accuracy: 0.7892\n",
      "Epoch 9/100\n",
      "932/932 [==============================] - 7s 7ms/step - loss: 0.5958 - auc: 0.6664 - accuracy: 0.6834 - val_loss: 0.5935 - val_auc: 0.7126 - val_accuracy: 0.7869\n",
      "Epoch 10/100\n",
      "932/932 [==============================] - 7s 7ms/step - loss: 0.5926 - auc: 0.6692 - accuracy: 0.6847 - val_loss: 0.5920 - val_auc: 0.7173 - val_accuracy: 0.7848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5941 - auc: 0.6708 - accuracy: 0.6845 - val_loss: 0.5877 - val_auc: 0.7201 - val_accuracy: 0.7906\n",
      "Epoch 12/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.5918 - auc: 0.6723 - accuracy: 0.6859 - val_loss: 0.5865 - val_auc: 0.7261 - val_accuracy: 0.7915\n",
      "Epoch 13/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5923 - auc: 0.6728 - accuracy: 0.6846 - val_loss: 0.5905 - val_auc: 0.7166 - val_accuracy: 0.7812\n",
      "Epoch 14/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5923 - auc: 0.6732 - accuracy: 0.6850 - val_loss: 0.5825 - val_auc: 0.7230 - val_accuracy: 0.7892\n",
      "Epoch 15/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5910 - auc: 0.6760 - accuracy: 0.6863 - val_loss: 0.5923 - val_auc: 0.7202 - val_accuracy: 0.7815\n",
      "Epoch 16/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5907 - auc: 0.6770 - accuracy: 0.6862 - val_loss: 0.5797 - val_auc: 0.7287 - val_accuracy: 0.7879\n",
      "Epoch 17/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.5894 - auc: 0.6785 - accuracy: 0.6878 - val_loss: 0.5844 - val_auc: 0.7230 - val_accuracy: 0.7827\n",
      "Epoch 18/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5904 - auc: 0.6803 - accuracy: 0.6838 - val_loss: 0.5760 - val_auc: 0.7347 - val_accuracy: 0.7917\n",
      "Epoch 19/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.5887 - auc: 0.6800 - accuracy: 0.6886 - val_loss: 0.5782 - val_auc: 0.7284 - val_accuracy: 0.7877\n",
      "Epoch 20/100\n",
      "932/932 [==============================] - 7s 7ms/step - loss: 0.5883 - auc: 0.6821 - accuracy: 0.6876 - val_loss: 0.5785 - val_auc: 0.7379 - val_accuracy: 0.7877\n",
      "Epoch 21/100\n",
      "932/932 [==============================] - 7s 7ms/step - loss: 0.5874 - auc: 0.6838 - accuracy: 0.6891 - val_loss: 0.5962 - val_auc: 0.7109 - val_accuracy: 0.7644\n",
      "Epoch 22/100\n",
      "932/932 [==============================] - 7s 8ms/step - loss: 0.5876 - auc: 0.6831 - accuracy: 0.6863 - val_loss: 0.5836 - val_auc: 0.7292 - val_accuracy: 0.7806\n",
      "Epoch 23/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.5862 - auc: 0.6852 - accuracy: 0.6869 - val_loss: 0.5902 - val_auc: 0.7183 - val_accuracy: 0.7706\n",
      "Epoch 24/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5868 - auc: 0.6847 - accuracy: 0.6894 - val_loss: 0.5658 - val_auc: 0.7463 - val_accuracy: 0.7912\n",
      "Epoch 25/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5850 - auc: 0.6856 - accuracy: 0.6904 - val_loss: 0.5778 - val_auc: 0.7321 - val_accuracy: 0.7842\n",
      "Epoch 26/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5860 - auc: 0.6871 - accuracy: 0.6886 - val_loss: 0.5784 - val_auc: 0.7324 - val_accuracy: 0.7781\n",
      "Epoch 27/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5845 - auc: 0.6890 - accuracy: 0.6888 - val_loss: 0.5861 - val_auc: 0.7285 - val_accuracy: 0.7754\n",
      "Epoch 28/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5852 - auc: 0.6900 - accuracy: 0.6902 - val_loss: 0.5860 - val_auc: 0.7243 - val_accuracy: 0.7735\n",
      "Epoch 29/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5840 - auc: 0.6914 - accuracy: 0.6886 - val_loss: 0.5709 - val_auc: 0.7415 - val_accuracy: 0.7823\n",
      "Epoch 30/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.5836 - auc: 0.6920 - accuracy: 0.6904 - val_loss: 0.5740 - val_auc: 0.7416 - val_accuracy: 0.7777\n",
      "Epoch 31/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5836 - auc: 0.6916 - accuracy: 0.6904 - val_loss: 0.5748 - val_auc: 0.7482 - val_accuracy: 0.7792\n",
      "Epoch 32/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5838 - auc: 0.6923 - accuracy: 0.6900 - val_loss: 0.5745 - val_auc: 0.7467 - val_accuracy: 0.7806\n",
      "Epoch 33/100\n",
      "932/932 [==============================] - 7s 7ms/step - loss: 0.5832 - auc: 0.6910 - accuracy: 0.6896 - val_loss: 0.5748 - val_auc: 0.7454 - val_accuracy: 0.7819\n",
      "Epoch 34/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5827 - auc: 0.6943 - accuracy: 0.6908 - val_loss: 0.5730 - val_auc: 0.7475 - val_accuracy: 0.7831\n",
      "Epoch 35/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5818 - auc: 0.6946 - accuracy: 0.6918 - val_loss: 0.5739 - val_auc: 0.7441 - val_accuracy: 0.7758\n",
      "Epoch 36/100\n",
      "932/932 [==============================] - 7s 7ms/step - loss: 0.5822 - auc: 0.6951 - accuracy: 0.6923 - val_loss: 0.5780 - val_auc: 0.7324 - val_accuracy: 0.7738\n",
      "Epoch 37/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5824 - auc: 0.6962 - accuracy: 0.6916 - val_loss: 0.5923 - val_auc: 0.7233 - val_accuracy: 0.7610\n",
      "Epoch 38/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5813 - auc: 0.6940 - accuracy: 0.6912 - val_loss: 0.5718 - val_auc: 0.7476 - val_accuracy: 0.7779\n",
      "Epoch 39/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5815 - auc: 0.6974 - accuracy: 0.6909 - val_loss: 0.5784 - val_auc: 0.7385 - val_accuracy: 0.7721\n",
      "Epoch 40/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5806 - auc: 0.6962 - accuracy: 0.6925 - val_loss: 0.5846 - val_auc: 0.7327 - val_accuracy: 0.7648\n",
      "Epoch 41/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.5803 - auc: 0.6979 - accuracy: 0.6918 - val_loss: 0.5735 - val_auc: 0.7490 - val_accuracy: 0.7773\n",
      "Epoch 42/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.5798 - auc: 0.6996 - accuracy: 0.6928 - val_loss: 0.5817 - val_auc: 0.7372 - val_accuracy: 0.7652\n",
      "Epoch 43/100\n",
      "932/932 [==============================] - 7s 8ms/step - loss: 0.5803 - auc: 0.6997 - accuracy: 0.6938 - val_loss: 0.5849 - val_auc: 0.7363 - val_accuracy: 0.7673\n",
      "Epoch 44/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5793 - auc: 0.7010 - accuracy: 0.6946 - val_loss: 0.5746 - val_auc: 0.7432 - val_accuracy: 0.7763\n",
      "Epoch 45/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5794 - auc: 0.6986 - accuracy: 0.6931 - val_loss: 0.5851 - val_auc: 0.7304 - val_accuracy: 0.7613\n",
      "Epoch 46/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5786 - auc: 0.6992 - accuracy: 0.6918 - val_loss: 0.5655 - val_auc: 0.7553 - val_accuracy: 0.7779\n",
      "Epoch 47/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5792 - auc: 0.6993 - accuracy: 0.6919 - val_loss: 0.5769 - val_auc: 0.7452 - val_accuracy: 0.7731\n",
      "Epoch 48/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5789 - auc: 0.6988 - accuracy: 0.6916 - val_loss: 0.5701 - val_auc: 0.7523 - val_accuracy: 0.7738\n",
      "Epoch 49/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5784 - auc: 0.6987 - accuracy: 0.6959 - val_loss: 0.5742 - val_auc: 0.7437 - val_accuracy: 0.7698\n",
      "Epoch 50/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5787 - auc: 0.6959 - accuracy: 0.6940 - val_loss: 0.5621 - val_auc: 0.7572 - val_accuracy: 0.7769\n",
      "Epoch 51/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5790 - auc: 0.6974 - accuracy: 0.6927 - val_loss: 0.5634 - val_auc: 0.7541 - val_accuracy: 0.7744\n",
      "Epoch 52/100\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 0.5776 - auc: 0.6973 - accuracy: 0.6945 - val_loss: 0.5661 - val_auc: 0.7565 - val_accuracy: 0.7765\n",
      "Epoch 53/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5774 - auc: 0.6995 - accuracy: 0.6943 - val_loss: 0.5751 - val_auc: 0.7454 - val_accuracy: 0.7663\n",
      "Epoch 54/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5773 - auc: 0.6984 - accuracy: 0.6940 - val_loss: 0.5747 - val_auc: 0.7410 - val_accuracy: 0.7579\n",
      "Epoch 55/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5765 - auc: 0.6991 - accuracy: 0.6958 - val_loss: 0.5541 - val_auc: 0.7656 - val_accuracy: 0.7800\n",
      "Epoch 56/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5767 - auc: 0.6999 - accuracy: 0.6959 - val_loss: 0.5800 - val_auc: 0.7375 - val_accuracy: 0.7590\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5773 - auc: 0.6983 - accuracy: 0.6972 - val_loss: 0.5630 - val_auc: 0.7563 - val_accuracy: 0.7735\n",
      "Epoch 58/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5755 - auc: 0.7026 - accuracy: 0.6955 - val_loss: 0.5757 - val_auc: 0.7444 - val_accuracy: 0.7598\n",
      "Epoch 59/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5757 - auc: 0.7008 - accuracy: 0.6958 - val_loss: 0.5634 - val_auc: 0.7575 - val_accuracy: 0.7735\n",
      "Epoch 60/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5758 - auc: 0.7003 - accuracy: 0.6950 - val_loss: 0.5692 - val_auc: 0.7549 - val_accuracy: 0.7704\n",
      "Epoch 61/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5755 - auc: 0.7019 - accuracy: 0.6982 - val_loss: 0.5764 - val_auc: 0.7497 - val_accuracy: 0.7625\n",
      "Epoch 62/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5753 - auc: 0.7004 - accuracy: 0.6947 - val_loss: 0.5790 - val_auc: 0.7420 - val_accuracy: 0.7573\n",
      "Epoch 63/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5756 - auc: 0.6977 - accuracy: 0.6980 - val_loss: 0.5731 - val_auc: 0.7478 - val_accuracy: 0.7619\n",
      "Epoch 64/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5761 - auc: 0.7005 - accuracy: 0.6976 - val_loss: 0.5590 - val_auc: 0.7629 - val_accuracy: 0.7754\n",
      "Epoch 65/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5753 - auc: 0.7009 - accuracy: 0.6960 - val_loss: 0.5714 - val_auc: 0.7477 - val_accuracy: 0.7573\n",
      "Epoch 66/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5750 - auc: 0.6995 - accuracy: 0.6984 - val_loss: 0.5796 - val_auc: 0.7401 - val_accuracy: 0.7565\n",
      "Epoch 67/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5752 - auc: 0.7004 - accuracy: 0.6960 - val_loss: 0.5749 - val_auc: 0.7450 - val_accuracy: 0.7598\n",
      "Epoch 68/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5748 - auc: 0.6996 - accuracy: 0.6979 - val_loss: 0.5708 - val_auc: 0.7507 - val_accuracy: 0.7654\n",
      "Epoch 69/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5755 - auc: 0.6980 - accuracy: 0.6975 - val_loss: 0.5658 - val_auc: 0.7518 - val_accuracy: 0.7617\n",
      "Epoch 70/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5742 - auc: 0.6976 - accuracy: 0.6976 - val_loss: 0.5672 - val_auc: 0.7531 - val_accuracy: 0.7619\n",
      "Epoch 71/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5733 - auc: 0.6991 - accuracy: 0.6987 - val_loss: 0.5672 - val_auc: 0.7484 - val_accuracy: 0.7600\n",
      "Epoch 72/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5747 - auc: 0.6978 - accuracy: 0.6960 - val_loss: 0.5729 - val_auc: 0.7480 - val_accuracy: 0.7606\n",
      "Epoch 73/100\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.5743 - auc: 0.6967 - accuracy: 0.6998 - val_loss: 0.5603 - val_auc: 0.7575 - val_accuracy: 0.7669\n",
      "Epoch 74/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5748 - auc: 0.6961 - accuracy: 0.6996 - val_loss: 0.5622 - val_auc: 0.7578 - val_accuracy: 0.7621\n",
      "Epoch 75/100\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 0.5732 - auc: 0.6964 - accuracy: 0.6993 - val_loss: 0.5805 - val_auc: 0.7372 - val_accuracy: 0.7498\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 각각의 모델로 각각의 표본 학습 (patience 수정)\n",
    "\n",
    "epochs = 100\n",
    "plot_list_half_2 = []\n",
    "model_list_half_2 = []\n",
    "learning_rate = 0.00001 ## converge를 위해서\n",
    "\n",
    "for (j, sample) in enumerate(sampling_list_half):\n",
    "    \n",
    "    X_train_preprocessing = sample[0]\n",
    "    X_train_add_feature = sample[1]\n",
    "    y_train_preprocessing = sample[3]\n",
    "    \n",
    "    print(\"Train data shape: {} Val data shape: {}\".format(X_train_preprocessing.shape, X_val_preprocessing.shape))\n",
    "    print(\"Training the model with {}th sample\".format(j))\n",
    "    print(\"-----------------------------------------------\")\n",
    "    \n",
    "    model_half_2 = RNN_Model(learning_rate)\n",
    "    ## patience 10 -> 20\n",
    "    epoch, hist = train_model(model_half_2, [X_train_preprocessing, X_train_add_feature], y_train_preprocessing, \n",
    "                              [X_val_preprocessing, X_val_add_feature], y_val_preprocessing, epochs = epochs, batch_size = 32, patience = 20)\n",
    "\n",
    "    model_list_half_2.append(model_half_2)\n",
    "    plot_list_half_2.append([epoch, hist])\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the 0th model\n",
      "0th model's \u001b[35m Precision \u001b[30m: 46.95 \u001b[35m Recall \u001b[30m: 58.26 \u001b[35m F1-score \u001b[30m: 0.52 \u001b[35m Accuracy\u001b[30m: 0.76 \n",
      "\n",
      "Predicting the 1th model\n",
      "1th model's \u001b[35m Precision \u001b[30m: 52.57 \u001b[35m Recall \u001b[30m: 50.61 \u001b[35m F1-score \u001b[30m: 0.52 \u001b[35m Accuracy\u001b[30m: 0.79 \n",
      "\n",
      "Predicting the 2th model\n",
      "2th model's \u001b[35m Precision \u001b[30m: 48.18 \u001b[35m Recall \u001b[30m: 54.53 \u001b[35m F1-score \u001b[30m: 0.51 \u001b[35m Accuracy\u001b[30m: 0.77 \n",
      "\n",
      "Predicting the 3th model\n",
      "3th model's \u001b[35m Precision \u001b[30m: 49.19 \u001b[35m Recall \u001b[30m: 54.06 \u001b[35m F1-score \u001b[30m: 0.52 \u001b[35m Accuracy\u001b[30m: 0.77 \n",
      "\n",
      "Predicting the 4th model\n",
      "4th model's \u001b[35m Precision \u001b[30m: 50.94 \u001b[35m Recall \u001b[30m: 53.22 \u001b[35m F1-score \u001b[30m: 0.52 \u001b[35m Accuracy\u001b[30m: 0.78 \n",
      "\n",
      "Predicting the 5th model\n",
      "5th model's \u001b[35m Precision \u001b[30m: 50.54 \u001b[35m Recall \u001b[30m: 52.85 \u001b[35m F1-score \u001b[30m: 0.52 \u001b[35m Accuracy\u001b[30m: 0.78 \n",
      "\n",
      "Predicting the 6th model\n",
      "6th model's \u001b[35m Precision \u001b[30m: 51.92 \u001b[35m Recall \u001b[30m: 49.30 \u001b[35m F1-score \u001b[30m: 0.51 \u001b[35m Accuracy\u001b[30m: 0.79 \n",
      "\n",
      "Predicting the 7th model\n",
      "7th model's \u001b[35m Precision \u001b[30m: 51.47 \u001b[35m Recall \u001b[30m: 53.97 \u001b[35m F1-score \u001b[30m: 0.53 \u001b[35m Accuracy\u001b[30m: 0.78 \n",
      "\n",
      "Predicting the 8th model\n",
      "8th model's \u001b[35m Precision \u001b[30m: 53.17 \u001b[35m Recall \u001b[30m: 51.73 \u001b[35m F1-score \u001b[30m: 0.52 \u001b[35m Accuracy\u001b[30m: 0.79 \n",
      "\n",
      "Predicting the 9th model\n",
      "9th model's \u001b[35m Precision \u001b[30m: 50.67 \u001b[35m Recall \u001b[30m: 52.94 \u001b[35m F1-score \u001b[30m: 0.52 \u001b[35m Accuracy\u001b[30m: 0.78 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# f1-score\n",
    "for (i, sample) in enumerate(sampling_list_half):\n",
    "    \n",
    "    print(\"Predicting the {}th model\".format(i))\n",
    "    \n",
    "    model = model_list_half_2[i]\n",
    "    y_proba = model.predict([X_val_preprocessing, X_val_add_feature])\n",
    "    y_pred = np.argmax(y_proba, axis = 1)\n",
    "    \n",
    "    precision, recall, f1, accuracy = f1_score(y_val, y_pred)\n",
    "    print(\"{}th model's \\033[35m Precision \\033[30m: {:.2f} \\033[35m Recall \\033[30m: {:.2f} \\033[35m F1-score \\033[30m: {:.2f} \\033[35m Accuracy\\033[30m: {:.2f} \\n\".format(i, precision * 100, recall * 100, f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_list = np.array([.0] * (len(X_test) * 2)).reshape(-1, 2)\n",
    "\n",
    "for (i, model) in enumerate(model_list_half_2):\n",
    "    \n",
    "    y_proba = model.predict([X_test_preprocessing, X_test_add_feature])\n",
    "    proba_list += y_proba\n",
    "    \n",
    "y_pred = np.argmax((proba_list / len(model_list_half_2)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mPrecision\u001b[30m: 0.53, \u001b[35mRecall\u001b[30m: 0.56, \u001b[35mF1-Score\u001b[30m: 0.54, \u001b[35mAccuracy\u001b[30m: 0.80\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, accuracy = f1_score(y_test, y_pred)\n",
    "print(\"\\033[35mPrecision\\033[30m: {:.2f}, \\033[35mRecall\\033[30m: {:.2f}, \\033[35mF1-Score\\033[30m: {:.2f}, \\033[35mAccuracy\\033[30m: {:.2f}\".format(precision, recall, f1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## early stopping 의 monitor를 loss로 변경하고 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Anaconda\\envs\\py37tf20\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "sample_proportion =[0.5] * 10\n",
    "sampling_list_5 = []\n",
    "\n",
    "for (i, proportion) in enumerate(sample_proportion):\n",
    "    df = load_sampling(split_train, proportion)\n",
    "    \n",
    "    X_train_preprocessing, X_train_add_feature, y_train_before, y_train_preprocessing = preprocessing(df)\n",
    "    \n",
    "    sampling_list_5.append([X_train_preprocessing, X_train_add_feature, y_train_preprocessing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각각의 모델로 각각의 표본 학습 (patience 수정)\n",
    "\n",
    "epochs = 150\n",
    "plot_list_5= []\n",
    "model_list_5 = []\n",
    "learning_rate = 0.00001 ## converge를 위해서\n",
    "\n",
    "for (j, sample) in enumerate(sampling_list_5):\n",
    "    \n",
    "    X_train_preprocessing = sample[0]\n",
    "    X_train_add_feature = sample[1]\n",
    "    y_train_preprocessing = sample[3]\n",
    "    \n",
    "    print(\"Train data shape: {} Val data shape: {}\".format(X_train_preprocessing.shape, X_val_preprocessing.shape))\n",
    "    print(\"Training the model with {}th sample\".format(j))\n",
    "    print(\"-----------------------------------------------\")\n",
    "    \n",
    "    model_5 = RNN_Model(learning_rate)\n",
    "    ## patience 10 -> 20\n",
    "    epoch, hist = train_model(model_half_2, [X_train_preprocessing, X_train_add_feature], y_train_preprocessing, \n",
    "                              [X_val_preprocessing, X_val_add_feature], y_val_preprocessing, epochs = epochs, batch_size = 32, patience = 15, monitor = 'val_loss')\n",
    "\n",
    "    model_list_5.append(model_half_2)\n",
    "    plot_list_5.append([epoch, hist])\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37tf20]",
   "language": "python",
   "name": "conda-env-py37tf20-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
